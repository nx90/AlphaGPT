<!DOCTYPE html>
<!-- saved from url=(0035)https://arxiv.org/html/2505.11122v3 -->
<html lang="en" data-theme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining</title>
<!--Generated on Wed Nov 12 07:06:06 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css">
<script src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/bootstrap.bundle.min.js.下载"></script>
<script src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/html2canvas.min.js.下载"></script>
<script src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/addons_new.js.下载"></script>
<script src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/feedbackOverlay.js.下载"></script>
<!--<base href="/html/2505.11122v3/">--><base href="."><link rel="stylesheet" href="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-modal {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style type="text/css">/* Copyright 2014-present Evernote Corporation. All rights reserved. */
@keyframes caretBlink {
    from { opacity: 1.0; }
    to { opacity: 0.0; }
}

@keyframes rotateSpinner {
    from {
        transform:rotate(0deg);
    }
    to {
        transform:rotate(360deg);
    }
}

#text-tool-caret {
    animation-name: caretBlink;  
    animation-iteration-count: infinite;  
    animation-timing-function: cubic-bezier(1.0,0,0,1.0);
    animation-duration: 1s; 
}

#en-markup-loading-spinner {
    position: absolute;
    top: calc(50% - 16px);
    left: calc(50% - 16px);
    width: 32px;
    height: 32px;
}

#en-markup-loading-spinner img {
    position: relative;
    top: 0px;
    left: 0px;
    animation-name: rotateSpinner;
    animation-duration: 0.6s;
    animation-iteration-count: infinite;
    animation-timing-function: linear;
}
</style><style type="text/css">/* Copyright 2014-present Evernote Corporation. All rights reserved. */
.skitchToastBoxContainer {
    position: absolute;
    width: 100%;
    text-align: center;
    top: 30px;
    -webkit-user-select: none;
    -moz-user-select: none;
    pointer-events: none;
}

.skitchToastBox {
    width: 200px;
    height: 16px;
    padding: 12px;
    background-color: rgba(47, 55, 61, 0.95);
    border-radius: 4px;
    color: white;
    cursor: default;
    font-size: 10pt;
    text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.32);
    font-family: 'Soleil', Helvetica, Arial, sans-serif;
    border: 2px rgba(255, 255, 255, 0.38) solid;
}

.lang-zh-cn .skitchToastBox {
    font-family: '微软雅黑', 'Microsoft YaHei', SimSun,
        '&#x30E1;&#x30A4;&#x30EA;&#x30AA;', Meiryo, 'MS PGothic', 'Soleil',
        Helvetica, Arial, sans-serif;
}

.lang-ja-jp .skitchToastBox {
    font-family: '&#x30E1;&#x30A4;&#x30EA;&#x30AA;', Meiryo, 'MS PGothic',
        '微软雅黑', 'Microsoft YaHei', SimSun, 'Soleil', Helvetica, Arial,
        sans-serif;
}

.skitchToast {
    padding-left: 20px;
    padding-right: 20px;
    display: inline-block;
    height: 10px;
    color: #f1f5f8;
    text-align: center;
}

.skitchVisible {
    /* Don't remove this class it's a hack used by the Evernote Clipper */
}
</style><style type="text/css">/* Copyright 2014-present Evernote Corporation. All rights reserved. */

@font-face {
	font-family: 'Soleil';
	src: url(data:application/font-woff2;base64,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);
	font-weight: normal;
	font-style: normal;
}
</style><style type="text/css">/* Copyright 2019-present Evernote Corporation. All rights reserved. */

#en-markup-disabled {
    position: fixed;
    z-index: 9999;
    width: 100%;
    height: 100%;
    top: 0px;
    left: 0px;
    cursor: default;
    -webkit-user-select: none;
}

#en-markup-alert-container {
    position: absolute;
    z-index: 9999;
    width: 450px;
    left: calc(50% - 225px);
    top: calc(50% - 85px);
    background-color: white;
    box-shadow: 0 2px 7px 1px rgba(0,0,0,0.35);
    -webkit-user-select: none;
}

#en-markup-alert-container .cell-1 {
    position: relative;
    height: 110px;
    width: 105px;
    float: left;
    text-align: center;
    background-image: url(data:image/png;base64,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);
    background-position: 65% 50%;
    background-repeat: no-repeat;
}

#en-markup-alert-container .cell-2 {
    position: relative;
    float: left;
    width: 345px;
    margin-top: 29px;
    margin-bottom: 20px;
}

#en-markup-alert-container .cell-2 .cell-2-title {
    margin-bottom: 5px;
    padding-right: 30px;
    font-size: 12pt;
    font-family: Tahoma, Arial;
}

#en-markup-alert-container .cell-2 .cell-2-message {
    padding-right: 30px;
    font-size: 9.5pt;
    font-family: Tahoma, Arial;
}

#en-markup-alert-container .cell-3 {
    position: relative;
    width: 450px;
    height: 60px;
    float: left;
    background-color: rgb(240,240,240);
}

#en-markup-alert-container .cell-3 button {
    position: absolute;
    top: 12px;
    right: 15px;
    width: 110px;
    height: 36px;
}

#en-markup-alert-container .cell-3 button.alt-button {
    position: absolute;
    top: 12px;
    right: 140px;
    width: 110px;
    height: 36px;
}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2505.11122v3">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2505.11122v3/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2505.11122v3">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2505.11122v3" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S1" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S2" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Preliminary</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S2.SSx1" title="In 2 Preliminary ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Factor Mining</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S2.SSx2" title="In 2 Preliminary ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Formulaic Alpha</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx1" title="In 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx2" title="In 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Expansion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx3" title="In 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Multi-Dimensional Alpha Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx4" title="In 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Backpropagation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx5" title="In 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Frequent Subtree Avoidance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx1" title="In 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Experiment Settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx1.SSS0.Px1" title="In Experiment Settings ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx1.SSS0.Px2" title="In Experiment Settings ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Baselines for Comparison</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx2" title="In 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Experiment 1: Prediction Performance Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx3" title="In 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Experiment 2: Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx4" title="In 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Experiment 3: Interpretablitity of Alpha Formulas</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S5" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S6" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A1" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Summary of Appendix</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Further Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2.SSx1" title="In Appendix B Further Related Work ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Automated Formulaic Alpha Mining</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2.SSx1.SSS0.Px1" title="In Automated Formulaic Alpha Mining ‣ Appendix B Further Related Work ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Traditional Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2.SSx1.SSS0.Px2" title="In Automated Formulaic Alpha Mining ‣ Appendix B Further Related Work ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Other LLM-based Frameworks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2.SSx2" title="In Appendix B Further Related Work ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Tree Search-based Reasoning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Illustrative Case Study of MCTS Workflow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Method Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx1" title="In Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Formula Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx2" title="In Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Refinement Suggestion Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx2.SSS0.Px1" title="In Refinement Suggestion Generation ‣ Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Effectiveness and Stability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx2.SSS0.Px2" title="In Refinement Suggestion Generation ‣ Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Diversity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx2.SSS0.Px3" title="In Refinement Suggestion Generation ‣ Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Turnover and Overfitting Risk</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx3" title="In Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Multi-Dimensional Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4.SSx4" title="In Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Dynamic Search Budget Allocation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A5" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>List of Operators</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A6" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Pseudo-Code</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Experimental Setup Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx1" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Hyperparameter Configurations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2.SSS0.Px1" title="In Hyperparameter Configurations ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Temperature Parameter of LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2.SSS0.Px2" title="In Hyperparameter Configurations ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">MCTS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2.SSS0.Px3" title="In Hyperparameter Configurations ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Effective Alpha Check</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2.SSS0.Px4" title="In Hyperparameter Configurations ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Evaluation Score</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx2.SSS0.Px5" title="In Hyperparameter Configurations ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Other Settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx3" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Model Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx4" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Backtesting Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx5" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Environment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx6" title="In Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Predictive Performance Evaluation Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx6.SSS0.Px1" title="In Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Information Coefficient (IC)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx6.SSS0.Px2" title="In Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Rank Information Coefficient (RankIC)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx6.SSS0.Px3" title="In Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Annualized Excess Return (AER)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx6.SSS0.Px4" title="In Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Information Ratio (IR)</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Additional Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx1" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Comparisons with Other Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx2" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Additional Results on the U.S. Stock Market</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx2.SSS0.Px1" title="In Additional Results on the U.S. Stock Market ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx2.SSS0.Px2" title="In Additional Results on the U.S. Stock Market ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx3" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Investigation of Potential Data Leakage in LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx4" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Sensitivity Analysis of LLM Backbone Choice</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx5" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Characteristics of Alphas at Varying MCTS Search Depths</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx6" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Cumulative Return Curve Visualizations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx7" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Interpretability of Mined Alpha Formulas</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx8" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Sensitivity Analysis of Key Framework Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9" title="In Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Cost Estimation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9.SSS0.Px1" title="In Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Server Computational Cost</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9.SSS0.Px2" title="In Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">LLM API Cost</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9.SSS0.Px3" title="In Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Estimation Considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9.SSS0.Px4" title="In Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Comparison under Equal API Cost</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span>Full Experimental Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A10" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">J </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11" title="In Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">K </span>LLM Agent Prompts</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.SSx1" title="In Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Portrait Generation Prompt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.SSx2" title="In Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Formula Generation Prompt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.SSx3" title="In Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Overfitting Risk Assessment Prompt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.SSx4" title="In Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_title">Alpha Refinement Prompt</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license</a><div id="watermark-tr">arXiv:2505.11122v3 [cs.AI] 12 Nov 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Navigating the Alpha Jungle:
<br class="ltx_break">An LLM-Powered MCTS Framework for Formulaic Factor Mining</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yu Shi<sup class="ltx_sup">1</sup>, Yitong Duan<sup class="ltx_sup">1, 2</sup>, and Jian Li<sup class="ltx_sup">1</sup>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p">Alpha factor mining is pivotal in quantitative investment for identifying predictive signals from complex financial data. While traditional formulaic alpha mining relies on human expertise, contemporary automated methods, such as those based on genetic programming or reinforcement learning, often struggle with search inefficiency or yield alpha factors that are difficult to interpret. This paper introduces a novel framework that integrates Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS) to overcome these limitations. Our framework leverages the LLM’s instruction-following and reasoning capability to iteratively generate and refine symbolic alpha formulas within an MCTS-driven exploration. A key innovation is the guidance of MCTS exploration by rich, quantitative feedback from financial backtesting of each candidate factor, enabling efficient navigation of the vast search space. Furthermore, a frequent subtree avoidance mechanism is introduced to enhance search diversity and prevent formulaic homogenization, further improving performance. Experimental results on real-world stock market data demonstrate that our LLM-based framework outperforms existing methods by mining alphas with superior predictive accuracy and trading performance. The resulting formulas are also more amenable to human interpretation, establishing a more effective and efficient paradigm for formulaic alpha mining.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">Predicting price movements in financial markets, characterized by low signal-to-noise ratios, remains a central challenge in quantitative investment. A common strategy to enhance model predictiveness is the extraction of predictive signals, or alpha factors (hereafter simply “alphas”), from stock data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Qian, Hua, and Sorensen <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib22" title="">2007</a>; Tulchinsky <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib27" title="">2019</a>)</cite>. Current alpha factor mining methodologies broadly fall into two categories: neural network-based and formula-based. Neural approaches (e.g., FactorVAE&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Duan et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib7" title="">2022</a>)</cite>, HIST&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib34" title="">2021a</a>)</cite>, REST&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib35" title="">2021b</a>)</cite>) implicitly construct complex alphas via deep learning, capturing intricate patterns but often suffering from a lack of interpretability. In contrast, formula-based methods aim to discover alphas represented by explicit mathematical expressions. These alpha factors are traditionally human-crafted, reflecting market insights (e.g., Fama-French factors&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fama and French <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib9" title="">1992</a>)</cite>, financial anomalies&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Harvey, Liu, and Zhu <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib11" title="">2016</a>; Hou, Xue, and Zhang <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib12" title="">2020</a>)</cite>). In recent years, automated techniques have emerged, employing methods like genetic programming or reinforcement learning to discover such formulaic alphas&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shi et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib24" title="">2024</a>; Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib39" title="">2023</a>; Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib43" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib44" title="">2023b</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="475" id="S1.F1.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A high-level schematic of our proposed alpha mining pipeline. The pipeline features an iterative Alpha Search loop where an LLM, guided by MCTS, generates and refines formulas. Effective alphas are collected in an Alpha Zoo before being used in the final Strategy Building stage.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">Despite their promise, existing automated formulaic alpha mining approaches face significant limitations.
<span class="ltx_text ltx_font_bold">First, the discovered alphas often exhibit poor interpretability.</span> These automated methods frequently engage in unconstrained, data-driven exploration of the vast alpha space, often without sufficient guidance from financial theory or domain expertise. Consequently, the resulting formulas can be overly complex and opaque. This lack of transparency poses considerable challenges in practical investment scenarios: it hinders practitioners’ ability to understand the underlying economic rationale of a strategy, makes it difficult to attribute portfolio performance accurately, and can erode trust, thereby impeding the adoption of these alphas even if they show promise in backtests.
<span class="ltx_text ltx_font_bold">Second, current methodologies often suffer from search inefficiency.</span> The search for a sufficient number of effective alpha factors typically requires generating and evaluating an enormous volume of candidate formulas. This exhaustive search process, while necessary due to the low signal density, inherently increases the likelihood of discovering spurious relationships and overfitting to the training data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Harvey, Liu, and Zhu <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib11" title="">2016</a>)</cite>. As a result, many discovered alphas may exhibit poor generalization and deliver underwhelming out-of-sample performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p">Addressing the identified shortcomings necessitates innovative approaches. In this light, Large Language Models (LLMs) emerge as a promising direction, given their vast prior knowledge and strong reasoning capabilities which are well-suited for generating interpretable alphas—a potential demonstrated in analogous tasks like financial investment&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib40" title="">2024</a>)</cite> and code generation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib18" title="">2024a</a>)</cite>. Drawing inspiration from advancements in LLM reasoning (e.g., Chain-of-Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib32" title="">2022</a>)</cite>, Tree-of-Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib38" title="">2024</a>)</cite>) and the efficacy of Monte Carlo Tree Search (MCTS)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Coulom <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib2" title="">2007</a>; Silver et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib25" title="">2016</a>)</cite> in enhancing LLM performance on complex problems&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib41" title="">2024</a>)</cite>, we frame alpha mining as an MCTS-driven search problem. Within this framework, each node in the tree represents a candidate alpha formula, allowing for a systematic exploration and iterative refinement within the vast and complex alpha space. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">1</span></a> provides a high-level illustration of this entire pipeline.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p">Unlike tasks such as mathematical derivation, where evaluating the contribution of intermediate steps towards the final solution is often challenging before the derivation is complete, alpha factor mining provides fine-grained feedback on each candidate alpha formula through backtesting. We leverage this detailed feedback to guide our search. We initiate the search with a LLM-generated alpha formula, as the root node of the search tree. Then we utilize the LLM to iteratively refine and improve the formulas, expanding the tree with new, potentially superior nodes. Furthermore, to mitigate the homogeneity of generated alpha formulas, we conduct frequent subtree mining on effective alphas and explicitly instruct the LLM to avoid using the most frequent subtrees during generation. By explicitly diversifying the search away from these common motifs, our approach enhances search efficiency and improves the quality of discovered alphas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p">The synergy between MCTS and LLMs has indeed shown promise in various reasoning tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhao, Lee, and Hsu <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib45" title="">2023</a>; DeLorenzo et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib6" title="">2024</a>)</cite>. Our work is distinct in its specific application of this synergy to the unique challenges of formulaic alpha mining. Unlike general reasoning tasks that use MCTS to explore a set of predefined actions or have the LLM evaluate abstract states&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xie et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib33" title="">2024</a>; Li et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib19" title="">2025</a>; Dainese et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib4" title="">2024</a>)</cite>, our framework leverages the LLM as a <span class="ltx_text ltx_font_italic">generative prior</span> for symbolic alpha formulas. Crucially, the MCTS exploration is guided by rich, quantitative, and domain-specific feedback from financial backtesting performed on each candidate alpha. This iterative loop—where the LLM’s generative capabilities are steered by MCTS informed by empirical financial performance—offers a distinct advantage.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p">The main contributions of this paper can be summarized as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p7">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p">We propose an LLM-Powered MCTS framework for formulaic alpha mining, modeling the task as a tree search-based reasoning problem where the LLM performs multi-step formula refinement guided by detailed backtesting feedback.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p">We design a frequent subtree avoidance method to improve search efficiency and alpha effectiveness by guiding the LLM to explore less common yet potentially effective formula structures.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p">We conduct a series of experiments to demonstrate the effectiveness of our proposed framework. The alphas mined by our framework achieve superior prediction performance while maintaining good interpretability, compared to those from other methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminary</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Alpha Factor Mining</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SSx1.p1">
<p class="ltx_p">We consider a financial market with <math alttext="n" class="ltx_Math" display="inline" id="S2.SSx1.p1.m1" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> stocks observed over <math alttext="T" class="ltx_Math" display="inline" id="S2.SSx1.p1.m2" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> trading days. For each stock <math alttext="i\in\{1,\dots,n\}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m3" intent=":literal"><semantics><mrow><mi>i</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>n</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">i\in\{1,\dots,n\}</annotation></semantics></math> and day <math alttext="t\in\{1,\dots,T\}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m4" intent=":literal"><semantics><mrow><mi>t</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>T</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">t\in\{1,\dots,T\}</annotation></semantics></math>, its state is described by a feature vector <math alttext="\bm{x}_{i,t}\in\mathbb{R}^{m}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m5" intent=":literal"><semantics><mrow><msub><mi>𝒙</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>∈</mo><msup><mi>ℝ</mi><mi>m</mi></msup></mrow><annotation encoding="application/x-tex">\bm{x}_{i,t}\in\mathbb{R}^{m}</annotation></semantics></math>. Raw features include daily open, high, low, close prices (OHLC), trading volume, and Volume-Weighted Average Price (VWAP). The complete market history is a tensor <math alttext="\bm{X}\in\mathbb{R}^{T\times n\times m}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m6" intent=":literal"><semantics><mrow><mi>𝑿</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>T</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>n</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\bm{X}\in\mathbb{R}^{T\times n\times m}</annotation></semantics></math>. Correspondingly, future returns are organized in a matrix <math alttext="\bm{Y}\in\mathbb{R}^{T\times n}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m7" intent=":literal"><semantics><mrow><mi>𝒀</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>T</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\bm{Y}\in\mathbb{R}^{T\times n}</annotation></semantics></math>, where <math alttext="y_{i,t}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m8" intent=":literal"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">y_{i,t}</annotation></semantics></math> is the realized future return for stock <math alttext="i" class="ltx_Math" display="inline" id="S2.SSx1.p1.m9" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> subsequent to day <math alttext="t" class="ltx_Math" display="inline" id="S2.SSx1.p1.m10" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>. To capture temporal patterns, we use a lookback window of length <math alttext="\tau" class="ltx_Math" display="inline" id="S2.SSx1.p1.m11" intent=":literal"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>. An <span class="ltx_text ltx_font_italic">alpha factor</span>, <math alttext="f" class="ltx_Math" display="inline" id="S2.SSx1.p1.m12" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>, maps the historical feature data for this window, <math alttext="\bm{X}_{t-\tau+1:t}=\{\bm{X}_{s}\mid t-\tau&lt;s\leq t\}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m13" intent=":literal"><semantics><mrow><msub><mi>𝑿</mi><mrow><mrow><mrow><mi>t</mi><mo>−</mo><mi>τ</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo lspace="0.278em" rspace="0.278em">:</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>𝑿</mi><mi>s</mi></msub><mo fence="true" lspace="0em" rspace="0em">∣</mo><mrow><mrow><mi>t</mi><mo>−</mo><mi>τ</mi></mrow><mo>&lt;</mo><mi>s</mi><mo>≤</mo><mi>t</mi></mrow><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{X}_{t-\tau+1:t}=\{\bm{X}_{s}\mid t-\tau&lt;s\leq t\}</annotation></semantics></math>, to a vector of predictive scores <math alttext="\bm{v}_{t}=f(\bm{X}_{t-\tau+1:t})\in\mathbb{R}^{n}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m14" intent=":literal"><semantics><mrow><msub><mi>𝒗</mi><mi>t</mi></msub><mo>=</mo><mrow><mi>f</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝑿</mi><mrow><mrow><mrow><mi>t</mi><mo>−</mo><mi>τ</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo lspace="0.278em" rspace="0.278em">:</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>∈</mo><msup><mi>ℝ</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">\bm{v}_{t}=f(\bm{X}_{t-\tau+1:t})\in\mathbb{R}^{n}</annotation></semantics></math>. Each <math alttext="v_{i,t}" class="ltx_Math" display="inline" id="S2.SSx1.p1.m15" intent=":literal"><semantics><msub><mi>v</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">v_{i,t}</annotation></semantics></math> represents the alpha’s assessment of stock <math alttext="i" class="ltx_Math" display="inline" id="S2.SSx1.p1.m16" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>’s future return.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SSx1.p2">
<p class="ltx_p">Alpha factor mining aims to discover a diverse set of <math alttext="K" class="ltx_Math" display="inline" id="S2.SSx1.p2.m1" intent=":literal"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> alphas, <math alttext="\mathcal{F}=\{f_{1},\dots,f_{K}\}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m2" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>f</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>f</mi><mi>K</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{F}=\{f_{1},\dots,f_{K}\}</annotation></semantics></math>, by searching within the vast space of all possible alpha factors, denoted as <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>. The outputs of these individual alphas, <math alttext="\{\bm{v}_{k,t}=f_{k}(\bm{X}_{t-\tau+1:t})\}_{k=1}^{K}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m4" intent=":literal"><semantics><msubsup><mrow><mo stretchy="false">{</mo><mrow><msub><mi>𝒗</mi><mrow><mi>k</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><msub><mi>f</mi><mi>k</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝑿</mi><mrow><mrow><mrow><mi>t</mi><mo>−</mo><mi>τ</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo lspace="0.278em" rspace="0.278em">:</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><annotation encoding="application/x-tex">\{\bm{v}_{k,t}=f_{k}(\bm{X}_{t-\tau+1:t})\}_{k=1}^{K}</annotation></semantics></math>, are typically aggregated by a combination model, <math alttext="g" class="ltx_Math" display="inline" id="S2.SSx1.p2.m5" intent=":literal"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>, into a composite alpha vector <math alttext="\bm{z}_{t}=g(\{\bm{v}_{k,t}\}_{k=1}^{K};\bm{\theta}_{g})" class="ltx_Math" display="inline" id="S2.SSx1.p2.m6" intent=":literal"><semantics><mrow><msub><mi>𝒛</mi><mi>t</mi></msub><mo>=</mo><mrow><mi>g</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>𝒗</mi><mrow><mi>k</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>;</mo><msub><mi>𝜽</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bm{z}_{t}=g(\{\bm{v}_{k,t}\}_{k=1}^{K};\bm{\theta}_{g})</annotation></semantics></math>, where <math alttext="\bm{\theta}_{g}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m7" intent=":literal"><semantics><msub><mi>𝜽</mi><mi>g</mi></msub><annotation encoding="application/x-tex">\bm{\theta}_{g}</annotation></semantics></math> are model parameters.
The quality of this composite signal is evaluated using a predefined performance metric, <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m8" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℒ</mi><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math> (e.g., Information Coefficient). Optimal parameters for the combination model, <math alttext="\bm{\theta}_{g}^{*}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m9" intent=":literal"><semantics><msubsup><mi>𝜽</mi><mi>g</mi><mo>∗</mo></msubsup><annotation encoding="application/x-tex">\bm{\theta}_{g}^{*}</annotation></semantics></math>, are learned by maximizing this metric:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bm{\theta}_{g}^{*}(\mathcal{F})=\arg\max_{\bm{\theta}_{g}}\mathcal{L}(g(\{\bm{v}_{k,t}\}_{k=1}^{K};\bm{\theta}_{g}),\bm{Y})." class="ltx_Math" display="block" id="S2.E1.m1" intent=":literal"><semantics><mrow><mrow><mrow><msubsup><mi>𝜽</mi><mi>g</mi><mo>∗</mo></msubsup><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><munder><mi>max</mi><msub><mi>𝜽</mi><mi>g</mi></msub></munder><mo lspace="0.167em">⁡</mo><mi class="ltx_font_mathcaligraphic">ℒ</mi></mrow></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>g</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>𝒗</mi><mrow><mi>k</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>;</mo><msub><mi>𝜽</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>𝒀</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\bm{\theta}_{g}^{*}(\mathcal{F})=\arg\max_{\bm{\theta}_{g}}\mathcal{L}(g(\{\bm{v}_{k,t}\}_{k=1}^{K};\bm{\theta}_{g}),\bm{Y}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">Let <math alttext="g^{*}(\mathcal{F})" class="ltx_Math" display="inline" id="S2.SSx1.p2.m10" intent=":literal"><semantics><mrow><msup><mi>g</mi><mo>∗</mo></msup><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">g^{*}(\mathcal{F})</annotation></semantics></math> be the combination model with parameters <math alttext="\bm{\theta}_{g}^{*}(\mathcal{F})" class="ltx_Math" display="inline" id="S2.SSx1.p2.m11" intent=":literal"><semantics><mrow><msubsup><mi>𝜽</mi><mi>g</mi><mo>∗</mo></msubsup><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{\theta}_{g}^{*}(\mathcal{F})</annotation></semantics></math>. The overarching goal is to find an optimal set of alpha factors <math alttext="\mathcal{F}^{*}\subset\mathcal{A}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m12" intent=":literal"><semantics><mrow><msup><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo>∗</mo></msup><mo>⊂</mo><mi class="ltx_font_mathcaligraphic">𝒜</mi></mrow><annotation encoding="application/x-tex">\mathcal{F}^{*}\subset\mathcal{A}</annotation></semantics></math> that maximizes the performance of this optimally combined signal: <math alttext="\mathcal{F}^{*}=\arg\max_{\mathcal{F}\subset\mathcal{A}}\mathcal{L}(g^{*}(\mathcal{F}),\bm{Y})." class="ltx_Math" display="inline" id="S2.SSx1.p2.m13" intent=":literal"><semantics><mrow><mrow><msup><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo>∗</mo></msup><mo>=</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><msub><mi>max</mi><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo>⊂</mo><mi class="ltx_font_mathcaligraphic">𝒜</mi></mrow></msub><mo lspace="0.167em">⁡</mo><mi class="ltx_font_mathcaligraphic">ℒ</mi></mrow></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>g</mi><mo>∗</mo></msup><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>𝒀</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\mathcal{F}^{*}=\arg\max_{\mathcal{F}\subset\mathcal{A}}\mathcal{L}(g^{*}(\mathcal{F}),\bm{Y}).</annotation></semantics></math>
This constitutes a challenging bilevel optimization problem due to the immense search space <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S2.SSx1.p2.m14" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math> and the complex interactions between alpha factors.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="386" id="S2.F2.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x2.png" width="969">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of our LLM-powered MCTS framework. The process begins with node selection via UCT. A refinement dimension is then chosen based on the node’s multi-dimensional evaluation scores. The LLM first proposes a conceptual refinement suggestion for that dimension and then translates it into a concrete formula. The new formula is backtested, and its performance results are used to expand the tree with a new node.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Formulaic Alpha</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SSx2.p1">
<p class="ltx_p">In this work, we focus on <span class="ltx_text ltx_font_italic">formulaic alphas</span>: alpha factors defined by mathematical expressions. These expressions are constructed from operators and operands. Operands typically include raw input features (e.g., <math alttext="\text{close}_{i,t}" class="ltx_Math" display="inline" id="S2.SSx2.p1.m1" intent=":literal"><semantics><msub><mtext>close</mtext><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">\text{close}_{i,t}</annotation></semantics></math>) and numerical constants. Operators apply mathematical transformations; for example, time-series operators can be used to construct an alpha like <math alttext="\text{Ma}(\text{close},5)-\text{Ma}(\text{close},20)" class="ltx_Math" display="inline" id="S2.SSx2.p1.m2" intent=":literal"><semantics><mrow><mrow><mtext>Ma</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mtext>close</mtext><mo>,</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mtext>Ma</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mtext>close</mtext><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{Ma}(\text{close},5)-\text{Ma}(\text{close},20)</annotation></semantics></math>. This specific alpha captures a price trend by contrasting short-term with long-term moving averages of closing prices. A complete list of available operators is provided in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A5.T2" title="Table 2 ‣ Appendix E List of Operators ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">2</span></a>. Formulaic alphas are naturally represented as expression trees (leaf nodes: operands; internal nodes: operators), making their structured yet flexible nature amenable to the automated mining techniques central to our framework.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">Our proposed alpha mining framework integrates LLMs with MCTS to automate the discovery and refinement of alpha factors. The framework’s objective is to search within the vast space of possible alpha formulas, denoted as <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S3.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>, to find a set of high-performing alphas. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S2.F2" title="Figure 2 ‣ Alpha Factor Mining ‣ 2 Preliminary ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">2</span></a> provides a conceptual illustration. The core iterative process involves: (1) selecting a promising node (alpha formula) using the Upper Confidence Bound for Trees (UCT) criterion <cite class="ltx_cite ltx_citemacro_citep">(Kocsis and Szepesvári <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib15" title="">2006</a>)</cite>; (2) expanding this node by having the LLM generate a refined alpha, guided by performance feedback on specific evaluation dimensions; and (3) evaluating the new alpha via backtesting, with results forming a new node in the search tree <math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="S3.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒯</mi><annotation encoding="application/x-tex">\mathcal{T}</annotation></semantics></math> (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3" title="Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">C</span></a> for an illustrative case). The LLM’s role is twofold: first, to propose targeted refinement suggestions, and second, to translate these suggestions into a concrete alpha formula <math alttext="f\in\mathcal{A}" class="ltx_Math" display="inline" id="S3.p1.m3" intent=":literal"><semantics><mrow><mi>f</mi><mo>∈</mo><mi class="ltx_font_mathcaligraphic">𝒜</mi></mrow><annotation encoding="application/x-tex">f\in\mathcal{A}</annotation></semantics></math>. Iteratively, high-performing alphas that satisfy a set of predefined criteria <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S3.p1.m4" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒞</mi><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math> (e.g., <math alttext="\text{IC}&gt;0.02" class="ltx_Math" display="inline" id="S3.p1.m5" intent=":literal"><semantics><mrow><mtext>IC</mtext><mo>&gt;</mo><mn>0.02</mn></mrow><annotation encoding="application/x-tex">\text{IC}&gt;0.02</annotation></semantics></math>) are collected into an effective alpha repository, <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="S3.p1.m6" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SSx1">
<h3 class="ltx_title ltx_title_subsection">Selection</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SSx1.p1">
<p class="ltx_p">The selection step in our MCTS framework navigates the exploration-exploitation trade-off. Each node <math alttext="s\in\mathcal{T}" class="ltx_Math" display="inline" id="S3.SSx1.p1.m1" intent=":literal"><semantics><mrow><mi>s</mi><mo>∈</mo><mi class="ltx_font_mathcaligraphic">𝒯</mi></mrow><annotation encoding="application/x-tex">s\in\mathcal{T}</annotation></semantics></math> represents an alpha, characterized by its formula <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.SSx1.p1.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>s</mi></msub><annotation encoding="application/x-tex">f_{s}</annotation></semantics></math> and refinement history. An action <math alttext="a" class="ltx_Math" display="inline" id="S3.SSx1.p1.m3" intent=":literal"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> corresponds to a specific refinement applied to <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p1.m4" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>. Each state-action pair <math alttext="(s,a)" class="ltx_Math" display="inline" id="S3.SSx1.p1.m5" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s,a)</annotation></semantics></math> maintains a quality value <math alttext="Q(s,a)" class="ltx_Math" display="inline" id="S3.SSx1.p1.m6" intent=":literal"><semantics><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q(s,a)</annotation></semantics></math>, representing the maximum reward (alpha score) observed in the subtree rooted at the child node resulting from this action. We employ the UCT criterion to select the optimal action <math alttext="a^{*}" class="ltx_Math" display="inline" id="S3.SSx1.p1.m7" intent=":literal"><semantics><msup><mi>a</mi><mo>∗</mo></msup><annotation encoding="application/x-tex">a^{*}</annotation></semantics></math>:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="a^{*}=\arg\max_{a\in A(s)}\left(Q(s,a)+c\sqrt{\frac{\ln(N_{s})}{N_{s^{\prime}}}}\right)" class="ltx_Math" display="block" id="S3.E2.m1" intent=":literal"><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup><mo>=</mo><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><munder><mi>max</mi><mrow><mi>a</mi><mo>∈</mo><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></munder><mo>⁡</mo><mrow><mo>(</mo><mrow><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><msqrt><mfrac><mrow><mi>ln</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msub><mi>N</mi><mi>s</mi></msub><mo stretchy="false">)</mo></mrow></mrow><msub><mi>N</mi><msup><mi>s</mi><mo>′</mo></msup></msub></mfrac></msqrt></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">a^{*}=\arg\max_{a\in A(s)}\left(Q(s,a)+c\sqrt{\frac{\ln(N_{s})}{N_{s^{\prime}}}}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="A(s)" class="ltx_Math" display="inline" id="S3.SSx1.p1.m8" intent=":literal"><semantics><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">A(s)</annotation></semantics></math> is the set of existing actions from state <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p1.m9" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, <math alttext="N_{s}" class="ltx_Math" display="inline" id="S3.SSx1.p1.m10" intent=":literal"><semantics><msub><mi>N</mi><mi>s</mi></msub><annotation encoding="application/x-tex">N_{s}</annotation></semantics></math> is the visit count of the parent state <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p1.m11" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, <math alttext="N_{s^{\prime}}" class="ltx_Math" display="inline" id="S3.SSx1.p1.m12" intent=":literal"><semantics><msub><mi>N</mi><msup><mi>s</mi><mo>′</mo></msup></msub><annotation encoding="application/x-tex">N_{s^{\prime}}</annotation></semantics></math> is the visit count of the child state <math alttext="s^{\prime}=\text{child}(s,a)" class="ltx_Math" display="inline" id="S3.SSx1.p1.m13" intent=":literal"><semantics><mrow><msup><mi>s</mi><mo>′</mo></msup><mo>=</mo><mrow><mtext>child</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">s^{\prime}=\text{child}(s,a)</annotation></semantics></math>, and <math alttext="c" class="ltx_Math" display="inline" id="S3.SSx1.p1.m14" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> is the exploration weight.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SSx1.p2">
<p class="ltx_p">Unlike standard MCTS, which expands only leaf nodes, our approach allows any node to be selected for expansion. This is crucial for iteratively refining promising, but not terminal, alpha ideas. To enable this, we augment the action space <math alttext="A(s)" class="ltx_Math" display="inline" id="S3.SSx1.p2.m1" intent=":literal"><semantics><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">A(s)</annotation></semantics></math> at any internal node <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p2.m2" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> with a “virtual” expansion action, <math alttext="a_{e}" class="ltx_Math" display="inline" id="S3.SSx1.p2.m3" intent=":literal"><semantics><msub><mi>a</mi><mi>e</mi></msub><annotation encoding="application/x-tex">a_{e}</annotation></semantics></math>. The selection process thus considers the full action set <math alttext="A(s)\cup\{a_{e}\}" class="ltx_Math" display="inline" id="S3.SSx1.p2.m4" intent=":literal"><semantics><mrow><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><mo>∪</mo><mrow><mo stretchy="false">{</mo><msub><mi>a</mi><mi>e</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">A(s)\cup\{a_{e}\}</annotation></semantics></math>. The UCT score for this virtual action is computed by adapting Equation&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E2" title="In Selection ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">2</span></a>, where we define a virtual visit count for the prospective new node <math alttext="s^{\prime}_{e}" class="ltx_Math" display="inline" id="S3.SSx1.p2.m5" intent=":literal"><semantics><msubsup><mi>s</mi><mi>e</mi><mo>′</mo></msubsup><annotation encoding="application/x-tex">s^{\prime}_{e}</annotation></semantics></math> as <math alttext="N_{s^{\prime}_{e}}=1+|C(s)|" class="ltx_Math" display="inline" id="S3.SSx1.p2.m6" intent=":literal"><semantics><mrow><msub><mi>N</mi><msubsup><mi>s</mi><mi>e</mi><mo>′</mo></msubsup></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mo stretchy="false">|</mo><mrow><mi>C</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">|</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">N_{s^{\prime}_{e}}=1+|C(s)|</annotation></semantics></math>, with <math alttext="C(s)" class="ltx_Math" display="inline" id="S3.SSx1.p2.m7" intent=":literal"><semantics><mrow><mi>C</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">C(s)</annotation></semantics></math> being the set of existing children of <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p2.m8" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>. If <math alttext="a_{e}" class="ltx_Math" display="inline" id="S3.SSx1.p2.m9" intent=":literal"><semantics><msub><mi>a</mi><mi>e</mi></msub><annotation encoding="application/x-tex">a_{e}</annotation></semantics></math> is selected, node <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx1.p2.m10" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> is chosen for expansion. This mechanism ensures that promising, non-leaf nodes can be further refined.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx2">
<h3 class="ltx_title ltx_title_subsection">Expansion</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SSx2.p1">
<p class="ltx_p">Upon selecting a node <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx2.p1.m1" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> for expansion, a new, refined alpha factor <math alttext="f_{new}" class="ltx_Math" display="inline" id="S3.SSx2.p1.m2" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">f_{new}</annotation></semantics></math> is generated. This process is structured to enhance the LLM’s effectiveness and the quality of refinements.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SSx2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Dimension-Targeted Refinement Suggestion.</span> Each node <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx2.p2.m1" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> is associated with a multi-dimensional evaluation score vector <math alttext="\bm{E}_{s}=[e_{1},\dots,e_{q}]\in[0,e_{\text{max}}]^{q}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m2" intent=":literal"><semantics><mrow><msub><mi>𝑬</mi><mi>s</mi></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>e</mi><mi>q</mi></msub><mo stretchy="false">]</mo></mrow><mo>∈</mo><msup><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><msub><mi>e</mi><mtext>max</mtext></msub><mo stretchy="false">]</mo></mrow><mi>q</mi></msup></mrow><annotation encoding="application/x-tex">\bm{E}_{s}=[e_{1},\dots,e_{q}]\in[0,e_{\text{max}}]^{q}</annotation></semantics></math>. To guide refinement towards areas of weakness while maintaining explorative diversity, we stochastically select a target dimension <math alttext="i^{*}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m3" intent=":literal"><semantics><msup><mi>i</mi><mo>∗</mo></msup><annotation encoding="application/x-tex">i^{*}</annotation></semantics></math> for improvement. The probability of choosing dimension <math alttext="i" class="ltx_Math" display="inline" id="S3.SSx2.p2.m4" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> is defined as:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(i^{*}=i|s)=\text{Softmax}\left((e_{\text{max}}\cdot\bm{1}_{q}-\bm{E}_{s})/T\right)_{i}" class="ltx_Math" display="block" id="S3.E3.m1" intent=":literal"><semantics><mrow><mrow><mi>P</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>i</mi><mo>∗</mo></msup><mo>=</mo><mrow><mi>i</mi><mo fence="false">|</mo><mi>s</mi></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mtext>Softmax</mtext><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo>(</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mrow><msub><mi>e</mi><mtext>max</mtext></msub><mo lspace="0.222em" rspace="0.222em">⋅</mo><msub><mn>𝟏</mn><mi>q</mi></msub></mrow><mo>−</mo><msub><mi>𝑬</mi><mi>s</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mo>/</mo><mi>T</mi></mrow><mo>)</mo></mrow><mi>i</mi></msub></mrow></mrow><annotation encoding="application/x-tex">P(i^{*}=i|s)=\text{Softmax}\left((e_{\text{max}}\cdot\bm{1}_{q}-\bm{E}_{s})/T\right)_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\bm{1}_{q}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m5" intent=":literal"><semantics><msub><mn>𝟏</mn><mi>q</mi></msub><annotation encoding="application/x-tex">\bm{1}_{q}</annotation></semantics></math> is a <math alttext="q" class="ltx_Math" display="inline" id="S3.SSx2.p2.m6" intent=":literal"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>-dimensional vector of ones and <math alttext="T" class="ltx_Math" display="inline" id="S3.SSx2.p2.m7" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> is a temperature parameter. This strategy prioritizes dimensions with lower scores. Once a dimension <math alttext="i^{*}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m8" intent=":literal"><semantics><msup><mi>i</mi><mo>∗</mo></msup><annotation encoding="application/x-tex">i^{*}</annotation></semantics></math> is selected, the LLM generates a textual refinement suggestion <math alttext="d_{s,i^{*}}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m9" intent=":literal"><semantics><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><annotation encoding="application/x-tex">d_{s,i^{*}}</annotation></semantics></math> aimed at improving performance on that dimension. This is framed as a few-shot learning task, where the context includes effective alphas from <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="S3.SSx2.p2.m10" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math> (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4" title="Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">D</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SSx2.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Alpha Formula Generation and Validation.</span> Following the targeted suggestion, we employ a two-step generation process. First, the LLM articulates the refined conceptual hypothesis, which is then used to prompt the generation of the concrete formula. This process, ensuring the formula aligns with a clear investment rationale, can be formalized as:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A11.EGx1">
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle d_{s,i^{*}}" class="ltx_Math" display="inline" id="S3.E4.m1" intent=":literal"><semantics><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><annotation encoding="application/x-tex">\displaystyle d_{s,i^{*}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\sim p_{\text{LLM}}(\cdot|s,i^{*},\mathcal{F}_{zoo})" class="ltx_math_unparsed" display="inline" id="S3.E4.m2" intent=":literal"><semantics><mrow><mo>∼</mo><msub><mi>p</mi><mtext>LLM</mtext></msub><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\sim p_{\text{LLM}}(\cdot|s,i^{*},\mathcal{F}_{zoo})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle f_{new}" class="ltx_Math" display="inline" id="S3.E5.m1" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">\displaystyle f_{new}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\sim p_{\text{LLM}}(\cdot|d_{s,i^{*}},f_{s})" class="ltx_math_unparsed" display="inline" id="S3.E5.m2" intent=":literal"><semantics><mrow><mo>∼</mo><msub><mi>p</mi><mtext>LLM</mtext></msub><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo fence="false" rspace="0.167em" stretchy="false">|</mo><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><mo>,</mo><msub><mi>f</mi><mi>s</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\sim p_{\text{LLM}}(\cdot|d_{s,i^{*}},f_{s})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">The generated formula <math alttext="f_{new}" class="ltx_Math" display="inline" id="S3.SSx2.p3.m1" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">f_{new}</annotation></semantics></math> undergoes an automated validation check, <math alttext="\text{IsValid}(f_{new})" class="ltx_Math" display="inline" id="S3.SSx2.p3.m2" intent=":literal"><semantics><mrow><mtext>IsValid</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{IsValid}(f_{new})</annotation></semantics></math>. If invalid, feedback is provided to the LLM for iterative correction. A valid formula and its evaluation results constitute the new node <math alttext="s_{new}" class="ltx_Math" display="inline" id="S3.SSx2.p3.m3" intent=":literal"><semantics><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">s_{new}</annotation></semantics></math> in the MCTS tree.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx3">
<h3 class="ltx_title ltx_title_subsection">Multi-Dimensional Alpha Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SSx3.p1">
<p class="ltx_p">The evaluation of a candidate alpha <math alttext="f" class="ltx_Math" display="inline" id="S3.SSx3.p1.m1" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is performed directly via backtesting, bypassing the simulation phase of traditional MCTS. A key challenge is the evolving nature of the effective alpha repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="S3.SSx3.p1.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math>, which progressively raises the bar for new alphas. To address this, we employ a relative ranking approach. The rank of <math alttext="f" class="ltx_Math" display="inline" id="S3.SSx3.p1.m3" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> against the repository for a given metric <math alttext="m" class="ltx_Math" display="inline" id="S3.SSx3.p1.m4" intent=":literal"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> is:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R(f,m,\mathcal{F}_{zoo})=\frac{1}{|\mathcal{F}_{zoo}|}\sum_{f^{\prime}\in\mathcal{F}_{zoo}}\mathbb{I}(m(f)&lt;m(f^{\prime}))" class="ltx_Math" display="block" id="S3.E6.m1" intent=":literal"><semantics><mrow><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo>,</mo><mi>m</mi><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munder><mo movablelimits="false">∑</mo><mrow><msup><mi>f</mi><mo>′</mo></msup><mo>∈</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub></mrow></munder><mrow><mi>𝕀</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><mo>&lt;</mo><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>f</mi><mo>′</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">R(f,m,\mathcal{F}_{zoo})=\frac{1}{|\mathcal{F}_{zoo}|}\sum_{f^{\prime}\in\mathcal{F}_{zoo}}\mathbb{I}(m(f)&lt;m(f^{\prime}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathbb{I}(\cdot)" class="ltx_Math" display="inline" id="S3.SSx3.p1.m5" intent=":literal"><semantics><mrow><mi>𝕀</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbb{I}(\cdot)</annotation></semantics></math> is the indicator function. This provides an adaptive evaluation criterion, avoiding fixed thresholds that may be too stringent early on or too lenient later.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SSx3.p2">
<p class="ltx_p">To provide granular feedback for refinement, we evaluate <math alttext="f" class="ltx_Math" display="inline" id="S3.SSx3.p2.m1" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> across a set of <math alttext="q" class="ltx_Math" display="inline" id="S3.SSx3.p2.m2" intent=":literal"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> dimensions <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SSx3.p2.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒟</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math>, exemplified here by <span class="ltx_text ltx_font_bold">Effectiveness</span>, <span class="ltx_text ltx_font_bold">Stability</span>, <span class="ltx_text ltx_font_bold">Turnover</span>, <span class="ltx_text ltx_font_bold">Diversity</span>, and <span class="ltx_text ltx_font_bold">Overfitting Risk</span> (detailed in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4" title="Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">D</span></a>). For each dimension <math alttext="D_{i}\in\mathcal{D}\setminus\{\text{Overfitting Risk}\}" class="ltx_Math" display="inline" id="S3.SSx3.p2.m4" intent=":literal"><semantics><mrow><msub><mi>D</mi><mi>i</mi></msub><mo>∈</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo>∖</mo><mrow><mo stretchy="false">{</mo><mtext>Overfitting Risk</mtext><mo stretchy="false">}</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">D_{i}\in\mathcal{D}\setminus\{\text{Overfitting Risk}\}</annotation></semantics></math>, we compute a score <math alttext="e_{i}" class="ltx_Math" display="inline" id="S3.SSx3.p2.m5" intent=":literal"><semantics><msub><mi>e</mi><mi>i</mi></msub><annotation encoding="application/x-tex">e_{i}</annotation></semantics></math> based on its percentile rank using a corresponding metric <math alttext="m_{i}" class="ltx_Math" display="inline" id="S3.SSx3.p2.m6" intent=":literal"><semantics><msub><mi>m</mi><mi>i</mi></msub><annotation encoding="application/x-tex">m_{i}</annotation></semantics></math>:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="e_{i}(f)=1-R(f,m_{i},\mathcal{F}_{zoo})" class="ltx_Math" display="block" id="S3.E7.m1" intent=":literal"><semantics><mrow><mrow><msub><mi>e</mi><mi>i</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>−</mo><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo>,</mo><msub><mi>m</mi><mi>i</mi></msub><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">e_{i}(f)=1-R(f,m_{i},\mathcal{F}_{zoo})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">The assessment of <span class="ltx_text ltx_font_bold">Overfitting Risk</span>, denoted <math alttext="e_{\text{overfit}}" class="ltx_Math" display="inline" id="S3.SSx3.p2.m7" intent=":literal"><semantics><msub><mi>e</mi><mtext>overfit</mtext></msub><annotation encoding="application/x-tex">e_{\text{overfit}}</annotation></semantics></math>, is distinct. We leverage an LLM that analyzes the formula <math alttext="f" class="ltx_Math" display="inline" id="S3.SSx3.p2.m8" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> and its refinement history <math alttext="H(s)" class="ltx_Math" display="inline" id="S3.SSx3.p2.m9" intent=":literal"><semantics><mrow><mi>H</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">H(s)</annotation></semantics></math>, providing a qualitative judgment: <math alttext="e_{\text{overfit}}=\text{LLM}_{\text{eval}}(f,H(s))" class="ltx_Math" display="inline" id="S3.SSx3.p2.m10" intent=":literal"><semantics><mrow><msub><mi>e</mi><mtext>overfit</mtext></msub><mo>=</mo><mrow><msub><mtext>LLM</mtext><mtext>eval</mtext></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo>,</mo><mrow><mi>H</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">e_{\text{overfit}}=\text{LLM}_{\text{eval}}(f,H(s))</annotation></semantics></math> (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.SSx3" title="Alpha Overfitting Risk Assessment Prompt ‣ Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">K</span></a> for the specific prompt). The overall alpha score, which serves as the reward signal for MCTS, is the aggregate of these dimensional scores:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(f)=\frac{1}{|\mathcal{D}|}\sum_{i=1}^{q}e_{i}(f)" class="ltx_Math" display="block" id="S3.E8.m1" intent=":literal"><semantics><mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo stretchy="false">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>q</mi></munderover><mrow><msub><mi>e</mi><mi>i</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">S(f)=\frac{1}{|\mathcal{D}|}\sum_{i=1}^{q}e_{i}(f)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">This score <math alttext="S(f)" class="ltx_Math" display="inline" id="S3.SSx3.p2.m11" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(f)</annotation></semantics></math> is used to update the Q-values in the search tree.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx4">
<h3 class="ltx_title ltx_title_subsection">Backpropagation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SSx4.p1">
<p class="ltx_p">During backpropagation, the reward <math alttext="S(f_{new})" class="ltx_Math" display="inline" id="S3.SSx4.p1.m1" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(f_{new})</annotation></semantics></math> of the newly evaluated alpha at node <math alttext="s_{new}" class="ltx_Math" display="inline" id="S3.SSx4.p1.m2" intent=":literal"><semantics><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">s_{new}</annotation></semantics></math> updates the statistics of all nodes along the path from the root to its parent. For each ancestor node <math alttext="s_{k}" class="ltx_Math" display="inline" id="S3.SSx4.p1.m3" intent=":literal"><semantics><msub><mi>s</mi><mi>k</mi></msub><annotation encoding="application/x-tex">s_{k}</annotation></semantics></math> on this path, leading to its child <math alttext="s_{k+1}" class="ltx_Math" display="inline" id="S3.SSx4.p1.m4" intent=":literal"><semantics><msub><mi>s</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">s_{k+1}</annotation></semantics></math> via action <math alttext="a_{k}" class="ltx_Math" display="inline" id="S3.SSx4.p1.m5" intent=":literal"><semantics><msub><mi>a</mi><mi>k</mi></msub><annotation encoding="application/x-tex">a_{k}</annotation></semantics></math>, we perform the following updates:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A11.EGx2">
<tbody id="S3.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle N_{s_{k}}" class="ltx_Math" display="inline" id="S3.E9.m1" intent=":literal"><semantics><msub><mi>N</mi><msub><mi>s</mi><mi>k</mi></msub></msub><annotation encoding="application/x-tex">\displaystyle N_{s_{k}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow N_{s_{k}}+1" class="ltx_Math" display="inline" id="S3.E9.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>N</mi><msub><mi>s</mi><mi>k</mi></msub></msub><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow N_{s_{k}}+1</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
<tbody id="S3.E10"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Q(s_{k},a_{k})" class="ltx_Math" display="inline" id="S3.E10.m1" intent=":literal"><semantics><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mi>k</mi></msub><mo>,</mo><msub><mi>a</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle Q(s_{k},a_{k})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow\max(Q(s_{k},a_{k}),S(f_{new}))" class="ltx_Math" display="inline" id="S3.E10.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mi>k</mi></msub><mo>,</mo><msub><mi>a</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow\max(Q(s_{k},a_{k}),S(f_{new}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">This ensures that the value of a path reflects the best outcome discovered within its entire subtree. Crucially, to enhance the quality of subsequent refinement suggestions and the accuracy of overfitting assessment, the LLM is provided with rich contextual information: the refinement history of the current node’s parent, children, and siblings. This allows the LLM to analyze the refinement trajectory and avoid redundant suggestions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="706" id="S3.F3.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x3.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of the Frequent Subtree Avoidance (FSA). The set of effective alphas from the Alpha Repository is mined for frequent subtrees. The most frequent ones are identified, and the LLM is subsequently instructed to avoid generating new formulas containing these common structural motifs.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S3.SSx5">
<h3 class="ltx_title ltx_title_subsection">Frequent Subtree Avoidance</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SSx5.p1">
<p class="ltx_p">To mitigate alpha formula homogenization and prevent the over-exploitation of common motifs, we introduce Frequent Subtree Avoidance (FSA), inspired by the concept of “root genes” in AutoAlpha <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib43" title="">2020</a>)</cite>. We define a <span class="ltx_text ltx_font_italic">root gene</span> as a subtree in an alpha’s expression tree whose leaves are exclusively raw input features (e.g., ‘close’, ‘high’). To focus on structure, we use an operator <math alttext="\text{Abs}(\cdot)" class="ltx_Math" display="inline" id="S3.SSx5.p1.m1" intent=":literal"><semantics><mrow><mtext>Abs</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Abs}(\cdot)</annotation></semantics></math> that abstracts away concrete parameter values from an expression tree. For instance, <math alttext="\text{Abs}(\text{Ma}(\text{vwap},20))" class="ltx_Math" display="inline" id="S3.SSx5.p1.m2" intent=":literal"><semantics><mrow><mtext>Abs</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mtext>Ma</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mtext>vwap</mtext><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Abs}(\text{Ma}(\text{vwap},20))</annotation></semantics></math> becomes <math alttext="\text{Ma}(\text{vwap},t)" class="ltx_Math" display="inline" id="S3.SSx5.p1.m3" intent=":literal"><semantics><mrow><mtext>Ma</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mtext>vwap</mtext><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Ma}(\text{vwap},t)</annotation></semantics></math>. The set of abstracted root genes for an alpha <math alttext="f" class="ltx_Math" display="inline" id="S3.SSx5.p1.m4" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is denoted <math alttext="\bar{\mathcal{G}}(f)" class="ltx_Math" display="inline" id="S3.SSx5.p1.m5" intent=":literal"><semantics><mrow><mover accent="true"><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo>¯</mo></mover><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bar{\mathcal{G}}(f)</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SSx5.p2">
<p class="ltx_p">The FSA mechanism operates by first identifying frequent closed root genes from the repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="S3.SSx5.p2.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math>. A root gene is “closed” if none of its immediate supertrees share the same support count, which helps identify maximal common patterns. The support for an abstracted root gene <math alttext="\bar{g}" class="ltx_Math" display="inline" id="S3.SSx5.p2.m2" intent=":literal"><semantics><mover accent="true"><mi>g</mi><mo>¯</mo></mover><annotation encoding="application/x-tex">\bar{g}</annotation></semantics></math> is:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E11">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Support}(\bar{g})=\frac{1}{|\mathcal{F}_{zoo}|}\sum_{f^{\prime}\in\mathcal{F}_{zoo}}\mathbb{I}(\bar{g}\subseteq\bar{\mathcal{G}}(f^{\prime}))" class="ltx_Math" display="block" id="S3.E11.m1" intent=":literal"><semantics><mrow><mrow><mtext>Support</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munder><mo movablelimits="false">∑</mo><mrow><msup><mi>f</mi><mo>′</mo></msup><mo>∈</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub></mrow></munder><mrow><mi>𝕀</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mover accent="true"><mi>g</mi><mo>¯</mo></mover><mo>⊆</mo><mrow><mover accent="true"><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo>¯</mo></mover><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>f</mi><mo>′</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{Support}(\bar{g})=\frac{1}{|\mathcal{F}_{zoo}|}\sum_{f^{\prime}\in\mathcal{F}_{zoo}}\mathbb{I}(\bar{g}\subseteq\bar{\mathcal{G}}(f^{\prime}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">We select the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SSx5.p2.m3" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> most frequent closed root genes to form a set of forbidden structures, <math alttext="\mathcal{G}_{\text{forbidden}}" class="ltx_Math" display="inline" id="S3.SSx5.p2.m4" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub><annotation encoding="application/x-tex">\mathcal{G}_{\text{forbidden}}</annotation></semantics></math>. During generation (Eq.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E5" title="In Expansion ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">5</span></a>), the LLM is constrained to produce a new formula <math alttext="f_{new}" class="ltx_Math" display="inline" id="S3.SSx5.p2.m5" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">f_{new}</annotation></semantics></math> that avoids these motifs:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E12">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Constraint: }\bar{\mathcal{G}}(f_{new})\cap\mathcal{G}_{\text{forbidden}}=\emptyset" class="ltx_Math" display="block" id="S3.E12.m1" intent=":literal"><semantics><mrow><mrow><mrow><mtext>Constraint:&nbsp;</mtext><mo lspace="0em" rspace="0em">​</mo><mover accent="true"><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo>¯</mo></mover><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>∩</mo><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub></mrow><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">\text{Constraint: }\bar{\mathcal{G}}(f_{new})\cap\mathcal{G}_{\text{forbidden}}=\emptyset</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">FSA acts as a regularization on the generation process. By discouraging common structures, it guides the MCTS search towards more structurally diverse and potentially novel regions of the alpha space <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S3.SSx5.p2.m6" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>, enabling a more efficient exploration, as demonstrated in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.SSx3" title="Experiment 2: Ablation Study ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p">We evaluate our proposed framework on real-world stock market data, addressing the following research questions (RQs):
<br class="ltx_break"><span class="ltx_text ltx_font_bold">Q1</span>: How does our approach compare to baselines in predictive performance? 
<br class="ltx_break"><span class="ltx_text ltx_font_bold">Q2</span>: Are MCTS and Frequent Subtree Avoidance effective components within our framework? 
<br class="ltx_break"><span class="ltx_text ltx_font_bold">Q3</span>: How does the interpretability of alpha formulas mined by our method compare to others?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SSx1">
<h3 class="ltx_title ltx_title_subsection">Experiment Settings</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SSx1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Data</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx1.SSS0.Px1.p1">
<p class="ltx_p">Our experiments are conducted on the Chinese A-shares market. To ensure comprehensive market representation, our experiments separately target two stock pools: the CSI 300 Index (large-cap, liquid stocks) and the CSI 1000 Index (small to mid-cap stocks). We define two distinct prediction targets: the 10-day return and the 30-day return of the stocks, with buying and selling executed at the closing price. The dataset is split chronologically into training (2011/01/01–2020/12/31) and testing (2021/01/01–2024/11/30) periods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SSx1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Baselines for Comparison</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx1.SSS0.Px2.p1">
<p class="ltx_p">We compare our framework with several formulaic alpha mining methods. <span class="ltx_text ltx_font_bold">DSO</span> (Deep Symbolic Optimization) <cite class="ltx_cite ltx_citemacro_citep">(Landajuela et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib17" title="">2022</a>)</cite> is a deep learning framework for symbolic optimization. <span class="ltx_text ltx_font_bold">GP</span> employs genetic programming for alpha mining. <span class="ltx_text ltx_font_bold">AlphaGen</span> <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib39" title="">2023</a>)</cite> is a reinforcement learning framework for formulaic alpha mining. <span class="ltx_text ltx_font_bold">AlphaForge</span> <cite class="ltx_cite ltx_citemacro_citep">(Shi et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib24" title="">2024</a>)</cite> features a generative-predictive architecture; to ensure a fair comparison of generative capabilities, we use only its alpha mining network. Among LLM-based approaches, <span class="ltx_text ltx_font_bold">CoT</span> (Chain-of-Thought) <cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib32" title="">2022</a>)</cite> prompts LLMs for step-by-step reasoning to directly generate alpha factors. <span class="ltx_text ltx_font_bold">ToT</span> (Tree-of-Thought) <cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib38" title="">2024</a>)</cite> enables LLMs to explore diverse reasoning paths in a tree structure. Lastly, <span class="ltx_text ltx_font_bold">FAMA</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib20" title="">2024b</a>)</cite> leverages LLMs with in-context examples to diversify formulas and a “chain-of-experience” to learn from past successes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SSx1.SSS0.Px2.p2">
<p class="ltx_p">We use OpenAI’s GPT4.1 model as the LLM for both our method and the LLM-based baselines. Furthermore, we evaluate the performance of our framework when using different LLM backbones, as detailed in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx4" title="Sensitivity Analysis of LLM Backbone Choice ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>. Regarding the potential data leakage issue in LLMs, please refer to the discussion in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx3" title="Investigation of Potential Data Leakage in LLMs ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SSx1.SSS0.Px2.p3">
<p class="ltx_p">To ensure a fair and rigorous comparison of algorithmic efficiency, we benchmark all methods based on a controlled “search count” (i.e., the number of unique alpha formulas generated and evaluated). This metric normalizes for the vast differences in computational cost per generation step across methods (e.g., a single LLM call vs. a GP mutation) and provides a direct measure of search space exploration efficiency. This approach is well-suited because our framework and all baselines inherently involve a distinct search process, where each iteration yields a new candidate alpha formula.
For LLM-based methods (including ours), we report the best performance achieved with search counts of 1,000, 2,000, or 3,000.
For other methods, the search count is incrementally increased from a small value until performance converges, capped at 600,000 (200<math alttext="\times" class="ltx_Math" display="inline" id="S4.SSx1.SSS0.Px2.p3.m1" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math> the LLM-based methods’ maximum).
This experimental design facilitates two key comparisons: first, it allows for an equitable assessment of our framework against other LLM-based methods under similar, well-defined computational budgets; second, it enables a robust comparison of search efficiency against other non-LLM-based methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="678" id="S4.F4.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The average predictive performance of LightGBM and MLP models trained on alphas mined by different methods.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S4.SSx2">
<h3 class="ltx_title ltx_title_subsection">Experiment 1: Prediction Performance Comparison</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx2.p1">
<p class="ltx_p">We evaluate the predictive performance of alphas generated by our method against baselines. To comprehensively assess the effectiveness of the generated alpha sets, we employ two representative machine learning models: LightGBM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ke et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib14" title="">2017</a>)</cite>, a popular gradient boosting framework known for its efficiency, and a 3-layer Multi-Layer Perceptron (MLP), which can capture complex non-linear relationships.
For each alpha generation method, we create alpha sets of three distinct sizes—10, 50, and 100—to serve as input features for these models. This allows for a thorough comparison of the mined alpha sets across varying sizes.
Both input alphas and target returns undergo cross-sectional rank normalization before training to mitigate outlier influence.
The predictive power of the alphas is evaluated using two standard metrics in quantitative finance: the Information Coefficient (IC) and the Rank Information Coefficient (RankIC).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Ablation study of our framework’s components.
Best results are highlighted in <span class="ltx_text ltx_font_bold">bold</span>. We ablate across five evaluation dimensions: Effectiveness (Eff.), Diversity (Div.), Turnover (Turn.), Stability (Stab.), and Overfitting Risk (O.R.). The checkmark (✓) indicates a dimension is included in the search, while the cross (×) indicates it is not.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:102.2pt;vertical-align:-49.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.9pt,9.7pt) scale(0.840652068371567,0.840652068371567) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">Search Strategy</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5">Included Evaluation Dimensions</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4">LightGBM</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4">MLP</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">Eff.</td>
<td class="ltx_td ltx_align_center ltx_border_t">Div.</td>
<td class="ltx_td ltx_align_center ltx_border_t">Turn.</td>
<td class="ltx_td ltx_align_center ltx_border_t">Stab.</td>
<td class="ltx_td ltx_align_center ltx_border_t">O.R.</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AER</td>
<td class="ltx_td ltx_align_center ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AER</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t">×</td>
<td class="ltx_td ltx_align_center ltx_border_t">×</td>
<td class="ltx_td ltx_align_center ltx_border_t">×</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0434</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0395</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0707</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.7461</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0421</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0393</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0922</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.9962</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">ToT</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">0.0459</td>
<td class="ltx_td ltx_align_center">0.0427</td>
<td class="ltx_td ltx_align_center">0.0868</td>
<td class="ltx_td ltx_align_center">0.9337</td>
<td class="ltx_td ltx_align_center">0.0452</td>
<td class="ltx_td ltx_align_center">0.0435</td>
<td class="ltx_td ltx_align_center">0.0945</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0348</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">MCTS</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">0.0409</td>
<td class="ltx_td ltx_align_center">0.0374</td>
<td class="ltx_td ltx_align_center">0.0941</td>
<td class="ltx_td ltx_align_center">0.9775</td>
<td class="ltx_td ltx_align_center">0.0400</td>
<td class="ltx_td ltx_align_center">0.0376</td>
<td class="ltx_td ltx_align_center">0.0935</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0010</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">MCTS</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">0.0501</td>
<td class="ltx_td ltx_align_center">0.0476</td>
<td class="ltx_td ltx_align_center">0.1003</td>
<td class="ltx_td ltx_align_center">1.0106</td>
<td class="ltx_td ltx_align_center">0.0486</td>
<td class="ltx_td ltx_align_center">0.0462</td>
<td class="ltx_td ltx_align_center">0.1023</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0462</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">MCTS</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">0.0492</td>
<td class="ltx_td ltx_align_center">0.0457</td>
<td class="ltx_td ltx_align_center">0.1063</td>
<td class="ltx_td ltx_align_center">1.1062</td>
<td class="ltx_td ltx_align_center">0.0489</td>
<td class="ltx_td ltx_align_center">0.0462</td>
<td class="ltx_td ltx_align_center">0.1185</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.2556</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">MCTS</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">×</td>
<td class="ltx_td ltx_align_center">0.0495</td>
<td class="ltx_td ltx_align_center">0.0462</td>
<td class="ltx_td ltx_align_center">0.1030</td>
<td class="ltx_td ltx_align_center">1.0331</td>
<td class="ltx_td ltx_align_center">0.0491</td>
<td class="ltx_td ltx_align_center">0.0465</td>
<td class="ltx_td ltx_align_center">0.1093</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.1773</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">MCTS</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_center">0.0515</td>
<td class="ltx_td ltx_align_center">0.0479</td>
<td class="ltx_td ltx_align_center">0.1075</td>
<td class="ltx_td ltx_align_center">1.1121</td>
<td class="ltx_td ltx_align_center">0.0503</td>
<td class="ltx_td ltx_align_center">0.0478</td>
<td class="ltx_td ltx_align_center">0.1166</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.2127</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">MCTS+FSA</td>
<td class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.0549</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.0512</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.1107</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">1.1792</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.0522</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.0503</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.1234</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">1.2712</span></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx2.p2">
<p class="ltx_p">To assess the practical profitability of the mined alphas in simulated real-world stock market scenarios, we follow established evaluation methodologies <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib39" title="">2023</a>)</cite> and conduct backtests. Specifically, we employ a top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SSx2.p2.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>/drop-<math alttext="n" class="ltx_Math" display="inline" id="S4.SSx2.p2.m2" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> portfolio construction strategy, implemented on the Qlib platform <cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib36" title="">2020</a>)</cite>. The detailed configuration of this strategy is described in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.SSx4" title="Backtesting Strategy ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">G</span></a>. The practical trading performance is evaluated using two key metrics: Annualized Excess Return (AER), which measures the strategy’s profitability, and Information Ratio (IR), which quantifies its risk-adjusted performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SSx2.p3">
<p class="ltx_p">The combination of these four metrics (IC, RankIC, AER, and IR) provides a comprehensive evaluation of the mined alphas.
As illustrated in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.F4" title="Figure 4 ‣ Baselines for Comparison ‣ Experiment Settings ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">4</span></a> (with detailed results presented in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9" title="Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">I</span></a>), our framework consistently outperforms baselines across all metrics.
This demonstrates that the alphas mined by our framework possess superior predictive capabilities for future stock returns, which can be effectively translated into trading profitability. These findings are further corroborated by our experiments on the U.S. stock market, with detailed results presented in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx2" title="Additional Results on the U.S. Stock Market ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="662" id="S4.F5.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x5.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Analysis of search dynamics. (a, b) Alpha mining efficiency, measured as the count of effective alphas found versus total generated. (c, d) Average in-sample and out-of-sample RankIC of the top 50 alphas over generations.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SSx3">
<h3 class="ltx_title ltx_title_subsection">Experiment 2: Ablation Study</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx3.p1">
<p class="ltx_p">We conduct ablation studies to evaluate three key components of our framework: MCTS, multi-dimensional feedback, and FSA.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SSx3.p2">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.T1" title="Table 1 ‣ Experiment 1: Prediction Performance Comparison ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">1</span></a> presents the impact of these components on predictive performance.
When incorporating Effectiveness and Diversity as feedback, MCTS demonstrates superior predictive performance over CoT and ToT.
Performance progressively improves with the integration of additional feedback dimensions. Notably, while Turnover feedback slightly reduces IC and RankIC, it enhances practical trading metrics (AER, IR) by mitigating transaction costs.
The integration of FSA yields further improvements across all metrics for both LightGBM and MLP models.
These results underscore the individual and collective contributions of MCTS, multi-dimensional feedback, and FSA to our framework’s efficacy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SSx3.p3">
<p class="ltx_p">Beyond predictive performance, we analyze the search dynamics in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.F5" title="Figure 5 ‣ Experiment 1: Prediction Performance Comparison ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">5</span></a>. Subplots (a) and (b) assess search efficiency by plotting the number of effective alphas mined against the total generated alphas. Our framework, even without FSA, demonstrates higher search efficiency than other LLM-based methods. FSA further amplifies this advantage. Furthermore, subplots (c) and (d) evaluate the quality and generalization of the top 50 alphas (selected by in-sample RankIC) over generations. The in-sample performance of our method’s alphas improves as the search progresses (c). More importantly, this improvement translates to superior out-of-sample performance (d), indicating that our framework discovers more generalizable alphas compared to baselines.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="628" id="S4.F6.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x6.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Cost-performance analysis across various methods. The plot shows Annualized Excess Return (AER) vs. Annualized Volatility (lower is better). Bubble size indicates the estimated single-run cost. Dashed lines represent constant Information Ratio (IR) levels.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx3.p4">
<p class="ltx_p">To establish a more standardized and equitable basis for comparison, we present a cost-performance analysis in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.F6" title="Figure 6 ‣ Experiment 2: Ablation Study ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">6</span></a>. We estimate the cost of a single experimental run for each method by unifying its runtime and API usage into a monetary value based on public cloud computing prices (detailed in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx9" title="Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>).
The analysis reveals that our framework achieves a favorable risk-return profile, with its variants occupying the highest Information Ratio (IR) contours.
Notably, the overall cost and performance of our framework are primarily driven by the choice of the underlying LLM.
For instance, employing a lightweight model like Gemini-2.0-flash-lite yields a high IR of 1.27 at a minimal cost of $7.5.
In contrast, using the more powerful GPT-4.1 results in a slightly lower IR of 1.23 at a substantially higher cost of $74.4.
This highlights that our framework offers the flexibility to select an appropriate LLM, enabling a desirable balance between performance and computational budget.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx4">
<h3 class="ltx_title ltx_title_subsection">Experiment 3: Interpretablitity of Alpha Formulas</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx4.p1">
<p class="ltx_p">In this experiment, we evaluate the interpretability of alpha formulas mined by different methods. We define the interpretability of an alpha formula by its capacity to articulate a reasonable logic, a specific market phenomenon, or an investment strategy.
To quantify this, we randomly select one alpha formula per method and employ LLMs to rank their interpretability. We repeat this process 50 times and compute the average rank for each method. To mitigate potential biases from a single LLM, we aggregate rankings from three distinct LLMs. The results are presented in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S4.F7" title="Figure 7 ‣ Experiment 3: Interpretablitity of Alpha Formulas ‣ 4 Experiment ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">7</span></a>. The findings indicate that formulas mined by our framework exhibit interpretability second only to those generated by the CoT method.
This result is particularly noteworthy when compared to non-LLM baselines, whose formulas were consistently ranked as less interpretable.
This suggests that our approach achieves a compelling trade-off, delivering strong predictive performance while maintaining a high degree of interpretability.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="708" id="S4.F7.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Interpretability Ranking Comparison, showing mean and standard deviation over 5 random seeds.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SSx4.p2">
<p class="ltx_p">Furthermore, acknowledging that LLMs might inherently favor formulas generated through LLM-driven processes, we provide illustrative examples of alpha formulas from our method and non-LLM-based approaches in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.SSx7" title="Interpretability of Mined Alpha Formulas ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>.
While a formal human study is outside the scope of this work, a qualitative inspection of these examples reveals a clear difference: formulas from our method tend to have more discernible logic compared to the often opaque structures produced by non-LLM methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p">Automated formulaic alpha mining has traditionally relied on genetic programming (GP) frameworks <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib21" title="">2019</a>; Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib43" title="">2020</a>)</cite>, with other notable approaches employing reinforcement learning <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib39" title="">2023</a>)</cite> and deep learning-based generative models <cite class="ltx_cite ltx_citemacro_citep">(Shi et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib24" title="">2024</a>)</cite>. More recently, LLMs have been introduced, with approaches like FAMA <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib20" title="">2024b</a>)</cite> and AlphaAgent <cite class="ltx_cite ltx_citemacro_citep">(Tang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib26" title="">2025</a>)</cite> leveraging them for direct alpha generation guided by in-context examples or heuristics. In contrast, our method frames alpha discovery as a formal reasoning task, uniquely employing MCTS to systematically explore the structured space of mathematical formulas. This approach is inspired by recent advancements in tree search-based reasoning, such as Tree of Thoughts (ToT) <cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib38" title="">2024</a>)</cite> and RethinkMCTS <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib18" title="">2024a</a>)</cite>, which enhance LLM planning by structuring generation as a search process. A further literature review is provided in Appendix A.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p">We introduce an LLM-Powered Monte Carlo Tree Search (MCTS) framework for formulaic alpha mining. This approach models alpha mining as a tree search, where an LLM iteratively generates and refines candidate formulas, critically guided by quantitative feedback from financial backtesting. To foster search efficiency and alpha effectiveness, we incorporate a Frequent Subtree Avoidance mechanism. Experimental results demonstrate that our framework mines alphas with superior predictive accuracy and trading performance, while also offering enhanced interpretability and search efficiency compared to existing methods. This work pioneers a promising direction for leveraging LLMs and MCTS to tackle the complex challenge of automated formulaic alpha mining in finance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amihud and Mendelson (1986)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Amihud, Y.; and Mendelson, H. 1986.

</span>
<span class="ltx_bibblock">Asset pricing and the bid-ask spread.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Journal of financial Economics</em>, 17(2): 223–249.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Coulom (2007)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Coulom, R. 2007.

</span>
<span class="ltx_bibblock">Monte-Carlo Tree Search in Crazy Stone,”.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proc. Game Prog. Workshop, Tokyo, Japan</em>, 74–75.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cui, C.; Wang, W.; Zhang, M.; Chen, G.; Luo, Z.; and Ooi, B.&nbsp;C. 2021.

</span>
<span class="ltx_bibblock">Alphaevolve: A learning framework to discover novel alphas in
quantitative investment.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 2021 International conference on
management of data</em>, 2208–2216.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dainese et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dainese, N.; Merler, M.; Alakuijala, M.; and Marttinen, P. 2024.

</span>
<span class="ltx_bibblock">Generating code world models with large language models guided by
monte carlo tree search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2405.15383</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De&nbsp;Bondt and Thaler (1985)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
De&nbsp;Bondt, W.&nbsp;F.; and Thaler, R. 1985.

</span>
<span class="ltx_bibblock">Does the stock market overreact?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The Journal of finance</em>, 40(3): 793–805.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeLorenzo et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
DeLorenzo, M.; Chowdhury, A.&nbsp;B.; Gohil, V.; Thakur, S.; Karri, R.; Garg, S.;
and Rajendran, J. 2024.

</span>
<span class="ltx_bibblock">Make every move count: Llm-based high-quality rtl code generation
using mcts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.03289</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Duan, Y.; Wang, L.; Zhang, Q.; and Li, J. 2022.

</span>
<span class="ltx_bibblock">Factorvae: A probabilistic dynamic factor model based on variational
autoencoder for predicting cross-sectional stock returns.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume&nbsp;36, 4468–4476.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efficiency (1993)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Efficiency, S.&nbsp;M. 1993.

</span>
<span class="ltx_bibblock">Returns to buying winners and selling losers: Implications for.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The Journal of Finance</em>, 48(1): 65–91.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fama and French (1992)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fama, E.&nbsp;F.; and French, K.&nbsp;R. 1992.

</span>
<span class="ltx_bibblock">The cross-section of expected stock returns.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">the Journal of Finance</em>, 47(2): 427–465.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">French, Schwert, and Stambaugh (1987)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
French, K.&nbsp;R.; Schwert, G.&nbsp;W.; and Stambaugh, R.&nbsp;F. 1987.

</span>
<span class="ltx_bibblock">Expected stock returns and volatility.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Journal of financial Economics</em>, 19(1): 3–29.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harvey, Liu, and Zhu (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Harvey, C.&nbsp;R.; Liu, Y.; and Zhu, H. 2016.

</span>
<span class="ltx_bibblock">… and the cross-section of expected returns.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The Review of Financial Studies</em>, 29(1): 5–68.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou, Xue, and Zhang (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hou, K.; Xue, C.; and Zhang, L. 2020.

</span>
<span class="ltx_bibblock">Replicating anomalies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The Review of financial studies</em>, 33(5): 2019–2133.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hu, Z.; Liu, C.; Feng, X.; Zhao, Y.; Ng, S.-K.; Luu, A.&nbsp;T.; He, J.; Koh, P.&nbsp;W.;
and Hooi, B. 2024.

</span>
<span class="ltx_bibblock">Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances
Information Seeking in Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.03271</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ke, G.; Meng, Q.; Finley, T.; Wang, T.; Chen, W.; Ma, W.; Ye, Q.; and Liu,
T.-Y. 2017.

</span>
<span class="ltx_bibblock">Lightgbm: A highly efficient gradient boosting decision tree.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocsis and Szepesvári (2006)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kocsis, L.; and Szepesvári, C. 2006.

</span>
<span class="ltx_bibblock">Bandit based monte-carlo planning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">European conference on machine learning</em>, 282–293.
Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kou et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kou, Z.; Yu, H.; Luo, J.; Peng, J.; and Chen, L. 2024.

</span>
<span class="ltx_bibblock">Automate strategy finding with llm in quant investment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2409.06289</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Landajuela et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Landajuela, M.; Lee, C.&nbsp;S.; Yang, J.; Glatt, R.; Santiago, C.&nbsp;P.; Aravena, I.;
Mundhenk, T.; Mulcahy, G.; and Petersen, B.&nbsp;K. 2022.

</span>
<span class="ltx_bibblock">A unified framework for deep symbolic regression.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:
33985–33998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li, Q.; Xia, W.; Du, K.; Dai, X.; Tang, R.; Wang, Y.; Yu, Y.; and Zhang, W.
2024a.

</span>
<span class="ltx_bibblock">RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search
for Code Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2409.09584</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li, S.; Dong, S.; Luan, K.; Di, X.; and Ding, C. 2025.

</span>
<span class="ltx_bibblock">Enhancing Reasoning through Process Supervision with Monte Carlo Tree
Search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2501.01478</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li, Z.; Song, R.; Sun, C.; Xu, W.; Yu, Z.; and Wen, J.-R. 2024b.

</span>
<span class="ltx_bibblock">Can Large Language Models Mine Interpretable Financial Factors More
Effectively? A Neural-Symbolic Factor Mining Agent Model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics
ACL 2024</em>, 3891–3902.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lin, X.; Chen, Y.; Li, Z.; and He, K. 2019.

</span>
<span class="ltx_bibblock">Stock Alpha Mining Based On Genetic Algorithm.

</span>
<span class="ltx_bibblock">Technical report, Huatai Securities Research Center.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian, Hua, and Sorensen (2007)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qian, E.&nbsp;E.; Hua, R.&nbsp;H.; and Sorensen, E.&nbsp;H. 2007.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Quantitative equity portfolio management: modern techniques and
applications</em>.

</span>
<span class="ltx_bibblock">Chapman and Hall/CRC.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ren, T.; Zhou, R.; Jiang, J.; Liang, J.; Wang, Q.; and Peng, Y. 2024.

</span>
<span class="ltx_bibblock">RiskMiner: Discovering Formulaic Alphas via Risk Seeking Monte Carlo
Tree Search.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 5th ACM International Conference on AI in
Finance</em>, 752–760.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shi, H.; Song, W.; Zhang, X.; Shi, J.; Luo, C.; Ao, X.; Arian, H.; and Seco, L.
2024.

</span>
<span class="ltx_bibblock">AlphaForge: A Framework to Mine and Dynamically Combine Formulaic
Alpha Factors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.18394</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Silver, D.; Huang, A.; Maddison, C.&nbsp;J.; Guez, A.; Sifre, L.; Van Den&nbsp;Driessche,
G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.;
et&nbsp;al. 2016.

</span>
<span class="ltx_bibblock">Mastering the game of Go with deep neural networks and tree search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">nature</em>, 529(7587): 484–489.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tang, Z.; Chen, Z.; Yang, J.; Mai, J.; Zheng, Y.; Wang, K.; Chen, J.; and Lin,
L. 2025.

</span>
<span class="ltx_bibblock">AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to
Counteract Alpha Decay.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2502.16789</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tulchinsky (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tulchinsky, I. 2019.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Finding Alphas: A quantitative approach to building trading
strategies</em>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, C.; Deng, Y.; Lyu, Z.; Zeng, L.; He, J.; Yan, S.; and An, B.
2024a.

</span>
<span class="ltx_bibblock">Q*: Improving multi-step reasoning for llms with deliberative
planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.14283</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, P.; Li, L.; Shao, Z.; Xu, R.; Dai, D.; Li, Y.; Chen, D.; Wu, Y.; and Sui,
Z. 2024b.

</span>
<span class="ltx_bibblock">Math-shepherd: Verify and reinforce llms step-by-step without human
annotations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 62nd Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, 9426–9439.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, S.; Yuan, H.; Ni, L.&nbsp;M.; and Guo, J. 2024c.

</span>
<span class="ltx_bibblock">Quantagent: Seeking holy grail in trading by self-improving large
language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.03755</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, S.; Yuan, H.; Zhou, L.; Ni, L.&nbsp;M.; Shum, H.-Y.; and Guo, J. 2023.

</span>
<span class="ltx_bibblock">Alpha-gpt: Human-ai interactive alpha mining for quantitative
investment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.00016</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.; Le, Q.&nbsp;V.;
Zhou, D.; et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 35:
24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xie, Y.; Goyal, A.; Zheng, W.; Kan, M.-Y.; Lillicrap, T.&nbsp;P.; Kawaguchi, K.; and
Shieh, M. 2024.

</span>
<span class="ltx_bibblock">Monte carlo tree search boosts reasoning via iterative preference
learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2405.00451</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2021a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xu, W.; Liu, W.; Wang, L.; Xia, Y.; Bian, J.; Yin, J.; and Liu, T.-Y.
2021a.

</span>
<span class="ltx_bibblock">Hist: A graph-based framework for stock trend forecasting via mining
concept-oriented shared information.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.13716</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2021b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xu, W.; Liu, W.; Xu, C.; Bian, J.; Yin, J.; and Liu, T.-Y. 2021b.

</span>
<span class="ltx_bibblock">Rest: Relational event-driven stock trend forecasting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the web conference 2021</em>, 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang, X.; Liu, W.; Zhou, D.; Bian, J.; and Liu, T.-Y. 2020.

</span>
<span class="ltx_bibblock">Qlib: An ai-oriented quantitative investment platform.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.11189</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang, X.; Yang, X.; Fang, S.; Xian, B.; Li, Y.; Wang, J.; Xu, M.; Pan, H.;
Hong, X.; Liu, W.; et&nbsp;al. 2025.

</span>
<span class="ltx_bibblock">R&amp;d-agent: Automating data-driven ai solution building through
llm-powered automated research, development, and evolution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2505.14738</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T.; Cao, Y.; and Narasimhan,
K. 2024.

</span>
<span class="ltx_bibblock">Tree of thoughts: Deliberate problem solving with large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu, S.; Xue, H.; Ao, X.; Pan, F.; He, J.; Tu, D.; and He, Q. 2023.

</span>
<span class="ltx_bibblock">Generating synergistic formulaic alpha collections via reinforcement
learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 29th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, 5476–5486.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu, Y.; Li, H.; Chen, Z.; Jiang, Y.; Li, Y.; Zhang, D.; Liu, R.; Suchow, J.&nbsp;W.;
and Khashanah, K. 2024.

</span>
<span class="ltx_bibblock">FinMem: A performance-enhanced LLM trading agent with layered memory
and character design.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the AAAI Symposium Series</em>, volume&nbsp;3,
595–597.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, D.; Huang, X.; Zhou, D.; Li, Y.; and Ouyang, W. 2024.

</span>
<span class="ltx_bibblock">Accessing gpt-4 level mathematical olympiad solutions via monte carlo
tree self-refine with llama-3 8b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.07394</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, S.; Chen, Z.; Shen, Y.; Ding, M.; Tenenbaum, J.&nbsp;B.; and Gan, C.
2023a.

</span>
<span class="ltx_bibblock">Planning with large language models for code generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.05510</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, T.; Li, Y.; Jin, Y.; and Li, J. 2020.

</span>
<span class="ltx_bibblock">Autoalpha: an efficient hierarchical evolutionary algorithm for
mining alpha factors in quantitative investment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.08245</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, T.; Zhang, Z.&nbsp;A.; Fan, Z.; Luo, H.; Liu, F.; Liu, Q.; Cao, W.; and Jian,
L. 2023b.

</span>
<span class="ltx_bibblock">OpenFE: automated feature generation with expert-level performance.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 41880–41901.
PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao, Lee, and Hsu (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhao, Z.; Lee, W.&nbsp;S.; and Hsu, D. 2023.

</span>
<span class="ltx_bibblock">Large language models as commonsense knowledge for large-scale task
planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36:
31967–31987.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhou, A.; Yan, K.; Shlapentokh-Rothman, M.; Wang, H.; and Wang, Y.-X. 2023.

</span>
<span class="ltx_bibblock">Language agent tree search unifies reasoning acting and planning in
language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.04406</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Summary of Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p">This appendix provides extensive supplementary material to support the methodologies, experiments, and findings presented in the main paper. The contents are organized as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A2" title="Appendix B Further Related Work ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">B</span></a>: Further Related Work.</span> A review of related work in automated formulaic alpha mining and tree search-based reasoning.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3" title="Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">C</span></a>: Illustrative Case Study.</span> A step-by-step walkthrough of our framework’s MCTS workflow.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A4" title="Appendix D Method Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">D</span></a>: Method Details.</span> Elaboration on the generation and refinement of alpha formulas, the multi-dimensional evaluation metrics, and the dynamic search budget strategy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A5.T2" title="Table 2 ‣ Appendix E List of Operators ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">2</span></a>: List of Operators.</span> A comprehensive list of operators employed within the alpha formulas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A6" title="Appendix F Pseudo-Code ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">F</span></a>: Pseudo-code.</span> The algorithmic pseudo-code of our framework.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7" title="Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">G</span></a>: Experimental Setup Details.</span> Details on the dataset, hyperparameter configurations, model specifications, backtesting strategy, and performance metrics.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8" title="Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">H</span></a>: Extended Experimental Results and Analyses.</span> Includes comparative analyses against other baselines, comparison results on the U.S. stock market, investigations into data leakage and LLM sensitivity, and qualitative analyses of alpha characteristics and interpretability.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9" title="Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">I</span></a>: Full Experiment Results.</span> Comprehensive results of the prediction performance comparison experiments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A10" title="Appendix J Limitations ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">J</span></a>: Limitations.</span> A discussion of the limitations of our framework.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i10.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11" title="Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">K</span></a>: LLM Agent Prompts.</span> Details of key prompts used for alpha generation, refinement, and overfitting risk assessment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Further Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Automated Formulaic Alpha Mining</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A2.SSx1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Traditional Methods</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SSx1.SSS0.Px1.p1">
<p class="ltx_p">As mentioned in the main text, traditional alpha mining encompasses several paradigms. Genetic programming (GP) is a foundational approach. Early work like GPLearn <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib21" title="">2019</a>)</cite> applies GP with a pre-defined set of time-series operators, while later enhancements like AutoAlpha <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib43" title="">2020</a>)</cite> improve efficiency by initializing the search with effective, low-depth alphas. AlphaEvolve <cite class="ltx_cite ltx_citemacro_citep">(Cui et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib3" title="">2021</a>)</cite> further advances this line of work by evolving computation graphs instead of simple formula trees. Beyond GP, other paradigms include AlphaGen <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib39" title="">2023</a>)</cite>, which uses reinforcement learning to optimize an entire alpha set, and AlphaForge <cite class="ltx_cite ltx_citemacro_citep">(Shi et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib24" title="">2024</a>)</cite>, which designs a deep learning-based generative-predictive structure.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SSx1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Other LLM-based Frameworks</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SSx1.SSS0.Px2.p1">
<p class="ltx_p">Several other works have explored the application of LLMs in quantitative finance, though they fall outside the scope of our direct comparison. For instance, AlphaGPT <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib31" title="">2023</a>)</cite> focuses on a human-AI interaction paradigm, using prompt engineering to translate researcher insights into alphas. A framework by Kou et al. <cite class="ltx_cite ltx_citemacro_citep">(Kou et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib16" title="">2024</a>)</cite> mines alphas from multimodal financial data via a multi-agent system. Similarly, QuantAgent <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib30" title="">2024c</a>)</cite> introduces a two-loop system where an LLM refines strategies from a knowledge base updated through real-world testing. These methods are excluded from our comparative benchmarks due to their reliance on non-standard data (e.g., multimodal), interactive human feedback, or methodologies that are not sufficiently detailed or open-sourced for a fair and reproducible comparison.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Tree Search-based Reasoning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SSx2.p1">
<p class="ltx_p">As mentioned in the main text, tree search methods are increasingly used to maximize the exploration capabilities of LLMs, allowing for different levels of search and planning <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib42" title="">2023a</a>; Hu et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib13" title="">2024</a>)</cite>. They are now widely applied in LLM-based agents and reasoning tasks <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib29" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib28" title="">a</a>)</cite>. LATS <cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib46" title="">2023</a>)</cite>, for example, extends this concept by viewing the LLM as a general agent that conducts exploration at both the reasoning and action levels, which is conceptually related to our approach of building a formula through a sequence of operator selections.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Illustrative Case Study of MCTS Workflow</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p">To elucidate the workflow of our proposed MCTS framework for alpha factor mining, this section provides a detailed step-by-step example.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="199" id="A3.F8.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/case_study_1.png" width="698">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Case Study: MCTS root node generation.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p">Initially, as depicted in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3.F8" title="Figure 8 ‣ Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">8</span></a>, an initial alpha formula is generated by the LLM. After undergoing a multi-dimensional evaluation, this formula becomes the root node (<math alttext="V_{0}" class="ltx_Math" display="inline" id="A3.p2.m1" intent=":literal"><semantics><msub><mi>V</mi><mn>0</mn></msub><annotation encoding="application/x-tex">V_{0}</annotation></semantics></math>) of the MCTS search tree. For this illustrative case, the target search count (initial search budget) is initialized to 3. This target is dynamically incremented by 1 (budget increment) each time a newly generated node achieves a new high score, encouraging deeper exploration of promising search trees.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="355" id="A3.F9.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/case_study_2.png" width="698">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Case Study: expansion to node <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.F9.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p3">
<p class="ltx_p">Following the construction of the root node, the MCTS process proceeds with node expansion. As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3.F9" title="Figure 9 ‣ Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">9</span></a>, the root node <math alttext="V_{0}" class="ltx_Math" display="inline" id="A3.p3.m1" intent=":literal"><semantics><msub><mi>V</mi><mn>0</mn></msub><annotation encoding="application/x-tex">V_{0}</annotation></semantics></math> is expanded to generate its first child node, <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p3.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math>. The dimension for refinement is selected by sampling according to Equation&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E3" title="In Expansion ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>) (in this instance, the <span class="ltx_text ltx_font_italic">Stability</span> dimension is chosen). Subsequently, the LLM generates targeted refinement suggestions. Based on these suggestions, a refined alpha formula is produced, with the modifications highlighted within the formula representation. This refined alpha formula is then subjected to the same multi-dimensional evaluation process, yielding the scored node <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p3.m3" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math>. The refinement history for <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p3.m4" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math> is updated to include a summary of this specific refinement step and the corresponding change in evaluation scores. Finally, both the target search count (if <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p3.m5" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math>’s score is a new high) and the current search count are updated.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="416" id="A3.F10.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/case_study_3.png" width="698">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Case Study: expansion to node <math alttext="V_{2}" class="ltx_Math" display="inline" id="A3.F10.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>2</mn></msub><annotation encoding="application/x-tex">V_{2}</annotation></semantics></math>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p4">
<p class="ltx_p">The expansion process continues, as illustrated in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3.F10" title="Figure 10 ‣ Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">10</span></a>. Based on the UCT criterion, node <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p4.m1" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math> is selected for the next expansion. Similar to the previous step, a dimension for refinement is sampled. The LLM then generates an improved alpha formula based on this dimension, which is subsequently evaluated to create node <math alttext="V_{2}" class="ltx_Math" display="inline" id="A3.p4.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>2</mn></msub><annotation encoding="application/x-tex">V_{2}</annotation></semantics></math>. Notably, the refinement history of <math alttext="V_{2}" class="ltx_Math" display="inline" id="A3.p4.m3" intent=":literal"><semantics><msub><mi>V</mi><mn>2</mn></msub><annotation encoding="application/x-tex">V_{2}</annotation></semantics></math> is cumulative, encapsulating all refinement steps and score evolutions from the root node <math alttext="V_{0}" class="ltx_Math" display="inline" id="A3.p4.m4" intent=":literal"><semantics><msub><mi>V</mi><mn>0</mn></msub><annotation encoding="application/x-tex">V_{0}</annotation></semantics></math> through <math alttext="V_{1}" class="ltx_Math" display="inline" id="A3.p4.m5" intent=":literal"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_{1}</annotation></semantics></math> to <math alttext="V_{2}" class="ltx_Math" display="inline" id="A3.p4.m6" intent=":literal"><semantics><msub><mi>V</mi><mn>2</mn></msub><annotation encoding="application/x-tex">V_{2}</annotation></semantics></math>. The current search count is then incremented.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p5">
<p class="ltx_p">Figures&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3.F11" title="Figure 11 ‣ Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">11</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A3.F12" title="Figure 12 ‣ Appendix C Illustrative Case Study of MCTS Workflow ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">12</span></a> showcase the outcomes of the two subsequent expansion steps, leading to the generation of nodes <math alttext="V_{3}" class="ltx_Math" display="inline" id="A3.p5.m1" intent=":literal"><semantics><msub><mi>V</mi><mn>3</mn></msub><annotation encoding="application/x-tex">V_{3}</annotation></semantics></math> and <math alttext="V_{4}" class="ltx_Math" display="inline" id="A3.p5.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>4</mn></msub><annotation encoding="application/x-tex">V_{4}</annotation></semantics></math>, respectively. Upon the expansion that creates node <math alttext="V_{4}" class="ltx_Math" display="inline" id="A3.p5.m3" intent=":literal"><semantics><msub><mi>V</mi><mn>4</mn></msub><annotation encoding="application/x-tex">V_{4}</annotation></semantics></math>, the current search count reaches the predetermined target. At this point, the expansion phase for the current MCTS iteration concludes. All five generated nodes (<math alttext="V_{0},...,V_{4}" class="ltx_Math" display="inline" id="A3.p5.m4" intent=":literal"><semantics><mrow><msub><mi>V</mi><mn>0</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>V</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">V_{0},...,V_{4}</annotation></semantics></math>) are then systematically reviewed. Nodes that meet predefined quality and performance criteria are added to the effective alpha repository.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p6">
<p class="ltx_p">This sequence completes one full iteration of the MCTS-driven alpha mining process. Our framework is designed to iteratively repeat this entire cycle, enabling the efficient and systematic mining of effective alphas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="401" id="A3.F11.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/case_study_4.png" width="698">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Case Study: expansion to node <math alttext="V_{3}" class="ltx_Math" display="inline" id="A3.F11.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>3</mn></msub><annotation encoding="application/x-tex">V_{3}</annotation></semantics></math>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="418" id="A3.F12.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/case_study_5.png" width="698">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Case Study: expansion to node <math alttext="V_{4}" class="ltx_Math" display="inline" id="A3.F12.m2" intent=":literal"><semantics><msub><mi>V</mi><mn>4</mn></msub><annotation encoding="application/x-tex">V_{4}</annotation></semantics></math> and search termination.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Method Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p">In this section, we elaborate on specific details of our framework, focusing on the generation process, evaluation metrics, and the search budget allocation strategy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="A4.SSx1">
<h3 class="ltx_title ltx_title_subsection">Alpha Formula Generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx1.p1">
<p class="ltx_p">We decompose the generation of alpha formulas into a two-step process: first, an <span class="ltx_text ltx_font_italic">alpha portrait</span> is generated, and subsequently, the corresponding alpha formula is derived from this portrait. An alpha portrait is a textual representation that includes the alpha’s name, a concise description of its underlying investment logic, and its formula expressed in pseudo-code. This two-step approach decouples the conceptual design of an alpha from its concrete construction, thereby reducing the instruction-following complexity for the LLM and enhancing the quality of the generated formulas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SSx1.p2">
<p class="ltx_p">When generating alpha formulas, the LLM is instructed to use symbolic parameters (e.g., the lookback window for a moving average operator) rather than fixed numerical values. Concurrently, the LLM proposes several candidate sets of parameter values (three sets in our experiments). We then backtest the alpha derived from each parameter set and select the configuration yielding the best performance. This strategy facilitates a more efficient exploration and utilization of each generated formula structure.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A4.SSx2">
<h3 class="ltx_title ltx_title_subsection">Refinement Suggestion Generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx2.p1">
<p class="ltx_p">During each refinement iteration, once a target dimension for improvement is selected as per Equation&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E3" title="In Expansion ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>, we leverage the LLM to generate targeted refinement suggestions. We employ few-shot learning, using alphas from the effective alpha repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="A4.SSx2.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math> as exemplars. The exemplar selection strategy is tailored for each evaluation dimension to provide the most relevant guidance:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A4.SSx2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Effectiveness and Stability</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx2.SSS0.Px1.p1">
<p class="ltx_p">To select diverse yet potent exemplars, we first filter the effective alpha repository by removing alphas with the highest correlation to the current alpha (top <math alttext="\eta" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px1.p1.m1" intent=":literal"><semantics><mi>η</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>%, where <math alttext="\eta=50" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px1.p1.m2" intent=":literal"><semantics><mrow><mi>η</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">\eta=50</annotation></semantics></math> in our experiments). This creates a candidate pool of more structurally distinct exemplars. From this filtered subset, we select the top-<math alttext="k" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px1.p1.m3" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> alphas (e.g., <math alttext="k=3" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px1.p1.m4" intent=":literal"><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k=3</annotation></semantics></math>) exhibiting the highest scores in Effectiveness or Stability to serve as few-shot examples. This two-stage process ensures diversity by preventing highly similar alphas from dominating the exemplar set and encouraging more innovative refinements.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A4.SSx2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Diversity</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx2.SSS0.Px2.p1">
<p class="ltx_p">To encourage the exploration of novel alpha structures, we select the top-<math alttext="k" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px2.p1.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> alphas from the effective alpha repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="A4.SSx2.SSS0.Px2.p1.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math> that exhibit the lowest correlation with the current alpha as few-shot exemplars.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A4.SSx2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Turnover and Overfitting Risk</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx2.SSS0.Px3.p1">
<p class="ltx_p">For these dimensions, we adopt a zero-shot approach, directly prompting the LLM to generate refinement suggestions without explicit exemplars, relying on the model’s intrinsic understanding of these concepts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SSx2.SSS0.Px3.p2">
<p class="ltx_p">Following the generation of a textual suggestion, the LLM produces a revised alpha formula. We then perform a syntax validation on this formula. If it is syntactically incorrect, the LLM receives the error as feedback and is prompted to correct it iteratively until the formula passes validation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A4.SSx3">
<h3 class="ltx_title ltx_title_subsection">Multi-Dimensional Evaluation Metrics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx3.p1">
<p class="ltx_p">As introduced in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx3" title="Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>, we evaluate each candidate alpha <math alttext="f" class="ltx_Math" display="inline" id="A4.SSx3.p1.m1" intent=":literal"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> across a set of <math alttext="q" class="ltx_Math" display="inline" id="A4.SSx3.p1.m2" intent=":literal"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> dimensions to provide granular feedback for refinement. The score for each dimension, <math alttext="e_{i}" class="ltx_Math" display="inline" id="A4.SSx3.p1.m3" intent=":literal"><semantics><msub><mi>e</mi><mi>i</mi></msub><annotation encoding="application/x-tex">e_{i}</annotation></semantics></math>, is typically derived from its percentile rank against the repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="A4.SSx3.p1.m4" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math> as defined in Equation&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E7" title="In Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">7</span></a>. The primary dimensions used in our framework are detailed as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SSx3.p2">
<ul class="ltx_itemize" id="A4.I1">
<li class="ltx_item" id="A4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i1.p1">
<p class="ltx_p">Effectiveness: This dimension measures the alpha’s core predictive power.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i2.p1">
<p class="ltx_p">Stability: This dimension assesses the consistency of an alpha’s predictive performance over time. An alpha that performs well only in specific market regimes is less reliable.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i3.p1">
<p class="ltx_p">Turnover: This dimension evaluates the trading cost associated with an alpha. It is measured by the average daily change in the alpha’s portfolio holdings. A high turnover implies frequent rebalancing, which can incur significant transaction costs and erode profits. The goal is to maintain turnover within a desirable, low range.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i4.p1">
<p class="ltx_p">Diversity: This dimension quantifies the novelty an alpha contributes to the existing repository <math alttext="\mathcal{F}{zoo}" class="ltx_Math" display="inline" id="A4.I1.i4.p1.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo lspace="0em" rspace="0em">​</mo><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow><annotation encoding="application/x-tex">\mathcal{F}{zoo}</annotation></semantics></math>. A valuable alpha should provide predictive signals that are not redundant with those already discovered.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i5.p1">
<p class="ltx_p">Overfitting Risk: As described in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx3" title="Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>, this is a qualitative assessment performed by an LLM. The model analyzes the formula’s complexity, the number of parameters, and its refinement history to identify signs of being overly tailored to the training data (i.e., “p-hacking”), which would impair its generalization performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A4.SSx4">
<h3 class="ltx_title ltx_title_subsection">Dynamic Search Budget Allocation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SSx4.p1">
<p class="ltx_p">To balance the breadth and depth of the MCTS search, we employ a dynamic budget allocation strategy. This approach directs more computational resources towards the most promising search paths without prematurely abandoning exploration. The mechanism is governed by two parameters: an initial search budget <math alttext="B" class="ltx_Math" display="inline" id="A4.SSx4.p1.m1" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> and a budget increment <math alttext="b" class="ltx_Math" display="inline" id="A4.SSx4.p1.m2" intent=":literal"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SSx4.p2">
<p class="ltx_p">The search process for any given MCTS tree begins with an initial budget of <math alttext="B" class="ltx_Math" display="inline" id="A4.SSx4.p2.m1" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> expansion steps. During the search, we monitor the score of each newly generated alpha. If a new alpha <math alttext="f_{new}" class="ltx_Math" display="inline" id="A4.SSx4.p2.m2" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">f_{new}</annotation></semantics></math> achieves a score <math alttext="S(f_{new})" class="ltx_Math" display="inline" id="A4.SSx4.p2.m3" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(f_{new})</annotation></semantics></math> that surpasses the highest score previously seen within that specific MCTS tree, it constitutes a “breakthrough”. Upon each such breakthrough, the remaining search budget for the current tree is increased by the increment <math alttext="b" class="ltx_Math" display="inline" id="A4.SSx4.p2.m4" intent=":literal"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>. The search for the current tree terminates when its allocated budget is exhausted.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SSx4.p3">
<p class="ltx_p">This strategy ensures that promising avenues, identified by the discovery of high-quality alphas, are explored more thoroughly, while preventing excessive resource expenditure on less fruitful branches of the search space <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="A4.SSx4.p3.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>. It dynamically adapts the search effort based on real-time performance feedback, leading to a more efficient and effective alpha mining process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>List of Operators</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p">In this paper, the operators we used can be categorized into two classes: unary operators and binary operators. All operators perform temporal operations, utilizing data from either the current trading day alone or including data from a preceding period. We list the details of all the operators in Table <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A5.T2" title="Table 2 ‣ Appendix E List of Operators ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">2</span></a></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:250.1pt;vertical-align:-122.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.2pt,8.0pt) scale(0.939926400325325,0.939926400325325) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_bold">Operator</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_bold">Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_bold">Description</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math alttext="-x,|x|,x^{2},1/x" class="ltx_Math" display="inline" id="A5.T2.m1" intent=":literal"><semantics><mrow><mrow><mo>−</mo><mi>x</mi></mrow><mo>,</mo><mrow><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">|</mo></mrow><mo>,</mo><msup><mi>x</mi><mn>2</mn></msup><mo>,</mo><mrow><mn>1</mn><mo>/</mo><mi>x</mi></mrow></mrow><annotation encoding="application/x-tex">-x,|x|,x^{2},1/x</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="15">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">Unary</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_t">The opposite/absolute/square/inverse value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m2" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Sign}(x)" class="ltx_Math" display="inline" id="A5.T2.m3" intent=":literal"><semantics><mrow><mi>Sign</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Sign}(x)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The sign of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m4" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Sin}(x),\mathrm{Cos}(x),\mathrm{Tanh}(x)" class="ltx_Math" display="inline" id="A5.T2.m5" intent=":literal"><semantics><mrow><mrow><mi>Sin</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Cos</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Tanh</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Sin}(x),\mathrm{Cos}(x),\mathrm{Tanh}(x)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">Sine, cosine, and hyperbolic tangent functions.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Log}(x)" class="ltx_Math" display="inline" id="A5.T2.m6" intent=":literal"><semantics><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Log}(x)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The natural logarithm of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m7" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Delay}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m8" intent=":literal"><semantics><mrow><mi>Delay</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Delay}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The value of expression <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m9" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> at <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m10" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> trading days prior.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Diff}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m11" intent=":literal"><semantics><mrow><mi>Diff</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Diff}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The difference between x and the value prior to day t, <math alttext="x-\mathrm{Delay}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m12" intent=":literal"><semantics><mrow><mi>x</mi><mo>−</mo><mrow><mi>Delay</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">x-\mathrm{Delay}(x,t)</annotation></semantics></math>.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Pct}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m13" intent=":literal"><semantics><mrow><mi>Pct</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Pct}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The rate of change of x relative to its value t days prior.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Ma}(x,t),\mathrm{Med}(x,t),\mathrm{Sum}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m14" intent=":literal"><semantics><mrow><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Med</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Sum</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Ma}(x,t),\mathrm{Med}(x,t),\mathrm{Sum}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The mean/median/sum value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m15" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m16" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Std}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m17" intent=":literal"><semantics><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Std}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The standard deviation value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m18" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m19" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Max}(x,t),\mathrm{Min}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m20" intent=":literal"><semantics><mrow><mrow><mi>Max</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Min</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Max}(x,t),\mathrm{Min}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The maximum/minimum value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m21" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m22" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Rank}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m23" intent=":literal"><semantics><mrow><mi>Rank</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Rank}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The ranking of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m24" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> relative to its values over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m25" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Skew}(x,t),\mathrm{Kurt}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m26" intent=":literal"><semantics><mrow><mrow><mi>Skew</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Kurt</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Skew}(x,t),\mathrm{Kurt}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The skewness/kurtosis value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m27" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m28" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Vari}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m29" intent=":literal"><semantics><mrow><mi>Vari</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Vari}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The variation value of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m30" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m31" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days, <math alttext="\mathrm{Std}(x,t)/\mathrm{Ma}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m32" intent=":literal"><semantics><mrow><mrow><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><mi>Ma</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Std}(x,t)/\mathrm{Ma}(x,t)</annotation></semantics></math>.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Autocorr}(x,t,n)" class="ltx_Math" display="inline" id="A5.T2.m33" intent=":literal"><semantics><mrow><mi>Autocorr</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Autocorr}(x,t,n)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The autocorrelation coefficient of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m34" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> with a lag of <math alttext="n" class="ltx_Math" display="inline" id="A5.T2.m35" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m36" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Zscore}(x,t)" class="ltx_Math" display="inline" id="A5.T2.m37" intent=":literal"><semantics><mrow><mi>Zscore</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Zscore}(x,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_left">The z-score normalization of <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m38" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> based on the mean and standard deviation</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_left">of its values over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m39" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
</tbody></table></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math alttext="x+y,x-y,x\cdot y,x/y" class="ltx_Math" display="inline" id="A5.T2.m40" intent=":literal"><semantics><mrow><mrow><mi>x</mi><mo>+</mo><mi>y</mi></mrow><mo>,</mo><mrow><mi>x</mi><mo>−</mo><mi>y</mi></mrow><mo>,</mo><mrow><mi>x</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><mi>y</mi></mrow><mo>,</mo><mrow><mi>x</mi><mo>/</mo><mi>y</mi></mrow></mrow><annotation encoding="application/x-tex">x+y,x-y,x\cdot y,x/y</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">Binary</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_t">Arithmetic operators.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Greater}(x,y),\mathrm{Less}(x,y)" class="ltx_Math" display="inline" id="A5.T2.m41" intent=":literal"><semantics><mrow><mrow><mi>Greater</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Less</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Greater}(x,y),\mathrm{Less}(x,y)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">Whether the first value is larger/smaller than the second value.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><math alttext="\mathrm{Cov}(x,y,t)" class="ltx_Math" display="inline" id="A5.T2.m42" intent=":literal"><semantics><mrow><mi>Cov</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Cov}(x,y,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left">The covariance between time series <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m43" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and <math alttext="y" class="ltx_Math" display="inline" id="A5.T2.m44" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m45" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><math alttext="\mathrm{Corr}(x,y,t)" class="ltx_Math" display="inline" id="A5.T2.m46" intent=":literal"><semantics><mrow><mi>Corr</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Corr}(x,y,t)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_bb">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_left">The Pearson’s correlation coefficient between time series <math alttext="x" class="ltx_Math" display="inline" id="A5.T2.m47" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and <math alttext="y" class="ltx_Math" display="inline" id="A5.T2.m48" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_left">over the past <math alttext="t" class="ltx_Math" display="inline" id="A5.T2.m49" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> days.</td>
</tr>
</tbody></table></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>All the operators used in the experiments.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Pseudo-Code</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p">We provide the pseudo-code for our LLM-guided MCTS framework in Algorithm&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#alg1" title="In Appendix F Pseudo-Code ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_algorithm" id="alg1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>
</div>
<div class="ltx_listingline">
<span class="ltx_text ltx_font_bold">Input:</span> <math alttext="f_{\text{seed}}" class="ltx_Math" display="inline" id="alg1.m1" intent=":literal"><semantics><msub><mi>f</mi><mtext>seed</mtext></msub><annotation encoding="application/x-tex">f_{\text{seed}}</annotation></semantics></math> (initial alpha), <math alttext="LLM" class="ltx_Math" display="inline" id="alg1.m2" intent=":literal"><semantics><mrow><mi>L</mi><mo lspace="0em" rspace="0em">​</mo><mi>L</mi><mo lspace="0em" rspace="0em">​</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">LLM</annotation></semantics></math> (language model), <math alttext="c" class="ltx_Math" display="inline" id="alg1.m3" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> (exploration const.), <math alttext="T" class="ltx_Math" display="inline" id="alg1.m4" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> (temperature),
<math alttext="e_{\text{max}}" class="ltx_Math" display="inline" id="alg1.m5" intent=":literal"><semantics><msub><mi>e</mi><mtext>max</mtext></msub><annotation encoding="application/x-tex">e_{\text{max}}</annotation></semantics></math> (max score/dim), <math alttext="B" class="ltx_Math" display="inline" id="alg1.m6" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> (initial search budget), <math alttext="b" class="ltx_Math" display="inline" id="alg1.m7" intent=":literal"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math> (budget increment), <math alttext="\theta_{\text{eff}}" class="ltx_Math" display="inline" id="alg1.m8" intent=":literal"><semantics><msub><mi>θ</mi><mtext>eff</mtext></msub><annotation encoding="application/x-tex">\theta_{\text{eff}}</annotation></semantics></math> (effectiveness threshold),
<math alttext="\mathcal{G}_{\text{forbidden}}" class="ltx_Math" display="inline" id="alg1.m9" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub><annotation encoding="application/x-tex">\mathcal{G}_{\text{forbidden}}</annotation></semantics></math> (initial forbidden structures)
</div>
<div class="ltx_listingline">
<span class="ltx_text ltx_font_bold">Output:</span> Repository <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="alg1.m10" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math> of effective alphas
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>
</div>
<div class="ltx_listingline">
</div>
<div class="ltx_listingline"> <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Initialization<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span>
<math alttext="\mathcal{F}_{zoo}\leftarrow\emptyset" class="ltx_Math" display="inline" id="alg1.m11" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">←</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">\mathcal{F}_{zoo}\leftarrow\emptyset</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>
<math alttext="s_{0}\leftarrow\text{CreateRootNode}(f_{\text{seed}})" class="ltx_Math" display="inline" id="alg1.m12" intent=":literal"><semantics><mrow><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false">←</mo><mrow><mtext>CreateRootNode</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mtext>seed</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">s_{0}\leftarrow\text{CreateRootNode}(f_{\text{seed}})</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>
<math alttext="\bm{E}_{s_{0}}\leftarrow\text{MultiDimEvaluate}(f_{\text{seed}},\mathcal{F}_{zoo})" class="ltx_Math" display="inline" id="alg1.m13" intent=":literal"><semantics><mrow><msub><mi>𝑬</mi><msub><mi>s</mi><mn>0</mn></msub></msub><mo stretchy="false">←</mo><mrow><mtext>MultiDimEvaluate</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mtext>seed</mtext></msub><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bm{E}_{s_{0}}\leftarrow\text{MultiDimEvaluate}(f_{\text{seed}},\mathcal{F}_{zoo})</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<math alttext="N_{s_{0}}\leftarrow 1" class="ltx_Math" display="inline" id="alg1.m14" intent=":literal"><semantics><mrow><msub><mi>N</mi><msub><mi>s</mi><mn>0</mn></msub></msub><mo stretchy="false">←</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">N_{s_{0}}\leftarrow 1</annotation></semantics></math>; <math alttext="S_{s_{0}}\leftarrow\text{AggregateScore}(\bm{E}_{s_{0}})" class="ltx_Math" display="inline" id="alg1.m15" intent=":literal"><semantics><mrow><msub><mi>S</mi><msub><mi>s</mi><mn>0</mn></msub></msub><mo stretchy="false">←</mo><mrow><mtext>AggregateScore</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝑬</mi><msub><mi>s</mi><mn>0</mn></msub></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">S_{s_{0}}\leftarrow\text{AggregateScore}(\bm{E}_{s_{0}})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m16" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Store the alpha’s intrinsic score <math alttext="S(f_{s_{0}})" class="ltx_Math" display="inline" id="alg1.m17" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><msub><mi>s</mi><mn>0</mn></msub></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(f_{s_{0}})</annotation></semantics></math> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>
Tree <math alttext="\mathcal{T}\leftarrow\{s_{0}\}" class="ltx_Math" display="inline" id="alg1.m18" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒯</mi><mo stretchy="false">←</mo><mrow><mo stretchy="false">{</mo><msub><mi>s</mi><mn>0</mn></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{T}\leftarrow\{s_{0}\}</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<math alttext="S_{\text{max}}\leftarrow S_{s_{0}}" class="ltx_Math" display="inline" id="alg1.m19" intent=":literal"><semantics><mrow><msub><mi>S</mi><mtext>max</mtext></msub><mo stretchy="false">←</mo><msub><mi>S</mi><msub><mi>s</mi><mn>0</mn></msub></msub></mrow><annotation encoding="application/x-tex">S_{\text{max}}\leftarrow S_{s_{0}}</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m20" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Track highest alpha score <math alttext="S(f)" class="ltx_Math" display="inline" id="alg1.m21" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(f)</annotation></semantics></math> found in the tree </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span class="ltx_text ltx_font_bold">for</span> <em class="ltx_emph ltx_font_italic"><math alttext="iter\leftarrow 1" class="ltx_Math" display="inline" id="alg1.m22" intent=":literal"><semantics><mrow><mrow><mi>i</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi></mrow><mo stretchy="false">←</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">iter\leftarrow 1</annotation></semantics></math> <span class="ltx_text ltx_font_bold ltx_font_upright">to</span> <math alttext="B" class="ltx_Math" display="inline" id="alg1.m23" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold">do</span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>   <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Selection Phase<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="s_{\text{selected}},P_{\text{path}}\leftarrow\text{SelectNodeViaUCT}(\mathcal{T},s_{0},c)" class="ltx_Math" display="inline" id="alg1.m24" intent=":literal"><semantics><mrow><mrow><msub><mi>s</mi><mtext>selected</mtext></msub><mo>,</mo><msub><mi>P</mi><mtext>path</mtext></msub></mrow><mo stretchy="false">←</mo><mrow><mtext>SelectNodeViaUCT</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">𝒯</mi><mo>,</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">s_{\text{selected}},P_{\text{path}}\leftarrow\text{SelectNodeViaUCT}(\mathcal{T},s_{0},c)</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m25" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Select leaf/internal node for expansion. <math alttext="P_{\text{path}}" class="ltx_Math" display="inline" id="alg1.m26" intent=":literal"><semantics><msub><mi>P</mi><mtext class="ltx_mathvariant_italic">path</mtext></msub><annotation encoding="application/x-tex">P_{\text{path}}</annotation></semantics></math> is a list of <math alttext="(s,a)" class="ltx_Math" display="inline" id="alg1.m27" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s,a)</annotation></semantics></math> pairs. </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>   <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Expansion Phase<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_italic">1. Prioritize refinement dimension  */</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\bm{E}_{s}\leftarrow s_{\text{selected}}.\bm{E}" class="ltx_Math" display="inline" id="alg1.m28" intent=":literal"><semantics><mrow><mrow><msub><mi>𝑬</mi><mi>s</mi></msub><mo stretchy="false">←</mo><msub><mi>s</mi><mtext>selected</mtext></msub></mrow><mo lspace="0em" rspace="0.167em">.</mo><mi>𝑬</mi></mrow><annotation encoding="application/x-tex">\bm{E}_{s}\leftarrow s_{\text{selected}}.\bm{E}</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="P(i|s)\leftarrow\text{Softmax}((e_{\text{max}}\mathbf{1}_{q}-\bm{E}_{s})/T)" class="ltx_Math" display="inline" id="alg1.m29" intent=":literal"><semantics><mrow><mrow><mi>P</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>i</mi><mo fence="false">|</mo><mi>s</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">←</mo><mrow><mtext>Softmax</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mrow><msub><mi>e</mi><mtext>max</mtext></msub><mo lspace="0em" rspace="0em">​</mo><msub><mn>𝟏</mn><mi>q</mi></msub></mrow><mo>−</mo><msub><mi>𝑬</mi><mi>s</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mo>/</mo><mi>T</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">P(i|s)\leftarrow\text{Softmax}((e_{\text{max}}\mathbf{1}_{q}-\bm{E}_{s})/T)</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="i^{*}\leftarrow\text{SampleDimension}(P(i|s))" class="ltx_Math" display="inline" id="alg1.m30" intent=":literal"><semantics><mrow><msup><mi>i</mi><mo>∗</mo></msup><mo stretchy="false">←</mo><mrow><mtext>SampleDimension</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>P</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>i</mi><mo fence="false">|</mo><mi>s</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">i^{*}\leftarrow\text{SampleDimension}(P(i|s))</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_italic">2. LLM generates refinement and new alpha formula  */</span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\text{context}\leftarrow\text{GetNodeRefinementContext}(s_{\text{selected}},\mathcal{T})" class="ltx_Math" display="inline" id="alg1.m31" intent=":literal"><semantics><mrow><mtext>context</mtext><mo stretchy="false">←</mo><mrow><mtext>GetNodeRefinementContext</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mtext>selected</mtext></msub><mo>,</mo><mi class="ltx_font_mathcaligraphic">𝒯</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{context}\leftarrow\text{GetNodeRefinementContext}(s_{\text{selected}},\mathcal{T})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m32" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Parent, children, siblings history </span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\text{examples}\leftarrow\text{SampleEffectiveAlphas}(\mathcal{F}_{zoo})" class="ltx_Math" display="inline" id="alg1.m33" intent=":literal"><semantics><mrow><mtext>examples</mtext><mo stretchy="false">←</mo><mrow><mtext>SampleEffectiveAlphas</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{examples}\leftarrow\text{SampleEffectiveAlphas}(\mathcal{F}_{zoo})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m34" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Few-shot examples </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="d_{s,i^{*}},f_{new}\leftarrow LLM.\text{GenerateRefinedAlpha}(s_{\text{selected}}.f,i^{*},\text{context},\text{examples},\mathcal{G}_{\text{forbidden}})" class="ltx_math_unparsed" display="inline" id="alg1.m35" intent=":literal"><semantics><mrow><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><mo>,</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">←</mo><mi>L</mi><mi>L</mi><mi>M</mi><mo lspace="0em" rspace="0.167em">.</mo><mtext>GenerateRefinedAlpha</mtext><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mtext>selected</mtext></msub><mo lspace="0em" rspace="0.167em">.</mo><mi>f</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup><mo>,</mo><mtext>context</mtext><mo>,</mo><mtext>examples</mtext><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">d_{s,i^{*}},f_{new}\leftarrow LLM.\text{GenerateRefinedAlpha}(s_{\text{selected}}.f,i^{*},\text{context},\text{examples},\mathcal{G}_{\text{forbidden}})</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_italic">3. Validate and revise formula iteratively  */</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<span class="ltx_text ltx_font_bold">while</span> <em class="ltx_emph ltx_font_italic"><math alttext="\neg\text{IsValid}(f_{new})" class="ltx_Math" display="inline" id="alg1.m36" intent=":literal"><semantics><mrow><mo rspace="0.167em">¬</mo><mrow><mtext class="ltx_mathvariant_italic">IsValid</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\neg\text{IsValid}(f_{new})</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold">do</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\text{feedback}\leftarrow\text{GetInvalidityReason}(f_{new})" class="ltx_Math" display="inline" id="alg1.m37" intent=":literal"><semantics><mrow><mtext>feedback</mtext><mo stretchy="false">←</mo><mrow><mtext>GetInvalidityReason</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{feedback}\leftarrow\text{GetInvalidityReason}(f_{new})</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="d_{s,i^{*}},f_{new}\leftarrow LLM.\text{CorrectAlphaFormula}(d_{s,i^{*}},\text{feedback},\text{context},\text{examples},\mathcal{G}_{\text{forbidden}})" class="ltx_Math" display="inline" id="alg1.m38" intent=":literal"><semantics><mrow><mrow><mrow><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><mo>,</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub></mrow><mo stretchy="false">←</mo><mrow><mi>L</mi><mo lspace="0em" rspace="0em">​</mo><mi>L</mi><mo lspace="0em" rspace="0em">​</mo><mi>M</mi></mrow></mrow><mo lspace="0em" rspace="0.167em">.</mo><mrow><mtext>CorrectAlphaFormula</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>d</mi><mrow><mi>s</mi><mo>,</mo><msup><mi>i</mi><mo>∗</mo></msup></mrow></msub><mo>,</mo><mtext>feedback</mtext><mo>,</mo><mtext>context</mtext><mo>,</mo><mtext>examples</mtext><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">d_{s,i^{*}},f_{new}\leftarrow LLM.\text{CorrectAlphaFormula}(d_{s,i^{*}},\text{feedback},\text{context},\text{examples},\mathcal{G}_{\text{forbidden}})</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  end while
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>   <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Evaluation of New Alpha<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\bm{E}_{new}\leftarrow\text{MultiDimEvaluate}(f_{new},\mathcal{F}_{zoo})" class="ltx_Math" display="inline" id="alg1.m39" intent=":literal"><semantics><mrow><msub><mi>𝑬</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">←</mo><mrow><mtext>MultiDimEvaluate</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bm{E}_{new}\leftarrow\text{MultiDimEvaluate}(f_{new},\mathcal{F}_{zoo})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m40" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">As in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.SSx3" title="Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>, using Eq.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E6" title="In Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">6</span></a> and LLM for overfitting </span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="S(f_{new})\leftarrow\text{AggregateScore}(\bm{E}_{new})" class="ltx_Math" display="inline" id="alg1.m41" intent=":literal"><semantics><mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">←</mo><mrow><mtext>AggregateScore</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝑬</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">S(f_{new})\leftarrow\text{AggregateScore}(\bm{E}_{new})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m42" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Calculate overall score using Eq.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E8" title="In Multi-Dimensional Alpha Evaluation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">8</span></a> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">28</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">29</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_italic">Create new node and add to tree  */</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">30</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="s_{new}\leftarrow\text{CreateNode}(f_{new},\bm{E}_{new},S(f_{new}))" class="ltx_Math" display="inline" id="alg1.m43" intent=":literal"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">←</mo><mrow><mtext>CreateNode</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo>,</mo><msub><mi>𝑬</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo>,</mo><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">s_{new}\leftarrow\text{CreateNode}(f_{new},\bm{E}_{new},S(f_{new}))</annotation></semantics></math>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\text{AddChildNode}(\mathcal{T},s_{\text{selected}},s_{new})" class="ltx_Math" display="inline" id="alg1.m44" intent=":literal"><semantics><mrow><mtext>AddChildNode</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">𝒯</mi><mo>,</mo><msub><mi>s</mi><mtext>selected</mtext></msub><mo>,</mo><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{AddChildNode}(\mathcal{T},s_{\text{selected}},s_{new})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m45" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">The action leading to <math alttext="s_{new}" class="ltx_Math" display="inline" id="alg1.m46" intent=":literal"><semantics><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><annotation encoding="application/x-tex">s_{new}</annotation></semantics></math> is implicitly defined </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">31</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">32</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">33</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>   <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Backpropagation Phase<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">34</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<span class="ltx_text ltx_font_bold">for</span> <em class="ltx_emph ltx_font_italic"><math alttext="(s_{k},a_{k})" class="ltx_Math" display="inline" id="alg1.m47" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mi>k</mi></msub><mo>,</mo><msub><mi>a</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s_{k},a_{k})</annotation></semantics></math> in <math alttext="P_{\text{path}}" class="ltx_Math" display="inline" id="alg1.m48" intent=":literal"><semantics><msub><mi>P</mi><mtext class="ltx_mathvariant_italic"><em class="ltx_emph" style="font-size:70%;">path</em></mtext></msub><annotation encoding="application/x-tex">P_{\text{path}}</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold">do</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">35</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="N_{s_{k}}\leftarrow N_{s_{k}}+1" class="ltx_Math" display="inline" id="alg1.m49" intent=":literal"><semantics><mrow><msub><mi>N</mi><msub><mi>s</mi><mi>k</mi></msub></msub><mo stretchy="false">←</mo><mrow><msub><mi>N</mi><msub><mi>s</mi><mi>k</mi></msub></msub><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">N_{s_{k}}\leftarrow N_{s_{k}}+1</annotation></semantics></math>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="Q(s_{k},a_{k})\leftarrow\max(Q(s_{k},a_{k}),S(f_{new}))" class="ltx_Math" display="inline" id="alg1.m50" intent=":literal"><semantics><mrow><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mi>k</mi></msub><mo>,</mo><msub><mi>a</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">←</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Q</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>s</mi><mi>k</mi></msub><mo>,</mo><msub><mi>a</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Q(s_{k},a_{k})\leftarrow\max(Q(s_{k},a_{k}),S(f_{new}))</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m51" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Update Q-value as per Eq.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#S3.E10" title="In Backpropagation ‣ 3 Methodology ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">10</span></a> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">36</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">37</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  end for
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">38</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> <math alttext="N_{s_{new}}\leftarrow N_{s_{new}}+1" class="ltx_Math" display="inline" id="alg1.m52" intent=":literal"><semantics><mrow><msub><mi>N</mi><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub></msub><mo stretchy="false">←</mo><mrow><msub><mi>N</mi><msub><mi>s</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub></msub><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">N_{s_{new}}\leftarrow N_{s_{new}}+1</annotation></semantics></math>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">39</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">40</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 1ex
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>   <span class="ltx_text ltx_font_italic">/* </span><span class="ltx_text ltx_font_bold ltx_font_italic">Repository and System Updates<span class="ltx_text ltx_font_medium"> */</span></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">41</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<span class="ltx_text ltx_font_bold">if</span> <em class="ltx_emph ltx_font_italic"><math alttext="\text{GetEffectivenessScore}(\bm{E}_{new})\geq\theta_{\text{eff}}" class="ltx_Math" display="inline" id="alg1.m53" intent=":literal"><semantics><mrow><mrow><mtext class="ltx_mathvariant_italic">GetEffectivenessScore</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐄</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>≥</mo><msub><mi>θ</mi><mtext class="ltx_mathvariant_italic"><em class="ltx_emph" style="font-size:70%;">eff</em></mtext></msub></mrow><annotation encoding="application/x-tex">\text{GetEffectivenessScore}(\bm{E}_{new})\geq\theta_{\text{eff}}</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold">then</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">42</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\mathcal{F}_{zoo}\leftarrow\mathcal{F}_{zoo}\cup\{f_{new}\}" class="ltx_Math" display="inline" id="alg1.m54" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">←</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo>∪</mo><mrow><mo stretchy="false">{</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">}</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{F}_{zoo}\leftarrow\mathcal{F}_{zoo}\cup\{f_{new}\}</annotation></semantics></math>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="\mathcal{G}_{\text{forbidden}}\leftarrow\text{UpdateForbiddenStructures}(\mathcal{F}_{zoo})" class="ltx_Math" display="inline" id="alg1.m55" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mtext>forbidden</mtext></msub><mo stretchy="false">←</mo><mrow><mtext>UpdateForbiddenStructures</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}_{\text{forbidden}}\leftarrow\text{UpdateForbiddenStructures}(\mathcal{F}_{zoo})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m56" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Update based on FSA logic </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">43</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">44</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  end if
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">45</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> <span class="ltx_text ltx_font_bold">if</span> <em class="ltx_emph ltx_font_italic"><math alttext="S(f_{new})&gt;S_{\text{max}}" class="ltx_Math" display="inline" id="alg1.m57" intent=":literal"><semantics><mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>&gt;</mo><msub><mi>S</mi><mtext class="ltx_mathvariant_italic"><em class="ltx_emph" style="font-size:70%;">max</em></mtext></msub></mrow><annotation encoding="application/x-tex">S(f_{new})&gt;S_{\text{max}}</annotation></semantics></math></em> <span class="ltx_text ltx_font_bold">then</span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="B\leftarrow B+b" class="ltx_Math" display="inline" id="alg1.m58" intent=":literal"><semantics><mrow><mi>B</mi><mo stretchy="false">←</mo><mrow><mi>B</mi><mo>+</mo><mi>b</mi></mrow></mrow><annotation encoding="application/x-tex">B\leftarrow B+b</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m59" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Increase total search budget </span>
</div>
<div class="ltx_listingline"> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
<math alttext="S_{\text{max}}\leftarrow S(f_{new})" class="ltx_Math" display="inline" id="alg1.m60" intent=":literal"><semantics><mrow><msub><mi>S</mi><mtext>max</mtext></msub><mo stretchy="false">←</mo><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>n</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>w</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">S_{\text{max}}\leftarrow S(f_{new})</annotation></semantics></math> <span class="ltx_text ltx_font_italic"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.m61" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> </span><span class="ltx_text ltx_font_italic">Update overall max score </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">46</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 

</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">47</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span>  end if
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">48</span> <span class="ltx_rule" style="width:1px;height:100%;--ltx-bg-color:black;display:inline-block;">&nbsp;</span> 
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">49</span> end for
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">50</span><span class="ltx_text ltx_font_bold">return</span> <math alttext="\mathcal{F}_{zoo}" class="ltx_Math" display="inline" id="alg1.m62" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℱ</mi><mrow><mi>z</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{zoo}</annotation></semantics></math>
</div>
<div class="ltx_listingline">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm&nbsp;1</span> </span>LLM-Guided MCTS Framework for Automated Alpha Mining</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Experimental Setup Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A7.SSx1">
<h3 class="ltx_title ltx_title_subsection">Dataset</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx1.p1">
<p class="ltx_p">All empirical data in this study are obtained through the Qlib platform&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib36" title="">2020</a>)</cite>, an open-source framework for quantitative financial research. We utilize the daily-frequency data for the Chinese A-shares market as provided by Qlib.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx1.p2">
<p class="ltx_p">To ensure maximum reproducibility and transparency, we deliberately refrain from applying any additional data filtering, preprocessing, or adjustments. The data is thus used in its original form as sourced from the platform. Furthermore, to maintain a consistent experimental environment, all backtesting simulations are implemented and executed within the Qlib framework. This leverages its integrated backtesting engine and ensures a standardized evaluation process for all experiments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx2">
<h3 class="ltx_title ltx_title_subsection">Hyperparameter Configurations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A7.SSx2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Temperature Parameter of LLMs</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx2.SSS0.Px1.p1">
<p class="ltx_p">When generating alpha portraits and alpha formulas, the temperature is set to 1.0; when correcting illegal alpha formulas, the temperature is adjusted to 0.8; and when scoring the overfitting risk of alpha, the temperature is set to 0.1.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">MCTS</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx2.SSS0.Px2.p1">
<p class="ltx_p">We set the exploration weight <math alttext="c" class="ltx_Math" display="inline" id="A7.SSx2.SSS0.Px2.p1.m1" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> in the UCT criterion to 1. For each search tree, the initial search budget is 3, and whenever a node achieves a higher score than previously, the search budget is increased by 1.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Effective Alpha Check</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx2.SSS0.Px3.p1">
<p class="ltx_p">Upon the completion of a search tree’s expansion, we examine the effectiveness of the alpha formulas corresponding to all nodes within the tree. Those alphas that pass the effectiveness check are added to the effective alpha repository. The specific criteria for determining effectiveness are as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx2.SSS0.Px3.p2">
<ul class="ltx_itemize" id="A7.I1">
<li class="ltx_item" id="A7.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I1.i1.p1">
<p class="ltx_p">Basic Criteria: <math alttext="\text{RankIC}\geq 0.015" class="ltx_Math" display="inline" id="A7.I1.i1.p1.m1" intent=":literal"><semantics><mrow><mtext>RankIC</mtext><mo>≥</mo><mn>0.015</mn></mrow><annotation encoding="application/x-tex">\text{RankIC}\geq 0.015</annotation></semantics></math>, <math alttext="\text{RankIR}\geq 0.3" class="ltx_Math" display="inline" id="A7.I1.i1.p1.m2" intent=":literal"><semantics><mrow><mtext>RankIR</mtext><mo>≥</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">\text{RankIR}\geq 0.3</annotation></semantics></math>, <math alttext="R_{\mathrm{RankIC}}\leq 0.95" class="ltx_Math" display="inline" id="A7.I1.i1.p1.m3" intent=":literal"><semantics><mrow><msub><mi>R</mi><mi>RankIC</mi></msub><mo>≤</mo><mn>0.95</mn></mrow><annotation encoding="application/x-tex">R_{\mathrm{RankIC}}\leq 0.95</annotation></semantics></math>, <math alttext="R_{\mathrm{RankIR}}\leq 0.95" class="ltx_Math" display="inline" id="A7.I1.i1.p1.m4" intent=":literal"><semantics><mrow><msub><mi>R</mi><mi>RankIR</mi></msub><mo>≤</mo><mn>0.95</mn></mrow><annotation encoding="application/x-tex">R_{\mathrm{RankIR}}\leq 0.95</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A7.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I1.i2.p1">
<p class="ltx_p">Turnover Criteria: <math alttext="\text{Daily Turnover}\leq 1.6" class="ltx_Math" display="inline" id="A7.I1.i2.p1.m1" intent=":literal"><semantics><mrow><mtext>Daily Turnover</mtext><mo>≤</mo><mn>1.6</mn></mrow><annotation encoding="application/x-tex">\text{Daily Turnover}\leq 1.6</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A7.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I1.i3.p1">
<p class="ltx_p">Diversity Criteria: The maximum correlation with the alpha within the effective alpha repository is less than 0.8.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A7.SSx2.SSS0.Px3.p3">
<p class="ltx_p">After the mining process is completed, we select the top <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx2.SSS0.Px3.p3.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> alphas with the highest RankIR from the effective alpha repository to form the final alpha set. In our experiments, <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx2.SSS0.Px3.p3.m2" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> is set to 10, 50, and 100.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Evaluation Score</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx2.SSS0.Px4.p1">
<p class="ltx_p">Here, we present the backtesting metrics utilized to calculate scores for evaluation dimensions: Effectiveness: RankIC, Stability: RankIR, Turnover: Daily turnover rate, Diversity: Maximum correlation with alphas in the effective alpha repository.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx2.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Other Settings</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx2.SSS0.Px5.p1">
<p class="ltx_p">When generating alpha refinement suggestions, the number of few-shot examples is set to 1; in the Frequent Subtree Avoidance method, the number of frequent subtrees to be avoided is set to 3. When calculating the selection probability for each evaluation dimension, the temperature parameter is set to <math alttext="T=1" class="ltx_Math" display="inline" id="A7.SSx2.SSS0.Px5.p1.m1" intent=":literal"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T=1</annotation></semantics></math>. Furthermore, during the generation of refinement suggestions for the Effectiveness and Stability dimensions, the correlation filtering ratio is maintained at <math alttext="\eta=50\%" class="ltx_Math" display="inline" id="A7.SSx2.SSS0.Px5.p1.m2" intent=":literal"><semantics><mrow><mi>η</mi><mo>=</mo><mrow><mn>50</mn><mo>%</mo></mrow></mrow><annotation encoding="application/x-tex">\eta=50\%</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SSx3">
<h3 class="ltx_title ltx_title_subsection">Model Settings</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx3.p1">
<p class="ltx_p">To ensure a fair comparison when evaluating alpha pools derived from different methods, we utilize fixed hyperparameters and consistent training strategies for all models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx3.p2">
<p class="ltx_p">For the LightGBM model, we configure it with 32 leaves per tree and a total of 200 estimators. The maximum depth of each tree is limited to 8, and the learning rate is set to 0.05. Both L1 and L2 regularization coefficients are fixed at 0.1 to control model complexity. In line with a simple hold-out approach, the model is trained on the entire training dataset (2011/01/01–2020/12/31) for the predetermined number of boosting rounds, without using a separate validation set for early stopping. The fully trained model is then evaluated on the final test set.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx3.p3">
<p class="ltx_p">Similarly, we train the Multi-Layer Perceptron (MLP) models with a consistent configuration. The MLP architecture consists of three hidden layers with 256, 128, and 64 units, respectively. A dropout rate of 0.3 is applied after each hidden layer to mitigate overfitting. We employ the Adam optimizer with a learning rate of 0.001 and a batch size of 1024, using Mean Squared Error (MSE) as the loss function. To prevent overfitting, early stopping with a patience of 5 epochs is implemented. For this purpose, we partition the data, designating the final year of the training period (2020/01/01–2020/12/31) as the validation set. The model is therefore trained on data from 2011 through 2019, with its performance on the validation set monitored to determine the stopping point.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx4">
<h3 class="ltx_title ltx_title_subsection">Backtesting Strategy</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx4.p1">
<p class="ltx_p">The top-<math alttext="k" class="ltx_Math" display="inline" id="A7.SSx4.p1.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>/drop-<math alttext="n" class="ltx_Math" display="inline" id="A7.SSx4.p1.m2" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> portfolio construction strategy employed in our backtests operates as follows. On each trading day, an equal-weight portfolio is formed by selecting the top <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx4.p1.m3" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> stocks based on the predictive signals from the trained models. We set <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx4.p1.m4" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> to represent the top 10% of the respective stock pool (e.g., <math alttext="k=30" class="ltx_Math" display="inline" id="A7.SSx4.p1.m5" intent=":literal"><semantics><mrow><mi>k</mi><mo>=</mo><mn>30</mn></mrow><annotation encoding="application/x-tex">k=30</annotation></semantics></math> for the CSI300 index and <math alttext="k=100" class="ltx_Math" display="inline" id="A7.SSx4.p1.m6" intent=":literal"><semantics><mrow><mi>k</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">k=100</annotation></semantics></math> for the CSI1000 index). To manage turnover and limit trading costs, a maximum of <math alttext="n" class="ltx_Math" display="inline" id="A7.SSx4.p1.m7" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> stocks are bought or sold daily. The value of <math alttext="n" class="ltx_Math" display="inline" id="A7.SSx4.p1.m8" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> is determined by <math alttext="n=k/w" class="ltx_Math" display="inline" id="A7.SSx4.p1.m9" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mi>k</mi><mo>/</mo><mi>w</mi></mrow></mrow><annotation encoding="application/x-tex">n=k/w</annotation></semantics></math>, where <math alttext="w" class="ltx_Math" display="inline" id="A7.SSx4.p1.m10" intent=":literal"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math> is the prediction horizon in days (e.g., for a 10-day return prediction on CSI300, <math alttext="n=30/10=3" class="ltx_Math" display="inline" id="A7.SSx4.p1.m11" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>30</mn><mo>/</mo><mn>10</mn></mrow><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">n=30/10=3</annotation></semantics></math>). This strategy ensures that the theoretical complete turnover period of the portfolio aligns with the prediction horizon. A conservative transaction cost of <math alttext="0.15\%" class="ltx_Math" display="inline" id="A7.SSx4.p1.m12" intent=":literal"><semantics><mrow><mn>0.15</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">0.15\%</annotation></semantics></math> per trade is incorporated to ensure a realistic performance assessment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx5">
<h3 class="ltx_title ltx_title_subsection">Environment</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx5.p1">
<p class="ltx_p">All the experiments are conducted with following settings:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx5.p2">
<ul class="ltx_itemize" id="A7.I2">
<li class="ltx_item" id="A7.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I2.i1.p1">
<p class="ltx_p">CPU: AMD EPYC 7642 48-Core Processor</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A7.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I2.i2.p1">
<p class="ltx_p">GPU: NVIDIA GeForce RTX 3080Ti</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A7.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I2.i3.p1">
<p class="ltx_p">Operating system: Ubuntu 20.04.3 LTS</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A7.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A7.I2.i4.p1">
<p class="ltx_p">Software versions: Python 3.8.5; Numpy 1.24.4; Pandas 1.5.2; Pytorch 2.2.2; Openai 1.57.4</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx6">
<h3 class="ltx_title ltx_title_subsection">Predictive Performance Evaluation Metrics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx6.p1">
<p class="ltx_p">To evaluate the predictive performance of the model (trained on the mined alpha set) in forecasting stock returns, we employ several standard metrics: the Information Coefficient (IC), Rank Information Coefficient (RankIC), Annualized Excess Return (AER), and Information Ratio (IR). Let <math alttext="f_{i,t}" class="ltx_Math" display="inline" id="A7.SSx6.p1.m1" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">f_{i,t}</annotation></semantics></math> denote the predicted returns for asset <math alttext="i" class="ltx_Math" display="inline" id="A7.SSx6.p1.m2" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> at time <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.p1.m3" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> (out of <math alttext="N_{t}" class="ltx_Math" display="inline" id="A7.SSx6.p1.m4" intent=":literal"><semantics><msub><mi>N</mi><mi>t</mi></msub><annotation encoding="application/x-tex">N_{t}</annotation></semantics></math> assets in the universe at time <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.p1.m5" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>), and <math alttext="r_{i,t+1}" class="ltx_Math" display="inline" id="A7.SSx6.p1.m6" intent=":literal"><semantics><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><annotation encoding="application/x-tex">r_{i,t+1}</annotation></semantics></math> be its realized total return over the subsequent period (e.g., from <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.p1.m7" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> to <math alttext="t+1" class="ltx_Math" display="inline" id="A7.SSx6.p1.m8" intent=":literal"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t+1</annotation></semantics></math>). The evaluation spans a total of <math alttext="T" class="ltx_Math" display="inline" id="A7.SSx6.p1.m9" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> time periods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A7.SSx6.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Information Coefficient (IC)</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx6.SSS0.Px1.p1">
<p class="ltx_p">The IC measures the linear correlation between predicted returns and subsequent total returns. It is calculated for each cross-section at time <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px1.p1.m1" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> (<math alttext="\text{IC}_{t}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px1.p1.m2" intent=":literal"><semantics><msub><mtext>IC</mtext><mi>t</mi></msub><annotation encoding="application/x-tex">\text{IC}_{t}</annotation></semantics></math>) and then averaged over all <math alttext="T" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px1.p1.m3" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> periods:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A11.EGx3">
<tbody id="A7.E13"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{IC}_{t}" class="ltx_Math" display="inline" id="A7.E13.m1" intent=":literal"><semantics><msub><mtext>IC</mtext><mi>t</mi></msub><annotation encoding="application/x-tex">\displaystyle\text{IC}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\sum_{i=1}^{N_{t}}(f_{i,t}-\bar{f}_{t})(r_{i,t+1}-\bar{r}_{t+1})}{\sqrt{\sum_{i=1}^{N_{t}}(f_{i,t}-\bar{f}_{t})^{2}}\sqrt{\sum_{i=1}^{N_{t}}(r_{i,t+1}-\bar{r}_{t+1})^{2}}}" class="ltx_Math" display="inline" id="A7.E13.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mstyle displaystyle="true"><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>t</mi></msub></msubsup><mrow><mrow><mo lspace="0em" stretchy="false">(</mo><mrow><msub><mi>f</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>−</mo><msub><mover accent="true"><mi>f</mi><mo>¯</mo></mover><mi>t</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo>−</mo><msub><mover accent="true"><mi>r</mi><mo>¯</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><msqrt><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>t</mi></msub></msubsup><msup><mrow><mo lspace="0em" stretchy="false">(</mo><mrow><msub><mi>f</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>−</mo><msub><mover accent="true"><mi>f</mi><mo>¯</mo></mover><mi>t</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></msqrt><mo lspace="0em" rspace="0em">​</mo><msqrt><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>t</mi></msub></msubsup><msup><mrow><mo lspace="0em" stretchy="false">(</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo>−</mo><msub><mover accent="true"><mi>r</mi><mo>¯</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{\sum_{i=1}^{N_{t}}(f_{i,t}-\bar{f}_{t})(r_{i,t+1}-\bar{r}_{t+1})}{\sqrt{\sum_{i=1}^{N_{t}}(f_{i,t}-\bar{f}_{t})^{2}}\sqrt{\sum_{i=1}^{N_{t}}(r_{i,t+1}-\bar{r}_{t+1})^{2}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
<tbody id="A7.E14"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath">IC</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{1}{T}\sum_{t=1}^{T}\text{IC}_{t}" class="ltx_Math" display="inline" id="A7.E14.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>T</mi></mfrac></mstyle><mo lspace="0em" rspace="0em">​</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><msub><mtext>IC</mtext><mi>t</mi></msub></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{1}{T}\sum_{t=1}^{T}\text{IC}_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(14)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\bar{f}_{t}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px1.p1.m4" intent=":literal"><semantics><msub><mover accent="true"><mi>f</mi><mo>¯</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\bar{f}_{t}</annotation></semantics></math> and <math alttext="\bar{r}_{t+1}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px1.p1.m5" intent=":literal"><semantics><msub><mover accent="true"><mi>r</mi><mo>¯</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\bar{r}_{t+1}</annotation></semantics></math> are the cross-sectional means of predicted signals and realized total returns, respectively. A higher IC indicates better predictive power.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx6.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Rank Information Coefficient (RankIC)</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx6.SSS0.Px2.p1">
<p class="ltx_p">The RankIC measures the monotonic relationship (Spearman’s rank correlation) between predicted returns and subsequent total returns. It is less sensitive to outliers than the Pearson correlation-based IC. Similar to IC, it is computed cross-sectionally and then averaged:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A11.EGx4">
<tbody id="A7.E15"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{RankIC}_{t}" class="ltx_Math" display="inline" id="A7.E15.m1" intent=":literal"><semantics><msub><mtext>RankIC</mtext><mi>t</mi></msub><annotation encoding="application/x-tex">\displaystyle\text{RankIC}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{Corr}(\text{rank}(f_{1,t},\dots,f_{N_{t},t}),\text{rank}(r_{1,t+1},\dots,r_{N_{t},t+1}))" class="ltx_Math" display="inline" id="A7.E15.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mrow><mtext>Corr</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mtext>rank</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mn>1</mn><mo>,</mo><mi>t</mi></mrow></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>f</mi><mrow><msub><mi>N</mi><mi>t</mi></msub><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mtext>rank</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>r</mi><mrow><msub><mi>N</mi><mi>t</mi></msub><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\text{Corr}(\text{rank}(f_{1,t},\dots,f_{N_{t},t}),\text{rank}(r_{1,t+1},\dots,r_{N_{t},t+1}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(15)</span></td>
</tr></tbody>
<tbody id="A7.E16"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath">RankIC</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{1}{T}\sum_{t=1}^{T}\text{RankIC}_{t}" class="ltx_Math" display="inline" id="A7.E16.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>T</mi></mfrac></mstyle><mo lspace="0em" rspace="0em">​</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><msub><mtext>RankIC</mtext><mi>t</mi></msub></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{1}{T}\sum_{t=1}^{T}\text{RankIC}_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(16)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\text{rank}(\cdot)" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px2.p1.m1" intent=":literal"><semantics><mrow><mtext>rank</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{rank}(\cdot)</annotation></semantics></math> denotes the operation that assigns ranks to the elements in the vector, and <math alttext="\text{Corr}(\cdot,\cdot)" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px2.p1.m2" intent=":literal"><semantics><mrow><mtext>Corr</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo rspace="0em">,</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Corr}(\cdot,\cdot)</annotation></semantics></math> is the Pearson correlation coefficient applied to these ranks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A7.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;">Instruments</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;"><math alttext="\Delta T" class="ltx_Math" display="inline" id="A7.T3.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">\Delta T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha Set</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">LightGBM</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">MLP</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">AER</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">AER</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="6" style="padding-left:4.0pt;padding-right:4.0pt;">CSI300</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha158</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0386</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0377</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0762</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.6713</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0337</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0329</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0307</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.2929</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha360</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0061</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0096</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0032</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0241</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0153</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0231</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0378</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.2847</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">AlphaAgent</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0298</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0244</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0383</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.3319</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0386</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0336</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0437</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.4411</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">RiskMiner</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0412</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0356</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0390</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">-0.5020</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0414</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0405</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0429</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.5726</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Ours</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0420</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0395</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0822</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.9397</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0422</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0408</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0737</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.8103</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha158</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0028</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0103</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0508</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">-0.3716</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0036</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0036</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0122</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">-0.1083</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha360</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0539</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0702</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0992</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">-0.5688</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0235</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0340</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0136</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.1553</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">AlphaAgent</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0372</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0339</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0412</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.3714</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0363</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0344</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0615</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.7084</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">RiskMiner</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0501</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0453</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0104</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.1151</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0407</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0395</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.0332</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">-0.3832</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Ours</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0417</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0401</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0826</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.0312</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0423</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0424</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.1315</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.4307</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="6" style="padding-left:4.0pt;padding-right:4.0pt;">CSI1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha158</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0610</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0627</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0316</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.3919</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0520</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0567</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.5877</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">1.5969</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha360</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0636</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0642</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0798</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.9242</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0550</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0608</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0689</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.7576</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">AlphaAgent</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0726</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0718</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0759</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.7111</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0752</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0659</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.1087</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">1.2615</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">RiskMiner</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0752</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0708</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0895</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.8997</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0712</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0635</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0709</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.7872</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Ours</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0804</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0729</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.1393</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.3577</span></td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0662</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0618</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.1204</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.2868</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha158</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0490</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0654</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0343</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.5068</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0380</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0373</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0545</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.7720</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Alpha360</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0420</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0567</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0171</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.2692</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0532</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0456</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0887</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">1.2959</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">AlphaAgent</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0778</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0692</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0756</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.9194</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0713</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0660</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0871</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">1.0454</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">RiskMiner</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0701</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0686</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.1022</td>
<td class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">1.1738</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0722</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0651</td>
<td class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">0.0843</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">1.0918</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Ours</td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0793</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0723</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.1326</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.2598</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0738</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.0710</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">0.1696</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold">1.5695</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Predictive performance comparison between our framework and other baselines. For AlphaAgent, RiskMiner and our framework, the size of alpha sets is fixed at 100.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="A7.SSx6.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Annualized Excess Return (AER)</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx6.SSS0.Px3.p1">
<p class="ltx_p">The AER measures the simple arithmetic average rate of excess return per year generated by a portfolio against a market benchmark. For our long-only strategy, at each rebalancing period <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m1" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>, we select the top-<math alttext="k" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m2" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> assets with the highest predicted returns <math alttext="f_{i,t}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m3" intent=":literal"><semantics><msub><mi>f</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">f_{i,t}</annotation></semantics></math>. The portfolio’s performance is based on the realized excess returns of these assets. Let <math alttext="r^{e}_{i,t+1}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m4" intent=":literal"><semantics><msubsup><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>e</mi></msubsup><annotation encoding="application/x-tex">r^{e}_{i,t+1}</annotation></semantics></math> denote the realized excess return of asset <math alttext="i" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m5" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> over the market benchmark for the period from <math alttext="t" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m6" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> to <math alttext="t+1" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m7" intent=":literal"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t+1</annotation></semantics></math>. Assuming the <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m8" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> selected assets are equally weighted, the portfolio’s excess return for the period <math alttext="t+1" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m9" intent=":literal"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t+1</annotation></semantics></math>, denoted <math alttext="R_{p,t+1}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p1.m10" intent=":literal"><semantics><msub><mi>R</mi><mrow><mi>p</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><annotation encoding="application/x-tex">R_{p,t+1}</annotation></semantics></math>, is the average of the individual assets’ excess returns:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx6.SSS0.Px3.p2">
<table class="ltx_equation ltx_eqn_table" id="A7.E17">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R_{p,t+1}=\frac{1}{k}\sum_{s\in\text{TopK}_{t}}r^{e}_{s,t+1}" class="ltx_Math" display="block" id="A7.E17.m1" intent=":literal"><semantics><mrow><msub><mi>R</mi><mrow><mi>p</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munder><mo movablelimits="false">∑</mo><mrow><mi>s</mi><mo>∈</mo><msub><mtext>TopK</mtext><mi>t</mi></msub></mrow></munder><msubsup><mi>r</mi><mrow><mi>s</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>e</mi></msubsup></mrow></mrow></mrow><annotation encoding="application/x-tex">R_{p,t+1}=\frac{1}{k}\sum_{s\in\text{TopK}_{t}}r^{e}_{s,t+1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(17)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A7.SSx6.SSS0.Px3.p3">
<p class="ltx_p">where <math alttext="\text{TopK}_{t}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p3.m1" intent=":literal"><semantics><msub><mtext>TopK</mtext><mi>t</mi></msub><annotation encoding="application/x-tex">\text{TopK}_{t}</annotation></semantics></math> is the set of <math alttext="k" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p3.m2" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> assets with the highest predicted returns based on <math alttext="\mathbf{f}_{t}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p3.m3" intent=":literal"><semantics><msub><mi>𝐟</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathbf{f}_{t}</annotation></semantics></math>. The AER, calculated as the arithmetic mean of these per-period portfolio excess returns scaled to an annual figure, over <math alttext="T_{p}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p3.m4" intent=":literal"><semantics><msub><mi>T</mi><mi>p</mi></msub><annotation encoding="application/x-tex">T_{p}</annotation></semantics></math> portfolio holding periods is then:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A7.SSx6.SSS0.Px3.p4">
<table class="ltx_equation ltx_eqn_table" id="A7.E18">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{AER}=\left(\frac{1}{T_{p}}\sum_{j=1}^{T_{p}}R_{p,j}\right)\times P" class="ltx_Math" display="block" id="A7.E18.m1" intent=":literal"><semantics><mrow><mtext>AER</mtext><mo>=</mo><mrow><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><msub><mi>T</mi><mi>p</mi></msub></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>p</mi></msub></munderover><msub><mi>R</mi><mrow><mi>p</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow></mrow><mo rspace="0.055em">)</mo></mrow><mo rspace="0.222em">×</mo><mi>P</mi></mrow></mrow><annotation encoding="application/x-tex">\text{AER}=\left(\frac{1}{T_{p}}\sum_{j=1}^{T_{p}}R_{p,j}\right)\times P</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(18)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A7.SSx6.SSS0.Px3.p5">
<p class="ltx_p">where <math alttext="R_{p,j}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m1" intent=":literal"><semantics><msub><mi>R</mi><mrow><mi>p</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">R_{p,j}</annotation></semantics></math> is the portfolio excess return over the benchmark in the <math alttext="j" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m2" intent=":literal"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th holding period, <math alttext="T_{p}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m3" intent=":literal"><semantics><msub><mi>T</mi><mi>p</mi></msub><annotation encoding="application/x-tex">T_{p}</annotation></semantics></math> is the total number of holding periods in the backtest, and <math alttext="P" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m4" intent=":literal"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math> is the number of holding periods in a year (e.g., <math alttext="P=252" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m5" intent=":literal"><semantics><mrow><mi>P</mi><mo>=</mo><mn>252</mn></mrow><annotation encoding="application/x-tex">P=252</annotation></semantics></math> for daily rebalancing, <math alttext="P=12" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px3.p5.m6" intent=":literal"><semantics><mrow><mi>P</mi><mo>=</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">P=12</annotation></semantics></math> for monthly rebalancing).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A7.SSx6.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Information Ratio (IR)</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A7.SSx6.SSS0.Px4.p1">
<p class="ltx_p">The IR measures the risk-adjusted excess return of the portfolio. It is defined as the Annualized Excess Return divided by its annualized volatility:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="A7.E19">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{IR}=\frac{\text{AER}}{\sigma(R_{p})\sqrt{P}}" class="ltx_Math" display="block" id="A7.E19.m1" intent=":literal"><semantics><mrow><mtext>IR</mtext><mo>=</mo><mfrac><mtext>AER</mtext><mrow><mi>σ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>p</mi></msub><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><msqrt><mi>P</mi></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{IR}=\frac{\text{AER}}{\sigma(R_{p})\sqrt{P}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(19)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where AER is the Annualized Excess Return calculated as per Eq.&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.E18" title="In Annualized Excess Return (AER) ‣ Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">18</span></a>), and <math alttext="\sigma(R_{p})" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px4.p1.m1" intent=":literal"><semantics><mrow><mi>σ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma(R_{p})</annotation></semantics></math> is the standard deviation of the <span class="ltx_text ltx_font_italic">per-period</span> portfolio excess returns <math alttext="R_{p,j}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px4.p1.m2" intent=":literal"><semantics><msub><mi>R</mi><mrow><mi>p</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">R_{p,j}</annotation></semantics></math> over the <math alttext="T_{p}" class="ltx_Math" display="inline" id="A7.SSx6.SSS0.Px4.p1.m3" intent=":literal"><semantics><msub><mi>T</mi><mi>p</mi></msub><annotation encoding="application/x-tex">T_{p}</annotation></semantics></math> holding periods. A higher IR indicates better return per unit of risk.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Additional Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A8.SSx1">
<h3 class="ltx_title ltx_title_subsection">Comparisons with Other Baselines</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A8.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">RankIC</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="8">LightGBM</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">-0.0055</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-0.0055</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0032</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0039</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0060</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.0072</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0022</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0005</td>
<td class="ltx_td ltx_align_center">0.0038</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0044</td>
<td class="ltx_td ltx_align_center">0.0006</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0015</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0094</td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">0.0106</span></td>
<td class="ltx_td ltx_align_center">0.0125</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0121</td>
<td class="ltx_td ltx_align_center">0.0126</td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">0.0134</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">0.0016</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0007</td>
<td class="ltx_td ltx_align_center">0.0086</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0060</td>
<td class="ltx_td ltx_align_center">0.0110</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0094</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0014</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0002</td>
<td class="ltx_td ltx_align_center">0.0106</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0104</td>
<td class="ltx_td ltx_align_center">0.0116</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0112</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0032</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0029</td>
<td class="ltx_td ltx_align_center">0.0098</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0111</td>
<td class="ltx_td ltx_align_center">0.0102</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0103</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0086</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0080</td>
<td class="ltx_td ltx_align_center">0.0085</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0095</td>
<td class="ltx_td ltx_align_center">0.0119</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0120</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0097</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0102</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0128</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.0129</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0132</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.0130</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="8">MLP</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">-0.0063</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-0.0070</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0048</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0051</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0041</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.0047</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">-0.0017</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.0018</td>
<td class="ltx_td ltx_align_center">0.0080</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0079</td>
<td class="ltx_td ltx_align_center">0.0031</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0036</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0089</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0094</td>
<td class="ltx_td ltx_align_center">0.0124</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0118</td>
<td class="ltx_td ltx_align_center">0.0117</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0112</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">-0.0001</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0000</td>
<td class="ltx_td ltx_align_center">0.0103</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0104</td>
<td class="ltx_td ltx_align_center">0.0070</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0073</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0029</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0035</td>
<td class="ltx_td ltx_align_center">0.0115</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0116</td>
<td class="ltx_td ltx_align_center">0.0113</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0114</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0029</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0029</td>
<td class="ltx_td ltx_align_center">0.0092</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0096</td>
<td class="ltx_td ltx_align_center">0.0120</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0113</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0079</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0080</td>
<td class="ltx_td ltx_align_center">0.0109</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0112</td>
<td class="ltx_td ltx_align_center">0.0111</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0108</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0092</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.0097</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0130</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.0127</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0125</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0122</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>The predictive performance alphas mined by different methods on the S&amp;P500 stock pool.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx1.p1">
<p class="ltx_p">To provide a comprehensive assessment of our proposed framework, we conduct additional comparisons against four benchmark alpha sets. The first two are the widely adopted handcrafted libraries <span class="ltx_text ltx_font_bold">Alpha158</span> and <span class="ltx_text ltx_font_bold">Alpha360</span>. Alpha158 consists of 158 factors derived from historical price and volume data for the Chinese A-share market, while Alpha360 is a more extensive set of 360 alphas. We construct these benchmark sets based on the information provided on the Qlib platform&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib36" title="">2020</a>)</cite>. As a third baseline, we include factors generated by <span class="ltx_text ltx_font_bold">AlphaAgent</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib26" title="">2025</a>)</cite>, a modern LLM-driven approach adapted from the RD-Agent&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib37" title="">2025</a>)</cite>. In contrast to purely search-based methods, AlphaAgent leverages human knowledge provided via natural language prompts to guide its discovery process. For our experiments, we direct it to generate 100 factors using the conceptual prompt of discovering “high-quality alpha factors for the Chinese A-share market.” As a final baseline, we incorporate <span class="ltx_text ltx_font_bold">RiskMiner</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ren et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib23" title="">2024</a>)</cite>, a state-of-the-art alpha mining method based on a risk-seeking Monte Carlo Tree Search.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx1.p2">
<p class="ltx_p">We evaluate the predictive performance of two distinct models: LightGBM and a 3-layer Multi-Layer Perceptron (MLP). Each model is trained using features from five separate sets: (i) Alpha158, (ii) Alpha360, (iii) the AlphaAgent-generated factors, (iv) the RiskMiner-generated factors, and (v) the alphas mined by our proposed method.
The comparative results are presented in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A7.T3" title="Table 3 ‣ Rank Information Coefficient (RankIC) ‣ Predictive Performance Evaluation Metrics ‣ Appendix G Experimental Setup Details ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">3</span></a>.
As illustrated, our method consistently achieves superior predictive performance across the various experimental settings and model architectures considered, underscoring its effectiveness in identifying more potent alpha signals compared to these established benchmarks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx2">
<h3 class="ltx_title ltx_title_subsection">Additional Results on the U.S. Stock Market</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx2.p1">
<p class="ltx_p">To further assess the generalizability and robustness of our proposed framework, we conduct additional experiments on the U.S. stock market, specifically focusing on the S&amp;P 500 index constituents. This allows us to validate whether the effectiveness of our alpha mining approach extends to different market environments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A8.SSx2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Experimental Setup</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx2.SSS0.Px1.p1">
<p class="ltx_p">We utilize the daily U.S. stock market data provided by the Qlib platform&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib36" title="">2020</a>)</cite>, which includes five fundamental features: open, high, low, close prices, and trading volume. The stock pool consists of the constituents of the S&amp;P 500 index. The prediction target is the 10-day forward return. Following a chronological split, the dataset is divided into a training period from 2007/01/01 to 2015/12/31, and a testing period from 2016/01/01 to 2020/10/10. All other experimental settings, including the alpha generation methods, model configurations (LightGBM and MLP), and evaluation metrics (IC and RankIC), remain consistent with those used for the Chinese market experiments described in the main paper.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A8.SSx2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx2.SSS0.Px2.p1">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T4" title="Table 4 ‣ Comparisons with Other Baselines ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">4</span></a> presents the predictive performance of alphas generated by our method and the baselines on the S&amp;P 500 dataset. The results demonstrate that our proposed framework maintains a strong competitive advantage in the U.S. market. Across both LightGBM and MLP models and for all alpha set sizes (10, 50, and 100), our method consistently achieves the highest or near-highest IC and RankIC scores. This suggests that the alphas mined by our framework are not only effective in the Chinese market but also possess robust predictive power in the more mature and competitive U.S. market, confirming the broad applicability of our approach.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A8.SSx3">
<h3 class="ltx_title ltx_title_subsection">Investigation of Potential Data Leakage in LLMs</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A8.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_tt">IC</td>
<td class="ltx_td ltx_align_center ltx_border_tt">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_tt">IR</td>
<td class="ltx_td ltx_align_center ltx_border_tt">RankIR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Random</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0126</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0179</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.095</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.148</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">GPT4.1</td>
<td class="ltx_td ltx_align_center">0.0130</td>
<td class="ltx_td ltx_align_center">0.0242</td>
<td class="ltx_td ltx_align_center">0.097</td>
<td class="ltx_td ltx_align_center">0.168</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Gemini2.0-flash-lite</td>
<td class="ltx_td ltx_align_center">0.0125</td>
<td class="ltx_td ltx_align_center">0.0231</td>
<td class="ltx_td ltx_align_center">0.094</td>
<td class="ltx_td ltx_align_center">0.180</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Deepseek-v3-0324</td>
<td class="ltx_td ltx_align_center">0.0122</td>
<td class="ltx_td ltx_align_center">0.0223</td>
<td class="ltx_td ltx_align_center">0.087</td>
<td class="ltx_td ltx_align_center">0.145</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0527</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0714</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.368</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.467</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Investigation of pre-existing knowledge (data leakage) in LLMs. We compare the performance of alphas generated by directly prompting various LLMs for high-performing formulas against a random baseline and our MCTS-based method. Metrics (IC, RankIC, IR, RankIR) are averages over 10 alphas per method. LLMs (GPT4.1, Gemini2.0-flash-lite, Deepseek-v3) are prompted for high-performing alphas (CSI300, 10-day return). ’Ours’ is our method with an alpha set size of 10.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx3.p1">
<p class="ltx_p">A critical concern when employing LLMs for tasks like alpha mining is the potential for data leakage. This refers to the possibility that LLMs’ training data might have inadvertently included information about historically well-performing alpha formulas, which could lead to an overestimation of their generative capabilities if they simply recall these formulas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx3.p2">
<p class="ltx_p">To investigate this, we design an experiment to explicitly probe whether pre-trained LLMs possess such inherent knowledge. We prompt three distinct LLM backbones—GPT-4.1, Gemini2.0-flash-lite, and Deepseek-v3—to generate alpha formulas specifically anticipated to yield high performance for 10-day forward return prediction on the A-share CSI300 stock pool. For each LLM and the Random baseline, we generate 10 distinct alpha formulas, and the performance metrics reported are averages across these 10 alphas. This setup directly attempts to leverage any pre-existing, “leaked” knowledge within the LLMs. The performance of alphas generated under this explicit instruction is compared against two baselines: (1) alphas generated randomly by an LLM (“Random”), and (2) alphas mined by our proposed framework (“Ours”).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx3.p3">
<p class="ltx_p">As shown in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T5" title="Table 5 ‣ Investigation of Potential Data Leakage in LLMs ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">5</span></a>, the average performance of alphas from LLMs explicitly prompted to generate high-performing expressions is not significantly different from the Random baseline. All these direct LLM generation approaches yield substantially lower performance across all metrics compared to our framework. These results suggest that the tested LLMs do not inherently leverage leaked knowledge of superior alpha formulas for this task, thereby alleviating data leakage concerns and highlighting the efficacy of our alpha mining framework.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx4">
<h3 class="ltx_title ltx_title_subsection">Sensitivity Analysis of LLM Backbone Choice</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx4.p1">
<p class="ltx_p">We evaluate the impact of different LLM backbones on our framework. We test several models from different series: GPT-4.1, Gemini-2.0-flash-lite, Gemini-2.5-flash-lite-preview-06-17, Deepseek-v3, and Qwen3-235b-a22b-2507. Experiments are conducted on the CSI300 stock pool, predicting 10-day forward returns with an alpha set size of 50. Results are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T6" title="Table 6 ‣ Sensitivity Analysis of LLM Backbone Choice ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">6</span></a>.
The findings reveal that the choice of LLM backbone leads to notable variations in the performance characteristics of the generated alpha sets. While each LLM may emphasize different aspects of alpha quality, our framework, when leveraging these advanced models, generally demonstrates performance that is competitive with or surpasses the best results of baselines.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A8.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4">LightGBM</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4">MLP</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Best of Baselines</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0388</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0378</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0680</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.7470</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0380</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0374</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0805</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.8414</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">GPT4.1</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0399</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0394</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0717</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.8283</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0436</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0425</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0661</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.7075</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Gemini-2.0-flash-lite</td>
<td class="ltx_td ltx_align_center">0.0376</td>
<td class="ltx_td ltx_align_center">0.0363</td>
<td class="ltx_td ltx_align_center">0.1037</td>
<td class="ltx_td ltx_align_center">1.1096</td>
<td class="ltx_td ltx_align_center">0.0389</td>
<td class="ltx_td ltx_align_center">0.0372</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.1734</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">1.9801</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Gemini-2.5-flash-lite-preview-06-17</td>
<td class="ltx_td ltx_align_center">0.0396</td>
<td class="ltx_td ltx_align_center">0.0390</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.1075</span></td>
<td class="ltx_td ltx_align_center">1.1885</td>
<td class="ltx_td ltx_align_center">0.0375</td>
<td class="ltx_td ltx_align_center">0.0373</td>
<td class="ltx_td ltx_align_center">0.1225</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.3898</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Deepseek-v3</td>
<td class="ltx_td ltx_align_center">0.0388</td>
<td class="ltx_td ltx_align_center">0.0386</td>
<td class="ltx_td ltx_align_center">0.1064</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">1.2144</span></td>
<td class="ltx_td ltx_align_center">0.0409</td>
<td class="ltx_td ltx_align_center">0.0401</td>
<td class="ltx_td ltx_align_center">0.1202</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.3732</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">Qwen3-235b-a22b-2507</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.0382</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.0372</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.0614</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.7769</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.0386</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.0380</td>
<td class="ltx_td ltx_align_center ltx_border_bb">0.1101</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">1.3177</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance comparison of our framework using different LLM backbones on the CSI300 dataset (10-day forward returns, alpha set size of 50). Best results are highlighted in <span class="ltx_text ltx_font_bold">bold</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A8.SSx5">
<h3 class="ltx_title ltx_title_subsection">Characteristics of Alphas at Varying MCTS Search Depths</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx5.p1">
<p class="ltx_p">In this section, we analysis the characteristics of alphas derived from nodes at different depths within the MCTS search tree. Alphas located at deeper levels of the tree undergo a greater number of refinement iterations. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.F14.sf1" title="In Figure 14 ‣ Sensitivity Analysis of Key Framework Hyperparameters ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">14(a)</span></a> illustrates how several key metrics evolve with MCTS depth: specifically, the average formula depth (depth of the formula’s tree representation), formula length (number of operators), in-sample (IS) and out-of-sample (OOS) RankIC, and the Overfitting Risk Score.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx5.p2">
<p class="ltx_p">We observe that as MCTS search depth increases, both the average formula depth and length initially rise before tending to stabilize. This stabilization is largely attributed to the Overfitting Risk Score, which penalizes overly complex formulas more prone to overfitting. Concurrently, both average IS and OOS RankIC exhibit a general upward trend with increasing depth, reflecting the efficacy of the refinement process. Conversely, the generalization gap (the difference between IS and OOS RankIC) tends to widen, indicating a decline in generalization performance as the formulas become more complex. This trend aligns with the behavior of the Overfitting Risk Score, suggesting that while refinement enhances performance, the associated risk of overfitting necessitates careful management, a role our ORS aims to fulfill.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A8.F13">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="A8.F13.fig1" style="width:208.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="736" id="A8.F13.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x8.png" width="830">
<figcaption class="ltx_caption ltx_centering"> (a) LightGBM Model</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="A8.F13.fig2" style="width:208.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="736" id="A8.F13.g2" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x9.png" width="830">
<figcaption class="ltx_caption ltx_centering"> (b) MLP Model</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Cumulative return curves of backtest using alphas generated by different methods.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A8.SSx6">
<h3 class="ltx_title ltx_title_subsection">Cumulative Return Curve Visualizations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx6.p1">
<p class="ltx_p">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.F13" title="Figure 13 ‣ Characteristics of Alphas at Varying MCTS Search Depths ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">13</span></a> presents the cumulative return curves derived from backtesting using alphas mined by different methods.
As illustrated, our proposed method consistently demonstrates superior performance, achieving the highest cumulative returns among the evaluated methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx7">
<h3 class="ltx_title ltx_title_subsection">Interpretability of Mined Alpha Formulas</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx7.p1">
<p class="ltx_p">In quantitative finance, interpretability refers to the ability to connect a mathematical factor to a coherent economic rationale explaining why it might predict cross-sectional returns. An interpretable alpha factor should be grounded in established financial theories or well-documented market phenomena, such as momentum, reversal, liquidity, or volatility effects (e.g., <cite class="ltx_cite ltx_citemacro_citep">(Efficiency <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib8" title="">1993</a>; De&nbsp;Bondt and Thaler <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib5" title="">1985</a>; Amihud and Mendelson <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib1" title="">1986</a>; French, Schwert, and Stambaugh <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#bib.bib10" title="">1987</a>)</cite>). Such grounding is valuable as it provides a plausible economic hypothesis for a factor’s potential efficacy. This enhances confidence that the factor captures a genuine market dynamic rather than a spurious, overfitted relationship unlikely to generalize out-of-sample.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A8.T7">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_justify ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p ltx_align_left"><span class="ltx_text ltx_font_bold">Alpha Formula</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">Ours</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_justify ltx_border_t">
<span class="ltx_inline-block">
<span class="ltx_block ltx_align_left ltx_minipage ltx_align_top" style="width:433.6pt;">
<span class="ltx_enumerate" id="A8.I1">
<span class="ltx_item" id="A8.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="A8.I1.i1.p1">
<span class="ltx_p"><math alttext="\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},20),30)" class="ltx_Math" display="inline" id="A8.I1.i1.p1.m1" intent=":literal"><semantics><mrow><mi>Zscore</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>close</mi><mo>−</mo><mi>vwap</mi></mrow><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},20),30)</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="A8.I1.i2.p1">
<span class="ltx_p"><math alttext="\mathrm{Std}(\mathrm{Pct}(\mathrm{vwap},20),25)\cdot\mathrm{Sum}(\mathrm{volume},40)/\mathrm{volume}" class="ltx_Math" display="inline" id="A8.I1.i2.p1.m1" intent=":literal"><semantics><mrow><mrow><mrow><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Pct</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>vwap</mi><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>25</mn><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><mi>Sum</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>40</mn><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><mi>volume</mi></mrow><annotation encoding="application/x-tex">\mathrm{Std}(\mathrm{Pct}(\mathrm{vwap},20),25)\cdot\mathrm{Sum}(\mathrm{volume},40)/\mathrm{volume}</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">3.</span>
<span class="ltx_para" id="A8.I1.i3.p1">
<span class="ltx_p"><math alttext="\mathrm{Corr}(\mathrm{close},\mathrm{volume},50)\cdot\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},30),40)" class="ltx_Math" display="inline" id="A8.I1.i3.p1.m1" intent=":literal"><semantics><mrow><mrow><mrow><mi>Corr</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>close</mi><mo>,</mo><mi>volume</mi><mo>,</mo><mn>50</mn><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><mi>Zscore</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>close</mi><mo>−</mo><mi>vwap</mi></mrow><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>40</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Corr}(\mathrm{close},\mathrm{volume},50)\cdot\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},30),40)</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I1.i4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">4.</span>
<span class="ltx_para" id="A8.I1.i4.p1">
<span class="ltx_p"><math alttext="\mathrm{Diff}(\mathrm{Ma}(\mathrm{volume},20),3)/\mathrm{Ma}(\mathrm{volume},60)" class="ltx_Math" display="inline" id="A8.I1.i4.p1.m1" intent=":literal"><semantics><mrow><mrow><mrow><mi>Diff</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><mi>Ma</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>60</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Diff}(\mathrm{Ma}(\mathrm{volume},20),3)/\mathrm{Ma}(\mathrm{volume},60)</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I1.i5" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">5.</span>
<span class="ltx_para" id="A8.I1.i5.p1">
<span class="ltx_p"><math alttext="\mathrm{Corr}(\mathrm{Pct}(\mathrm{close},10),\mathrm{Pct}(\mathrm{volume},10),10)\cdot\mathrm{Corr}(\mathrm{Pct}(\mathrm{close},30)," class="ltx_math_unparsed" display="inline" id="A8.I1.i5.p1.m1" intent=":literal"><semantics><mrow><mi>Corr</mi><mrow><mo stretchy="false">(</mo><mi>Pct</mi><mrow><mo stretchy="false">(</mo><mi>close</mi><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow><mo>,</mo><mi>Pct</mi><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow><mo>,</mo><mn>10</mn><mo rspace="0.055em" stretchy="false">)</mo></mrow><mo rspace="0.222em">⋅</mo><mi>Corr</mi><mrow><mo stretchy="false">(</mo><mi>Pct</mi><mrow><mo stretchy="false">(</mo><mi>close</mi><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow><mo>,</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Corr}(\mathrm{Pct}(\mathrm{close},10),\mathrm{Pct}(\mathrm{volume},10),10)\cdot\mathrm{Corr}(\mathrm{Pct}(\mathrm{close},30),</annotation></semantics></math>
<br class="ltx_break"><math alttext="\qquad\mathrm{Pct}(\mathrm{volume},30),30)\cdot\mathrm{Skew}(\mathrm{volume},20)" class="ltx_math_unparsed" display="inline" id="A8.I1.i5.p1.m2" intent=":literal"><semantics><mrow><mi>Pct</mi><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow><mo>,</mo><mn>30</mn><mo rspace="0.055em" stretchy="false">)</mo><mo rspace="0.222em">⋅</mo><mi>Skew</mi><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\qquad\mathrm{Pct}(\mathrm{volume},30),30)\cdot\mathrm{Skew}(\mathrm{volume},20)</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I1.i6" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">6.</span>
<span class="ltx_para" id="A8.I1.i6.p1">
<span class="ltx_p"><math alttext="\mathrm{Ma}(\mathrm{Corr}(\mathrm{volume},\mathrm{close},20)\cdot\mathrm{Skew}(\mathrm{high}-\mathrm{low},20),10)" class="ltx_Math" display="inline" id="A8.I1.i6.p1.m1" intent=":literal"><semantics><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mrow><mi>Corr</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mi>close</mi><mo>,</mo><mn>20</mn><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><mi>Skew</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>high</mi><mo>−</mo><mi>low</mi></mrow><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Ma}(\mathrm{Corr}(\mathrm{volume},\mathrm{close},20)\cdot\mathrm{Skew}(\mathrm{high}-\mathrm{low},20),10)</annotation></semantics></math></span>
</span></span>
</span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">GP</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_justify ltx_border_t">
<span class="ltx_inline-block">
<span class="ltx_block ltx_align_left ltx_minipage ltx_align_top" style="width:433.6pt;">
<span class="ltx_enumerate" id="A8.I2">
<span class="ltx_item" id="A8.I2.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="A8.I2.i1.p1">
<span class="ltx_p"><math alttext="\mathrm{Add}(\mathrm{Mul}(-0.01,\mathrm{volume}),\mathrm{Log}(\mathrm{Log}(\mathrm{close})))" class="ltx_Math" display="inline" id="A8.I2.i1.p1.m1" intent=":literal"><semantics><mrow><mi>Add</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Mul</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo>−</mo><mn>0.01</mn></mrow><mo>,</mo><mi>volume</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>close</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Add}(\mathrm{Mul}(-0.01,\mathrm{volume}),\mathrm{Log}(\mathrm{Log}(\mathrm{close})))</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I2.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="A8.I2.i2.p1">
<span class="ltx_p"><math alttext="\mathrm{Less}(\mathrm{Cov}(\mathrm{open},\mathrm{Add}(\mathrm{high},\mathrm{Div}(\mathrm{volume},-5)),10),\mathrm{Std}(\mathrm{Log}(\mathrm{close}),50))" class="ltx_Math" display="inline" id="A8.I2.i2.p1.m1" intent=":literal"><semantics><mrow><mi>Less</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Cov</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>open</mi><mo>,</mo><mrow><mi>Add</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>high</mi><mo>,</mo><mrow><mi>Div</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mrow><mo>−</mo><mn>5</mn></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>close</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>50</mn><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Less}(\mathrm{Cov}(\mathrm{open},\mathrm{Add}(\mathrm{high},\mathrm{Div}(\mathrm{volume},-5)),10),\mathrm{Std}(\mathrm{Log}(\mathrm{close}),50))</annotation></semantics></math></span>
</span></span>
</span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">DSO</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_justify ltx_border_t">
<span class="ltx_inline-block">
<span class="ltx_block ltx_align_left ltx_minipage ltx_align_top" style="width:433.6pt;">
<span class="ltx_enumerate" id="A8.I3">
<span class="ltx_item" id="A8.I3.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="A8.I3.i1.p1">
<span class="ltx_p"><math alttext="\mathrm{Greater}(\mathrm{volume},\mathrm{Med}(\mathrm{Sub}(\mathrm{Ma}(\mathrm{open},10),\mathrm{Med}(\mathrm{Std}(\mathrm{Sign}(\mathrm{close}),10),10)),10))" class="ltx_Math" display="inline" id="A8.I3.i1.p1.m1" intent=":literal"><semantics><mrow><mi>Greater</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mrow><mi>Med</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Sub</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>open</mi><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Med</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Sign</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>close</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Greater}(\mathrm{volume},\mathrm{Med}(\mathrm{Sub}(\mathrm{Ma}(\mathrm{open},10),\mathrm{Med}(\mathrm{Std}(\mathrm{Sign}(\mathrm{close}),10),10)),10))</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I3.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="A8.I3.i2.p1">
<span class="ltx_p"><math alttext="\mathrm{Cov}(\mathrm{Med}(\mathrm{Sign}(\mathrm{vwap}),50),5,20)" class="ltx_Math" display="inline" id="A8.I3.i2.p1.m1" intent=":literal"><semantics><mrow><mi>Cov</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Med</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Sign</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>vwap</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>50</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>5</mn><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Cov}(\mathrm{Med}(\mathrm{Sign}(\mathrm{vwap}),50),5,20)</annotation></semantics></math></span>
</span></span>
</span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">AlphaGen</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_justify ltx_border_t">
<span class="ltx_inline-block">
<span class="ltx_block ltx_align_left ltx_minipage ltx_align_top" style="width:433.6pt;">
<span class="ltx_enumerate" id="A8.I4">
<span class="ltx_item" id="A8.I4.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="A8.I4.i1.p1">
<span class="ltx_p"><math alttext="\mathrm{Corr}(\mathrm{Rank}(\mathrm{Diff}(\mathrm{Greater}(2.0,\mathrm{volume}),50),10),\mathrm{close},20)" class="ltx_Math" display="inline" id="A8.I4.i1.p1.m1" intent=":literal"><semantics><mrow><mi>Corr</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Rank</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Diff</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Greater</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>2.0</mn><mo>,</mo><mi>volume</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>50</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>close</mi><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Corr}(\mathrm{Rank}(\mathrm{Diff}(\mathrm{Greater}(2.0,\mathrm{volume}),50),10),\mathrm{close},20)</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I4.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="A8.I4.i2.p1">
<span class="ltx_p"><math alttext="\mathrm{Ma}(\mathrm{Greater}(\mathrm{Std}(\mathrm{Less}(0.01,\mathrm{Less}(\mathrm{Div}(\mathrm{Log}(\mathrm{high}),-2.0),-30)),1),-30),5)" class="ltx_Math" display="inline" id="A8.I4.i2.p1.m1" intent=":literal"><semantics><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Greater</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Less</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>0.01</mn><mo>,</mo><mrow><mi>Less</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Div</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>high</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mo>−</mo><mn>2.0</mn></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mo>−</mo><mn>30</mn></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mo>−</mo><mn>30</mn></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Ma}(\mathrm{Greater}(\mathrm{Std}(\mathrm{Less}(0.01,\mathrm{Less}(\mathrm{Div}(\mathrm{Log}(\mathrm{high}),-2.0),-30)),1),-30),5)</annotation></semantics></math></span>
</span></span>
</span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center">AlphaForge</td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t">
<span class="ltx_inline-block">
<span class="ltx_block ltx_align_left ltx_minipage ltx_align_top" style="width:433.6pt;">
<span class="ltx_enumerate" id="A8.I5">
<span class="ltx_item" id="A8.I5.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="A8.I5.i1.p1">
<span class="ltx_p"><math alttext="1/(1/(\mathrm{Diff}(\mathrm{Sin}(1/(\mathrm{Cos}(((0.01+\mathrm{Sin}(\mathrm{Tanh}(\mathrm{high})))/30)))),30)))" class="ltx_Math" display="inline" id="A8.I5.i1.p1.m1" intent=":literal"><semantics><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Diff</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Sin</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Cos</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>0.01</mn><mo>+</mo><mrow><mi>Sin</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Tanh</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>high</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow><mo>/</mo><mn>30</mn></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">1/(1/(\mathrm{Diff}(\mathrm{Sin}(1/(\mathrm{Cos}(((0.01+\mathrm{Sin}(\mathrm{Tanh}(\mathrm{high})))/30)))),30)))</annotation></semantics></math></span>
</span></span>
<span class="ltx_item" id="A8.I5.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="A8.I5.i2.p1">
<span class="ltx_p"><math alttext="(|(\mathrm{Cos}|(\mathrm{Tanh}(\mathrm{Sin}(\mathrm{Diff}(\mathrm{Sin}(30+\mathrm{low}),20)))|))+30.0|)^{2}" class="ltx_math_unparsed" display="inline" id="A8.I5.i2.p1.m1" intent=":literal"><semantics><msup><mrow><mo stretchy="false">(</mo><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mrow><mo stretchy="false">(</mo><mi>Cos</mi><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mrow><mo stretchy="false">(</mo><mi>Tanh</mi><mrow><mo stretchy="false">(</mo><mi>Sin</mi><mrow><mo stretchy="false">(</mo><mi>Diff</mi><mrow><mo stretchy="false">(</mo><mi>Sin</mi><mrow><mo stretchy="false">(</mo><mn>30</mn><mo>+</mo><mi>low</mi><mo stretchy="false">)</mo></mrow><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><mo>+</mo><mn>30.0</mn><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><annotation encoding="application/x-tex">(|(\mathrm{Cos}|(\mathrm{Tanh}(\mathrm{Sin}(\mathrm{Diff}(\mathrm{Sin}(30+\mathrm{low}),20)))|))+30.0|)^{2}</annotation></semantics></math></span>
</span></span>
</span>
</span>
</span>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Examples of alpha formulas mined by our framework and other non-LLM-based baselines. Each numbered item represents a distinct alpha formula.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx7.p2">
<p class="ltx_p">As shown in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T7" title="Table 7 ‣ Interpretability of Mined Alpha Formulas ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">7</span></a>, the formulas discovered by our framework can be deconstructed into components with plausible economic intuition. For instance, the formula <math alttext="\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},20),30)" class="ltx_Math" display="inline" id="A8.SSx7.p2.m1" intent=":literal"><semantics><mrow><mi>Zscore</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Ma</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>close</mi><mo>−</mo><mi>vwap</mi></mrow><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>30</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Zscore}(\mathrm{Ma}(\mathrm{close}-\mathrm{vwap},20),30)</annotation></semantics></math> can be interpreted as a measure of anomalous intraday momentum. It isolates the end-of-day buying or selling pressure (<math alttext="\mathrm{close}-\mathrm{vwap}" class="ltx_Math" display="inline" id="A8.SSx7.p2.m2" intent=":literal"><semantics><mrow><mi>close</mi><mo>−</mo><mi>vwap</mi></mrow><annotation encoding="application/x-tex">\mathrm{close}-\mathrm{vwap}</annotation></semantics></math>), smooths it into a short-term trend, and then uses a <math alttext="\mathrm{Zscore}" class="ltx_Math" display="inline" id="A8.SSx7.p2.m3" intent=":literal"><semantics><mi>Zscore</mi><annotation encoding="application/x-tex">\mathrm{Zscore}</annotation></semantics></math> to flag statistically significant deviations. Such abnormal pressure may signal informed trading or strong sentiment, potentially predicting continued returns. Another example, <math alttext="\mathrm{Std}(\mathrm{Pct}(\mathrm{vwap},20),25)\cdot\mathrm{Sum}(\mathrm{volume},40)/\mathrm{volume}" class="ltx_Math" display="inline" id="A8.SSx7.p2.m4" intent=":literal"><semantics><mrow><mrow><mrow><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Pct</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>vwap</mi><mo>,</mo><mn>20</mn><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mn>25</mn><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><mi>Sum</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>volume</mi><mo>,</mo><mn>40</mn><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><mi>volume</mi></mrow><annotation encoding="application/x-tex">\mathrm{Std}(\mathrm{Pct}(\mathrm{vwap},20),25)\cdot\mathrm{Sum}(\mathrm{volume},40)/\mathrm{volume}</annotation></semantics></math>, combines a measure of recent price volatility with a volume-based reversal signal. This formula identifies assets with high recent volatility but abnormally low current trading activity—a potential signature of trend exhaustion that often precedes price reversals. Other formulas generated by our framework are similarly composed of interpretable concepts like price-volume correlation and volume acceleration (see Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T7" title="Table 7 ‣ Interpretability of Mined Alpha Formulas ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">7</span></a>, formulas 3-6).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx7.p3">
<p class="ltx_p">In stark contrast, formulas from the baselines often exhibit fundamental issues that undermine their economic plausibility. A primary concern is dimensional inconsistency. For example, the GP formula <math alttext="\mathrm{Add}(\mathrm{Mul}(-0.01,\mathrm{volume}),\mathrm{Log}(\mathrm{Log}(\mathrm{close})))" class="ltx_Math" display="inline" id="A8.SSx7.p3.m1" intent=":literal"><semantics><mrow><mi>Add</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Mul</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo>−</mo><mn>0.01</mn></mrow><mo>,</mo><mi>volume</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Log</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>close</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Add}(\mathrm{Mul}(-0.01,\mathrm{volume}),\mathrm{Log}(\mathrm{Log}(\mathrm{close})))</annotation></semantics></math> attempts to add a term based on trading volume (unit: shares) to a transformed price term (unit: log-currency). This is analogous to adding mass to length, an operation that lacks a coherent real-world interpretation. Other methods produce expressions like <math alttext="\mathrm{Std}(\mathrm{Less}(...))" class="ltx_Math" display="inline" id="A8.SSx7.p3.m2" intent=":literal"><semantics><mrow><mi>Std</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Less</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">…</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{Std}(\mathrm{Less}(...))</annotation></semantics></math>, which calculates the standard deviation of a binary true/false series, a statistically questionable operation. The challenge is most acute for AlphaForge, whose unconstrained search yields formulas like <math alttext="1/(1/(\mathrm{Diff}(\mathrm{Sin}(1/(\mathrm{Cos}(...))))))" class="ltx_Math" display="inline" id="A8.SSx7.p3.m3" intent=":literal"><semantics><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Diff</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Sin</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Cos</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">…</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">1/(1/(\mathrm{Diff}(\mathrm{Sin}(1/(\mathrm{Cos}(...))))))</annotation></semantics></math>. The nested trigonometric functions applied to financial data are mathematically valid but have no clear basis in economic theory.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx7.p4">
<p class="ltx_p">While such formulas might fit the training data, their lack of a plausible economic basis makes them resemble “black boxes.” This is a critical drawback, as formulas that violate basic principles like dimensional consistency are at high risk of being spurious artifacts of overfitting. Consequently, they are less likely to be trusted by practitioners and integrated into investment strategies.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx8">
<h3 class="ltx_title ltx_title_subsection">Sensitivity Analysis of Key Framework Hyperparameters</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A8.F14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A8.F14.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="772" id="A8.F14.sf1.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x10.png" width="969">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Evolution of Alpha Characteristics with MCTS Search Depth.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A8.F14.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="745" id="A8.F14.sf2.g1" src="./Navigating the Alpha Jungle_ An LLM-Powered MCTS Framework for Formulaic Factor Mining_files/x11.png" width="968">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Impact of varying the initial MCTS search budget <math alttext="B" class="ltx_Math" display="inline" id="A8.F14.sf2.m3" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> and the UCT exploration weight <math alttext="c" class="ltx_Math" display="inline" id="A8.F14.sf2.m4" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> on the predictive performance.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Analysis of MCTS search characteristics and parameter sensitivity.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx8.p1">
<p class="ltx_p">In this section, we investigate the sensitivity of our framework to two key hyperparameters: the initial MCTS search budget <math alttext="B" class="ltx_Math" display="inline" id="A8.SSx8.p1.m1" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> (i.e., the initial target search number of MCTS) and the UCT exploration weight <math alttext="c" class="ltx_Math" display="inline" id="A8.SSx8.p1.m2" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>.
We conduct experiments using constituents of the CSI300 Index as the stock pool, targeting 10-day forward returns. The alpha set size is set to 50. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.F14.sf2" title="In Figure 14 ‣ Sensitivity Analysis of Key Framework Hyperparameters ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">14(b)</span></a> illustrates the model’s performance under various settings for these parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx8.p2">
<p class="ltx_p">For the initial MCTS search budget <math alttext="B" class="ltx_Math" display="inline" id="A8.SSx8.p2.m1" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>, a value of 3 yields the best performance. A larger <math alttext="B" class="ltx_Math" display="inline" id="A8.SSx8.p2.m2" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> can lead to excessive exploration of unpromising MCTS trees, consuming more computational resources without proportional gains. Conversely, a budget that is too small may result in insufficient exploration of potentially promising trees, thereby diminishing search efficacy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx8.p3">
<p class="ltx_p">Regarding the UCT exploration weight <math alttext="c" class="ltx_Math" display="inline" id="A8.SSx8.p3.m1" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>, our findings suggest that an excessively large value is detrimental. A higher <math alttext="c" class="ltx_Math" display="inline" id="A8.SSx8.p3.m2" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> biases the search towards more uniform exploration (randomness), potentially squandering refinement opportunities on underperforming alpha candidates.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A8.T8">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><span class="ltx_text ltx_font_bold">Time (h)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">GPU</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><span class="ltx_text ltx_font_bold">Input Tokens</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><span class="ltx_text ltx_font_bold">Output Tokens</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span class="ltx_text ltx_font_bold">Cost ($)</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">Server</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">API</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">GP</td>
<td class="ltx_td ltx_align_right ltx_border_t">28.30</td>
<td class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td class="ltx_td ltx_align_right ltx_border_t">0</td>
<td class="ltx_td ltx_align_right ltx_border_t">0</td>
<td class="ltx_td ltx_align_right ltx_border_t">87.051</td>
<td class="ltx_td ltx_align_right ltx_border_t">0.000</td>
<td class="ltx_td ltx_align_right ltx_border_t">87.051</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">DSO</td>
<td class="ltx_td ltx_align_right">8.70</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">26.761</td>
<td class="ltx_td ltx_align_right">0.000</td>
<td class="ltx_td ltx_align_right">26.761</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">AlphaGen</td>
<td class="ltx_td ltx_align_right">13.80</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">42.449</td>
<td class="ltx_td ltx_align_right">0.000</td>
<td class="ltx_td ltx_align_right">42.449</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">AlphaForge</td>
<td class="ltx_td ltx_align_right">0.42</td>
<td class="ltx_td ltx_align_center">✓</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">0</td>
<td class="ltx_td ltx_align_right">1.292</td>
<td class="ltx_td ltx_align_right">0.000</td>
<td class="ltx_td ltx_align_right">1.292</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">CoT</td>
<td class="ltx_td ltx_align_right ltx_border_t">1.42</td>
<td class="ltx_td ltx_align_center ltx_border_t"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m1" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t">6,110,411</td>
<td class="ltx_td ltx_align_right ltx_border_t">1,143,407</td>
<td class="ltx_td ltx_align_right ltx_border_t">2.939</td>
<td class="ltx_td ltx_align_right ltx_border_t">21.368</td>
<td class="ltx_td ltx_align_right ltx_border_t">24.307</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">ToT</td>
<td class="ltx_td ltx_align_right">1.73</td>
<td class="ltx_td ltx_align_center"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m2" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right">7,072,398</td>
<td class="ltx_td ltx_align_right">1,800,932</td>
<td class="ltx_td ltx_align_right">3.581</td>
<td class="ltx_td ltx_align_right">28.552</td>
<td class="ltx_td ltx_align_right">32.133</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">FAMA</td>
<td class="ltx_td ltx_align_right">1.81</td>
<td class="ltx_td ltx_align_center"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m3" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right">6,866,434</td>
<td class="ltx_td ltx_align_right">1,198,739</td>
<td class="ltx_td ltx_align_right">3.747</td>
<td class="ltx_td ltx_align_right">23.323</td>
<td class="ltx_td ltx_align_right">27.069</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Ours (GPT4.1)</td>
<td class="ltx_td ltx_align_right">2.76</td>
<td class="ltx_td ltx_align_center"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m4" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right">21,391,823</td>
<td class="ltx_td ltx_align_right">3,238,154</td>
<td class="ltx_td ltx_align_right">5.713</td>
<td class="ltx_td ltx_align_right">68.689</td>
<td class="ltx_td ltx_align_right">74.402</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Ours (Gemini-2.0-flash-lite)</td>
<td class="ltx_td ltx_align_right">1.94</td>
<td class="ltx_td ltx_align_center"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m5" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right">24,175,761</td>
<td class="ltx_td ltx_align_right">5,692,047</td>
<td class="ltx_td ltx_align_right">4.016</td>
<td class="ltx_td ltx_align_right">3.521</td>
<td class="ltx_td ltx_align_right">7.537</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">Ours (Deepseek-v3)</td>
<td class="ltx_td ltx_align_right ltx_border_bb">6.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb"><math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m6" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb">27,291,214</td>
<td class="ltx_td ltx_align_right ltx_border_bb">5,257,428</td>
<td class="ltx_td ltx_align_right ltx_border_bb">14.304</td>
<td class="ltx_td ltx_align_right ltx_border_bb">7.931</td>
<td class="ltx_td ltx_align_right ltx_border_bb">22.235</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Comparison of single-experiment costs and resource usage across different methods. Time is measured in hours. GPU usage is indicated by a checkmark (✓) for required or a cross (<math alttext="\times" class="ltx_Math" display="inline" id="A8.T8.m8" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math>) for not required. Costs are presented in USD.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A8.SSx9">
<h3 class="ltx_title ltx_title_subsection">Cost Estimation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx9.p1">
<p class="ltx_p">To provide a standardized and equitable basis for comparing the efficiency of different alpha discovery methods, we conduct a cost-performance analysis. This appendix details the methodology we use to estimate the monetary cost of a single experimental run for each method, as presented in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T8" title="Table 8 ‣ Sensitivity Analysis of Key Framework Hyperparameters ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">8</span></a>. The cost estimation is based on a representative experimental setting: generating an alpha set of 100 alphas on the CSI 300 index.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A8.SSx9.p2">
<p class="ltx_p">The total cost for a single run comprises two primary components: server computational cost and LLM API cost.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A8.SSx9.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Server Computational Cost</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx9.SSS0.Px1.p1">
<p class="ltx_p">The server cost is a function of the experiment’s runtime and the required hardware. We reference public cloud computing prices from Amazon Web Services (AWS) for our calculations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A8.I6">
<li class="ltx_item" id="A8.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I6.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">CPU-only Server:</span> For methods that do not require a GPU (all LLM-based methods), we use a 48-core CPU server, priced at $2.07 per hour.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A8.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I6.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">GPU-enabled Server:</span> For methods requiring GPU acceleration (all non-LLM-based methods), we use a server equipped with an RTX 3080Ti GPU. The total server cost combines the base CPU server price with the GPU price of $1.006 per hour, for a total hourly rate of $3.076.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
<p class="ltx_p">The server cost is calculated as: <math alttext="\text{Cost}_{\text{Server}}=\text{Runtime (h)}\times\text{Hourly Rate (\textdollar/h)}" class="ltx_Math" display="inline" id="A8.SSx9.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><msub><mtext>Cost</mtext><mtext>Server</mtext></msub><mo>=</mo><mrow><mtext>Runtime (h)</mtext><mo lspace="0.222em" rspace="0.222em">×</mo><mtext>Hourly Rate ($/h)</mtext></mrow></mrow><annotation encoding="application/x-tex">\text{Cost}_{\text{Server}}=\text{Runtime (h)}\times\text{Hourly Rate (\textdollar/h)}</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A8.SSx9.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">LLM API Cost</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx9.SSS0.Px2.p1">
<p class="ltx_p">The API cost applies only to LLM-based methods and depends on the number of input and output tokens processed. We use the official pricing for each model. The costs, specified in USD per million tokens for input and output respectively, are as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A8.I7">
<li class="ltx_item" id="A8.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I7.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">GPT-4.1</span>: ($2.00, $8.00)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A8.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I7.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Gemini-2.0-flash-lite</span>: ($0.075, $0.30)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A8.I7.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I7.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Deepseek-v3</span>: ($0.071, $1.14)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
<p class="ltx_p">The API cost is calculated as: <math alttext="\text{Cost}_{\text{API}}=(\frac{\text{Input Tokens}}{10^{6}}\times\text{Rate}_{\text{Input}})+(\frac{\text{Output Tokens}}{10^{6}}\times\text{Rate}_{\text{Output}})" class="ltx_Math" display="inline" id="A8.SSx9.SSS0.Px2.p1.m1" intent=":literal"><semantics><mrow><msub><mtext>Cost</mtext><mtext>API</mtext></msub><mo>=</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mfrac><mtext>Input Tokens</mtext><msup><mn>10</mn><mn>6</mn></msup></mfrac><mo lspace="0.222em" rspace="0.222em">×</mo><msub><mtext>Rate</mtext><mtext>Input</mtext></msub></mrow><mo stretchy="false">)</mo></mrow><mo>+</mo><mrow><mo stretchy="false">(</mo><mrow><mfrac><mtext>Output Tokens</mtext><msup><mn>10</mn><mn>6</mn></msup></mfrac><mo lspace="0.222em" rspace="0.222em">×</mo><msub><mtext>Rate</mtext><mtext>Output</mtext></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\text{Cost}_{\text{API}}=(\frac{\text{Input Tokens}}{10^{6}}\times\text{Rate}_{\text{Input}})+(\frac{\text{Output Tokens}}{10^{6}}\times\text{Rate}_{\text{Output}})</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A8.SSx9.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Estimation Considerations</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx9.SSS0.Px3.p1">
<p class="ltx_p">It is important to acknowledge two caveats in our estimation:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A8.I8">
<li class="ltx_item" id="A8.I8.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I8.i1.p1">
<p class="ltx_p">The cost for non-LLM-based methods is likely an underestimation. Real-world quantitative finance applications often involve higher-frequency data, which would significantly increase the time and computational resources for alpha factor calculation and backtesting.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A8.I8.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A8.I8.i2.p1">
<p class="ltx_p">Conversely, the API cost for LLM-based methods may be a slight overestimation, as we do not account for potential cost reductions from API-level caching, where repeated input tokens can be priced lower.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A8.SSx9.SSS0.Px3.p2">
<p class="ltx_p">The final total cost in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T8" title="Table 8 ‣ Sensitivity Analysis of Key Framework Hyperparameters ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">8</span></a> is the sum of the server and API costs, offering a unified metric to evaluate search efficiency in terms of performance per dollar.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A8.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:96.7pt;vertical-align:-46.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-69.1pt,13.2pt) scale(0.785485913106569,0.785485913106569) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4">LightGBM</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0201</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0206</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0549</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6713</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0314</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0289</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0531</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.5939</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0373</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0352</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0321</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.3992</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0269</td>
<td class="ltx_td ltx_align_center">0.0267</td>
<td class="ltx_td ltx_align_center">0.0387</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.4335</td>
<td class="ltx_td ltx_align_center">0.0261</td>
<td class="ltx_td ltx_align_center">0.0240</td>
<td class="ltx_td ltx_align_center">0.0695</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7544</td>
<td class="ltx_td ltx_align_center">0.0358</td>
<td class="ltx_td ltx_align_center">0.0332</td>
<td class="ltx_td ltx_align_center">0.0620</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6872</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0210</td>
<td class="ltx_td ltx_align_center">0.0206</td>
<td class="ltx_td ltx_align_center">0.0175</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.2103</td>
<td class="ltx_td ltx_align_center">0.0243</td>
<td class="ltx_td ltx_align_center">0.0227</td>
<td class="ltx_td ltx_align_center">0.0593</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7470</td>
<td class="ltx_td ltx_align_center">0.0366</td>
<td class="ltx_td ltx_align_center">0.0345</td>
<td class="ltx_td ltx_align_center">0.0731</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.8009</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0386</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0364</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0668</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.7485</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0399</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0394</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0717</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.8283</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0420</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0395</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0822</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.9397</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4">MLP</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0207</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0209</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0608</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7030</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0304</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0290</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0566</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6779</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0367</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0334</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0343</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.4163</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0281</td>
<td class="ltx_td ltx_align_center">0.0278</td>
<td class="ltx_td ltx_align_center">0.0625</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7185</td>
<td class="ltx_td ltx_align_center">0.0299</td>
<td class="ltx_td ltx_align_center">0.0291</td>
<td class="ltx_td ltx_align_center">0.0571</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6340</td>
<td class="ltx_td ltx_align_center">0.0323</td>
<td class="ltx_td ltx_align_center">0.0316</td>
<td class="ltx_td ltx_align_center">0.0340</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.3770</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0243</td>
<td class="ltx_td ltx_align_center">0.0227</td>
<td class="ltx_td ltx_align_center">0.0593</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7470</td>
<td class="ltx_td ltx_align_center">0.0292</td>
<td class="ltx_td ltx_align_center">0.0281</td>
<td class="ltx_td ltx_align_center">0.0585</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6868</td>
<td class="ltx_td ltx_align_center">0.0378</td>
<td class="ltx_td ltx_align_center">0.0373</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0845</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">0.9401</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0411</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0406</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0741</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.8186</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0436</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0425</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0661</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.7075</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0422</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0408</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0737</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t">0.8103</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Predictive performance of LightGBM and MLP models trained on alphas mined by different methods. The experiment is conducted on the CSI 300 stock pool with a 10-day return prediction horizon.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="A8.SSx9.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Comparison under Equal API Cost</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A8.SSx9.SSS0.Px4.p1">
<p class="ltx_p">To further scrutinize the search efficiency of the LLM-based methods, we conduct an additional comparison under an equal-cost constraint. For the baseline methods, we incrementally increase the number of generated alphas, evaluating performance at each 1,000-alpha interval until their total API cost matches that of our method. We report the results from the evaluation interval that achieved the highest IC. As shown in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A8.T9" title="Table 9 ‣ Estimation Considerations ‣ Cost Estimation Details ‣ Appendix H Additional Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">9</span></a>, our method still achieves superior performance even when baselines are allocated an equivalent API budget. To match this budget, the baseline methods require generating a larger volume of alphas, and their runtimes exceed that of our method. This analysis suggests that our framework demonstrates high search efficiency across the dimensions of search count, token consumption, and runtime.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A9">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Full Experimental Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A9.p1">
<p class="ltx_p">In this section, we provide detailed experimental results for our proposed method and all other baselines.
Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9.T10" title="Table 10 ‣ Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9.T11" title="Table 11 ‣ Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">11</span></a> illustrate the experimental results for the LightGBM and MLP models on the CSI300 stock pool.
Similarly, Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9.T12" title="Table 12 ‣ Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">12</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A9.T13" title="Table 13 ‣ Appendix I Full Experimental Results ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">13</span></a> present the results for these two models on the CSI1000 stock pool.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A9.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:177.9pt;vertical-align:-86.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.7pt,20.6pt) scale(0.811684707392303,0.811684707392303) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><math alttext="\Delta T" class="ltx_Math" display="inline" id="A9.T10.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">\Delta T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="8">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0165</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0148</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0138</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.1717</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0248</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0246</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0570</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6777</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0319</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0288</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0716</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.7222</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0079</td>
<td class="ltx_td ltx_align_center">0.0090</td>
<td class="ltx_td ltx_align_center">0.0434</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6125</td>
<td class="ltx_td ltx_align_center">0.0174</td>
<td class="ltx_td ltx_align_center">0.0178</td>
<td class="ltx_td ltx_align_center">-0.0569</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.6460</td>
<td class="ltx_td ltx_align_center">0.0246</td>
<td class="ltx_td ltx_align_center">0.0247</td>
<td class="ltx_td ltx_align_center">-0.0090</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">-0.1069</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0443</td>
<td class="ltx_td ltx_align_center">0.0411</td>
<td class="ltx_td ltx_align_center">0.0119</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.1335</td>
<td class="ltx_td ltx_align_center">0.0388</td>
<td class="ltx_td ltx_align_center">0.0378</td>
<td class="ltx_td ltx_align_center">-0.0342</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.3473</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0446</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0416</span></td>
<td class="ltx_td ltx_align_center">0.0094</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.1091</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0521</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0518</span></td>
<td class="ltx_td ltx_align_center">0.0231</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.2653</td>
<td class="ltx_td ltx_align_center">0.0293</td>
<td class="ltx_td ltx_align_center">0.0271</td>
<td class="ltx_td ltx_align_center">0.0252</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.3005</td>
<td class="ltx_td ltx_align_center">0.0407</td>
<td class="ltx_td ltx_align_center">0.0387</td>
<td class="ltx_td ltx_align_center">-0.0253</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">-0.3004</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0201</td>
<td class="ltx_td ltx_align_center">0.0206</td>
<td class="ltx_td ltx_align_center">0.0549</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6713</td>
<td class="ltx_td ltx_align_center">0.0240</td>
<td class="ltx_td ltx_align_center">0.0224</td>
<td class="ltx_td ltx_align_center">0.0600</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6683</td>
<td class="ltx_td ltx_align_center">0.0237</td>
<td class="ltx_td ltx_align_center">0.0225</td>
<td class="ltx_td ltx_align_center">0.0600</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6681</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0269</td>
<td class="ltx_td ltx_align_center">0.0267</td>
<td class="ltx_td ltx_align_center">0.0387</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.4335</td>
<td class="ltx_td ltx_align_center">0.0256</td>
<td class="ltx_td ltx_align_center">0.0242</td>
<td class="ltx_td ltx_align_center">0.0680</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7365</td>
<td class="ltx_td ltx_align_center">0.0358</td>
<td class="ltx_td ltx_align_center">0.0332</td>
<td class="ltx_td ltx_align_center">0.0620</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6872</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0210</td>
<td class="ltx_td ltx_align_center">0.0206</td>
<td class="ltx_td ltx_align_center">0.0175</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.2103</td>
<td class="ltx_td ltx_align_center">0.0243</td>
<td class="ltx_td ltx_align_center">0.0227</td>
<td class="ltx_td ltx_align_center">0.0593</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7470</td>
<td class="ltx_td ltx_align_center">0.0292</td>
<td class="ltx_td ltx_align_center">0.0281</td>
<td class="ltx_td ltx_align_center">0.0585</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6868</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0386</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0364</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0668</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.7485</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0399</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0394</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0717</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">0.8283</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0420</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0395</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0822</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.9397</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="8">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0145</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0118</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0322</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3857</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0248</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0246</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0570</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6777</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0319</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0288</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0716</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.7222</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0079</td>
<td class="ltx_td ltx_align_center">0.0090</td>
<td class="ltx_td ltx_align_center">-0.0050</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.0682</td>
<td class="ltx_td ltx_align_center">0.0174</td>
<td class="ltx_td ltx_align_center">0.0178</td>
<td class="ltx_td ltx_align_center">0.0156</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.1735</td>
<td class="ltx_td ltx_align_center">0.0246</td>
<td class="ltx_td ltx_align_center">0.0247</td>
<td class="ltx_td ltx_align_center">0.0185</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.2039</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0299</td>
<td class="ltx_td ltx_align_center">0.0280</td>
<td class="ltx_td ltx_align_center">0.0597</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7792</td>
<td class="ltx_td ltx_align_center">0.0322</td>
<td class="ltx_td ltx_align_center">0.0286</td>
<td class="ltx_td ltx_align_center">0.0150</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.1540</td>
<td class="ltx_td ltx_align_center">0.0401</td>
<td class="ltx_td ltx_align_center">0.0339</td>
<td class="ltx_td ltx_align_center">0.0548</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.4662</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">0.0326</td>
<td class="ltx_td ltx_align_center">0.0322</td>
<td class="ltx_td ltx_align_center">0.0981</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9455</td>
<td class="ltx_td ltx_align_center">0.0286</td>
<td class="ltx_td ltx_align_center">0.0278</td>
<td class="ltx_td ltx_align_center">0.0551</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7341</td>
<td class="ltx_td ltx_align_center">0.0339</td>
<td class="ltx_td ltx_align_center">0.0315</td>
<td class="ltx_td ltx_align_center">0.0164</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.2176</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0200</td>
<td class="ltx_td ltx_align_center">0.0186</td>
<td class="ltx_td ltx_align_center">0.0774</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9554</td>
<td class="ltx_td ltx_align_center">0.0274</td>
<td class="ltx_td ltx_align_center">0.0250</td>
<td class="ltx_td ltx_align_center">0.0574</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6105</td>
<td class="ltx_td ltx_align_center">0.0278</td>
<td class="ltx_td ltx_align_center">0.0247</td>
<td class="ltx_td ltx_align_center">0.0468</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.5037</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0232</td>
<td class="ltx_td ltx_align_center">0.0247</td>
<td class="ltx_td ltx_align_center">0.1064</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3221</td>
<td class="ltx_td ltx_align_center">0.0291</td>
<td class="ltx_td ltx_align_center">0.0285</td>
<td class="ltx_td ltx_align_center">0.0632</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7982</td>
<td class="ltx_td ltx_align_center">0.0348</td>
<td class="ltx_td ltx_align_center">0.0312</td>
<td class="ltx_td ltx_align_center">0.0587</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.7037</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0298</td>
<td class="ltx_td ltx_align_center">0.0307</td>
<td class="ltx_td ltx_align_center">0.1050</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1609</td>
<td class="ltx_td ltx_align_center">0.0285</td>
<td class="ltx_td ltx_align_center">0.0298</td>
<td class="ltx_td ltx_align_center">0.0803</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9502</td>
<td class="ltx_td ltx_align_center">0.0301</td>
<td class="ltx_td ltx_align_center">0.0297</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0934</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">1.1629</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0334</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0334</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1129</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.3286</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0352</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0340</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0886</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.1299</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0417</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0401</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0826</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t">1.0312</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>The predictive performance of LightGBM model trained on alphas mined by different methods on the CSI300 stock pool.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A9.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:177.9pt;vertical-align:-86.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.7pt,20.6pt) scale(0.811684707392303,0.811684707392303) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><math alttext="\Delta T" class="ltx_Math" display="inline" id="A9.T11.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">\Delta T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="8">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0124</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0120</td>
<td class="ltx_td ltx_align_center ltx_border_t">-0.0212</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-0.2240</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0257</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0233</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0769</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8324</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0277</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0266</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0345</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.3967</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0085</td>
<td class="ltx_td ltx_align_center">0.0082</td>
<td class="ltx_td ltx_align_center">0.0485</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.5849</td>
<td class="ltx_td ltx_align_center">0.0062</td>
<td class="ltx_td ltx_align_center">0.0052</td>
<td class="ltx_td ltx_align_center">-0.0263</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.2623</td>
<td class="ltx_td ltx_align_center">0.0256</td>
<td class="ltx_td ltx_align_center">0.0245</td>
<td class="ltx_td ltx_align_center">0.0019</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.0230</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0419</td>
<td class="ltx_td ltx_align_center">0.0418</td>
<td class="ltx_td ltx_align_center">0.0725</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.8199</td>
<td class="ltx_td ltx_align_center">0.0380</td>
<td class="ltx_td ltx_align_center">0.0374</td>
<td class="ltx_td ltx_align_center">0.0524</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6187</td>
<td class="ltx_td ltx_align_center">0.0311</td>
<td class="ltx_td ltx_align_center">0.0313</td>
<td class="ltx_td ltx_align_center">0.0295</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.3044</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0549</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0554</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0802</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">0.8397</span></td>
<td class="ltx_td ltx_align_center">0.0232</td>
<td class="ltx_td ltx_align_center">0.0207</td>
<td class="ltx_td ltx_align_center">0.0668</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7509</td>
<td class="ltx_td ltx_align_center">0.0408</td>
<td class="ltx_td ltx_align_center">0.0395</td>
<td class="ltx_td ltx_align_center">0.0220</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.2555</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0207</td>
<td class="ltx_td ltx_align_center">0.0209</td>
<td class="ltx_td ltx_align_center">0.0608</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7030</td>
<td class="ltx_td ltx_align_center">0.0260</td>
<td class="ltx_td ltx_align_center">0.0260</td>
<td class="ltx_td ltx_align_center">0.0500</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.5632</td>
<td class="ltx_td ltx_align_center">0.0263</td>
<td class="ltx_td ltx_align_center">0.0257</td>
<td class="ltx_td ltx_align_center">0.0592</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6627</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0281</td>
<td class="ltx_td ltx_align_center">0.0278</td>
<td class="ltx_td ltx_align_center">0.0625</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7185</td>
<td class="ltx_td ltx_align_center">0.0285</td>
<td class="ltx_td ltx_align_center">0.0286</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0805</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">0.8414</span></td>
<td class="ltx_td ltx_align_center">0.0323</td>
<td class="ltx_td ltx_align_center">0.0316</td>
<td class="ltx_td ltx_align_center">0.0340</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.3770</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0243</td>
<td class="ltx_td ltx_align_center">0.0227</td>
<td class="ltx_td ltx_align_center">0.0593</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7470</td>
<td class="ltx_td ltx_align_center">0.0292</td>
<td class="ltx_td ltx_align_center">0.0281</td>
<td class="ltx_td ltx_align_center">0.0585</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6868</td>
<td class="ltx_td ltx_align_center">0.0307</td>
<td class="ltx_td ltx_align_center">0.0319</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.1013</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">1.2209</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0411</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0406</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0741</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8186</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0436</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0425</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0661</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7075</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0422</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0408</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0737</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.8103</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="8">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0149</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0144</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0541</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6154</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0262</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0245</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1422</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.5026</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0220</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0194</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0815</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.7696</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">-0.0009</td>
<td class="ltx_td ltx_align_center">0.0017</td>
<td class="ltx_td ltx_align_center">-0.0605</td>
<td class="ltx_td ltx_align_center ltx_border_r">-0.6320</td>
<td class="ltx_td ltx_align_center">0.0067</td>
<td class="ltx_td ltx_align_center">0.0057</td>
<td class="ltx_td ltx_align_center">0.0037</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.0378</td>
<td class="ltx_td ltx_align_center">0.0250</td>
<td class="ltx_td ltx_align_center">0.0230</td>
<td class="ltx_td ltx_align_center">0.0919</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.9969</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0204</td>
<td class="ltx_td ltx_align_center">0.0190</td>
<td class="ltx_td ltx_align_center">0.0417</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.4695</td>
<td class="ltx_td ltx_align_center">0.0240</td>
<td class="ltx_td ltx_align_center">0.0257</td>
<td class="ltx_td ltx_align_center">0.0538</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6088</td>
<td class="ltx_td ltx_align_center">0.0415</td>
<td class="ltx_td ltx_align_center">0.0400</td>
<td class="ltx_td ltx_align_center">0.1149</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.2440</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">0.0348</td>
<td class="ltx_td ltx_align_center">0.0355</td>
<td class="ltx_td ltx_align_center">0.1162</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0065</td>
<td class="ltx_td ltx_align_center">0.0283</td>
<td class="ltx_td ltx_align_center">0.0274</td>
<td class="ltx_td ltx_align_center">0.1004</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2230</td>
<td class="ltx_td ltx_align_center">0.0317</td>
<td class="ltx_td ltx_align_center">0.0280</td>
<td class="ltx_td ltx_align_center">0.0732</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.9253</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0198</td>
<td class="ltx_td ltx_align_center">0.0188</td>
<td class="ltx_td ltx_align_center">0.1050</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2943</td>
<td class="ltx_td ltx_align_center">0.0274</td>
<td class="ltx_td ltx_align_center">0.0264</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.1631</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">1.6693</span></td>
<td class="ltx_td ltx_align_center">0.0276</td>
<td class="ltx_td ltx_align_center">0.0250</td>
<td class="ltx_td ltx_align_center">0.1042</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0422</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0265</td>
<td class="ltx_td ltx_align_center">0.0262</td>
<td class="ltx_td ltx_align_center">0.0975</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1829</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0355</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0353</span></td>
<td class="ltx_td ltx_align_center">0.1330</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.5599</td>
<td class="ltx_td ltx_align_center">0.0337</td>
<td class="ltx_td ltx_align_center">0.0327</td>
<td class="ltx_td ltx_align_center">0.0584</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.7347</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0341</td>
<td class="ltx_td ltx_align_center">0.0338</td>
<td class="ltx_td ltx_align_center">0.1173</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3005</td>
<td class="ltx_td ltx_align_center">0.0302</td>
<td class="ltx_td ltx_align_center">0.0300</td>
<td class="ltx_td ltx_align_center">0.0596</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6626</td>
<td class="ltx_td ltx_align_center">0.0331</td>
<td class="ltx_td ltx_align_center">0.0327</td>
<td class="ltx_td ltx_align_center">0.1012</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0366</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0361</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0359</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1259</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.3210</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0337</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0340</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.1235</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1.3931</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0423</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0424</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1315</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">1.4307</span></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>The predictive performance of MLP model trained on alphas mined by different methods on the CSI300 stock pool.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A9.T12">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:177.9pt;vertical-align:-86.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.7pt,20.6pt) scale(0.811684707392303,0.811684707392303) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><math alttext="\Delta T" class="ltx_Math" display="inline" id="A9.T12.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">\Delta T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="8">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0621</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0581</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0965</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8339</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0627</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0587</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0956</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8933</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0744</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0646</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1054</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">1.0063</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0362</td>
<td class="ltx_td ltx_align_center">0.0368</td>
<td class="ltx_td ltx_align_center">0.0926</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.8602</td>
<td class="ltx_td ltx_align_center">0.0492</td>
<td class="ltx_td ltx_align_center">0.0466</td>
<td class="ltx_td ltx_align_center">0.1091</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0195</td>
<td class="ltx_td ltx_align_center">0.0609</td>
<td class="ltx_td ltx_align_center">0.0559</td>
<td class="ltx_td ltx_align_center">0.1137</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0720</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0528</td>
<td class="ltx_td ltx_align_center">0.0511</td>
<td class="ltx_td ltx_align_center">0.0770</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7751</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0828</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0720</span></td>
<td class="ltx_td ltx_align_center">0.0403</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.4799</td>
<td class="ltx_td ltx_align_center">0.0793</td>
<td class="ltx_td ltx_align_center">0.0693</td>
<td class="ltx_td ltx_align_center">0.0816</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.9041</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0702</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0628</span></td>
<td class="ltx_td ltx_align_center">0.0768</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7029</td>
<td class="ltx_td ltx_align_center">0.0664</td>
<td class="ltx_td ltx_align_center">0.0601</td>
<td class="ltx_td ltx_align_center">0.0881</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7687</td>
<td class="ltx_td ltx_align_center">0.0728</td>
<td class="ltx_td ltx_align_center">0.0631</td>
<td class="ltx_td ltx_align_center">0.0512</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.4607</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0556</td>
<td class="ltx_td ltx_align_center">0.0498</td>
<td class="ltx_td ltx_align_center">0.0450</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.4726</td>
<td class="ltx_td ltx_align_center">0.0638</td>
<td class="ltx_td ltx_align_center">0.0574</td>
<td class="ltx_td ltx_align_center">0.0607</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.6113</td>
<td class="ltx_td ltx_align_center">0.0670</td>
<td class="ltx_td ltx_align_center">0.0597</td>
<td class="ltx_td ltx_align_center">0.0602</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.5818</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0619</td>
<td class="ltx_td ltx_align_center">0.0573</td>
<td class="ltx_td ltx_align_center">0.0993</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9592</td>
<td class="ltx_td ltx_align_center">0.0599</td>
<td class="ltx_td ltx_align_center">0.0558</td>
<td class="ltx_td ltx_align_center">0.0954</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9419</td>
<td class="ltx_td ltx_align_center">0.0654</td>
<td class="ltx_td ltx_align_center">0.0585</td>
<td class="ltx_td ltx_align_center">0.0909</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.8889</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0631</td>
<td class="ltx_td ltx_align_center">0.0595</td>
<td class="ltx_td ltx_align_center">0.1053</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9234</td>
<td class="ltx_td ltx_align_center">0.0643</td>
<td class="ltx_td ltx_align_center">0.0596</td>
<td class="ltx_td ltx_align_center">0.1134</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0222</td>
<td class="ltx_td ltx_align_center">0.0647</td>
<td class="ltx_td ltx_align_center">0.0584</td>
<td class="ltx_td ltx_align_center">0.1186</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0708</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0661</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0603</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1096</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.0919</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0748</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0677</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1418</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.3699</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0804</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0729</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1393</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">1.3577</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="8">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0575</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0522</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0996</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.1359</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0674</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0637</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0559</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7088</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0706</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0672</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0496</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.6230</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0362</td>
<td class="ltx_td ltx_align_center">0.0368</td>
<td class="ltx_td ltx_align_center">0.1181</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1052</td>
<td class="ltx_td ltx_align_center">0.0420</td>
<td class="ltx_td ltx_align_center">0.0397</td>
<td class="ltx_td ltx_align_center">0.1096</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2138</td>
<td class="ltx_td ltx_align_center">0.0609</td>
<td class="ltx_td ltx_align_center">0.0559</td>
<td class="ltx_td ltx_align_center">0.1226</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.1488</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0511</td>
<td class="ltx_td ltx_align_center">0.0502</td>
<td class="ltx_td ltx_align_center">0.1087</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2971</td>
<td class="ltx_td ltx_align_center">0.0727</td>
<td class="ltx_td ltx_align_center">0.0634</td>
<td class="ltx_td ltx_align_center">0.0991</td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">1.4196</span></td>
<td class="ltx_td ltx_align_center">0.0685</td>
<td class="ltx_td ltx_align_center">0.0686</td>
<td class="ltx_td ltx_align_center">0.0520</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.7458</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">0.0558</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0532</span></td>
<td class="ltx_td ltx_align_center">0.1095</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9708</td>
<td class="ltx_td ltx_align_center">0.0705</td>
<td class="ltx_td ltx_align_center">0.0638</td>
<td class="ltx_td ltx_align_center">0.1081</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9519</td>
<td class="ltx_td ltx_align_center">0.0705</td>
<td class="ltx_td ltx_align_center">0.0611</td>
<td class="ltx_td ltx_align_center">0.0796</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.8501</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0471</td>
<td class="ltx_td ltx_align_center">0.0438</td>
<td class="ltx_td ltx_align_center">0.1030</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1473</td>
<td class="ltx_td ltx_align_center">0.0693</td>
<td class="ltx_td ltx_align_center">0.0629</td>
<td class="ltx_td ltx_align_center">0.1110</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9757</td>
<td class="ltx_td ltx_align_center">0.0743</td>
<td class="ltx_td ltx_align_center">0.0661</td>
<td class="ltx_td ltx_align_center">0.1118</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0872</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0475</td>
<td class="ltx_td ltx_align_center">0.0458</td>
<td class="ltx_td ltx_align_center">0.1340</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.4212</td>
<td class="ltx_td ltx_align_center">0.0643</td>
<td class="ltx_td ltx_align_center">0.0576</td>
<td class="ltx_td ltx_align_center">0.1097</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1991</td>
<td class="ltx_td ltx_align_center">0.0758</td>
<td class="ltx_td ltx_align_center">0.0694</td>
<td class="ltx_td ltx_align_center">0.1147</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.1127</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0543</td>
<td class="ltx_td ltx_align_center">0.0522</td>
<td class="ltx_td ltx_align_center">0.1136</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9774</td>
<td class="ltx_td ltx_align_center">0.0550</td>
<td class="ltx_td ltx_align_center">0.0523</td>
<td class="ltx_td ltx_align_center">0.1340</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2054</td>
<td class="ltx_td ltx_align_center">0.0557</td>
<td class="ltx_td ltx_align_center">0.0523</td>
<td class="ltx_td ltx_align_center">0.1226</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0912</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0529</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0506</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1543</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.6588</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0741</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0673</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1461</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1.4065</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0793</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0723</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1326</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">1.2598</span></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>The predictive performance of LightGBM model trained on alphas mined by different methods on the CSI1000 stock pool.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A9.T13">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:177.9pt;vertical-align:-86.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.7pt,20.6pt) scale(0.811684707392303,0.811684707392303) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><math alttext="\Delta T" class="ltx_Math" display="inline" id="A9.T13.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">\Delta T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Alpha Num = 100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IR</td>
<td class="ltx_td ltx_align_center ltx_border_t">IC</td>
<td class="ltx_td ltx_align_center ltx_border_t">RankIC</td>
<td class="ltx_td ltx_align_center ltx_border_t">AR</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">IR</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="8">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0578</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0555</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0922</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8226</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0606</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0572</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0807</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6590</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0659</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0613</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1031</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.9692</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0355</td>
<td class="ltx_td ltx_align_center">0.0349</td>
<td class="ltx_td ltx_align_center">0.1043</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9314</td>
<td class="ltx_td ltx_align_center">0.0416</td>
<td class="ltx_td ltx_align_center">0.0405</td>
<td class="ltx_td ltx_align_center">0.0820</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7957</td>
<td class="ltx_td ltx_align_center">0.0502</td>
<td class="ltx_td ltx_align_center">0.0469</td>
<td class="ltx_td ltx_align_center">0.0926</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.8907</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0462</td>
<td class="ltx_td ltx_align_center">0.0463</td>
<td class="ltx_td ltx_align_center">0.0947</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9076</td>
<td class="ltx_td ltx_align_center">0.0665</td>
<td class="ltx_td ltx_align_center">0.0619</td>
<td class="ltx_td ltx_align_center">0.0445</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.5072</td>
<td class="ltx_td ltx_align_center">0.0659</td>
<td class="ltx_td ltx_align_center">0.0597</td>
<td class="ltx_td ltx_align_center">0.0261</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.4004</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0694</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0634</span></td>
<td class="ltx_td ltx_align_center">0.1060</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9916</td>
<td class="ltx_td ltx_align_center">0.0633</td>
<td class="ltx_td ltx_align_center">0.0580</td>
<td class="ltx_td ltx_align_center">0.1086</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9420</td>
<td class="ltx_td ltx_align_center">0.0632</td>
<td class="ltx_td ltx_align_center">0.0606</td>
<td class="ltx_td ltx_align_center">0.0631</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.5837</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0518</td>
<td class="ltx_td ltx_align_center">0.0480</td>
<td class="ltx_td ltx_align_center">0.0513</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.5369</td>
<td class="ltx_td ltx_align_center">0.0585</td>
<td class="ltx_td ltx_align_center">0.0544</td>
<td class="ltx_td ltx_align_center">0.0721</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.7412</td>
<td class="ltx_td ltx_align_center">0.0648</td>
<td class="ltx_td ltx_align_center">0.0593</td>
<td class="ltx_td ltx_align_center">0.0706</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6824</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0606</td>
<td class="ltx_td ltx_align_center">0.0578</td>
<td class="ltx_td ltx_align_center">0.1118</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0644</td>
<td class="ltx_td ltx_align_center">0.0575</td>
<td class="ltx_td ltx_align_center">0.0558</td>
<td class="ltx_td ltx_align_center">0.0934</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9376</td>
<td class="ltx_td ltx_align_center">0.0637</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0622</span></td>
<td class="ltx_td ltx_align_center">0.0971</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.9258</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0620</td>
<td class="ltx_td ltx_align_center">0.0591</td>
<td class="ltx_td ltx_align_center">0.1045</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9361</td>
<td class="ltx_td ltx_align_center">0.0611</td>
<td class="ltx_td ltx_align_center">0.0582</td>
<td class="ltx_td ltx_align_center">0.1011</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9539</td>
<td class="ltx_td ltx_align_center">0.0635</td>
<td class="ltx_td ltx_align_center">0.0572</td>
<td class="ltx_td ltx_align_center">0.1041</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.0323</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0609</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0581</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1286</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.3039</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0681</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0622</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1168</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.1843</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0662</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0618</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.1204</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">1.2868</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="8">30</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GP</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0555</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.0517</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1590</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.4989</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0653</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0606</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1105</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.2125</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0655</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0638</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.0977</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">1.0269</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DSO</td>
<td class="ltx_td ltx_align_center">0.0312</td>
<td class="ltx_td ltx_align_center">0.0318</td>
<td class="ltx_td ltx_align_center">0.1171</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0981</td>
<td class="ltx_td ltx_align_center">0.0338</td>
<td class="ltx_td ltx_align_center">0.0326</td>
<td class="ltx_td ltx_align_center">0.1336</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3199</td>
<td class="ltx_td ltx_align_center">0.0542</td>
<td class="ltx_td ltx_align_center">0.0522</td>
<td class="ltx_td ltx_align_center">0.1056</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.9626</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaGen</td>
<td class="ltx_td ltx_align_center">0.0505</td>
<td class="ltx_td ltx_align_center">0.0505</td>
<td class="ltx_td ltx_align_center">0.1436</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3123</td>
<td class="ltx_td ltx_align_center">0.0664</td>
<td class="ltx_td ltx_align_center">0.0611</td>
<td class="ltx_td ltx_align_center">0.0766</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0838</td>
<td class="ltx_td ltx_align_center">0.0640</td>
<td class="ltx_td ltx_align_center">0.0622</td>
<td class="ltx_td ltx_align_center">0.0569</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.8894</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">AlphaForge</td>
<td class="ltx_td ltx_align_center">0.0541</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.0517</span></td>
<td class="ltx_td ltx_align_center">0.1071</td>
<td class="ltx_td ltx_align_center ltx_border_r">0.9857</td>
<td class="ltx_td ltx_align_center">0.0642</td>
<td class="ltx_td ltx_align_center">0.0606</td>
<td class="ltx_td ltx_align_center">0.1134</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.0138</td>
<td class="ltx_td ltx_align_center">0.0717</td>
<td class="ltx_td ltx_align_center">0.0650</td>
<td class="ltx_td ltx_align_center">0.0667</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">0.6850</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">CoT</td>
<td class="ltx_td ltx_align_center">0.0465</td>
<td class="ltx_td ltx_align_center">0.0440</td>
<td class="ltx_td ltx_align_center">0.1176</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2683</td>
<td class="ltx_td ltx_align_center">0.0662</td>
<td class="ltx_td ltx_align_center">0.0620</td>
<td class="ltx_td ltx_align_center">0.1345</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3550</td>
<td class="ltx_td ltx_align_center">0.0698</td>
<td class="ltx_td ltx_align_center">0.0615</td>
<td class="ltx_td ltx_align_center">0.1174</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.4363</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">ToT</td>
<td class="ltx_td ltx_align_center">0.0466</td>
<td class="ltx_td ltx_align_center">0.0447</td>
<td class="ltx_td ltx_align_center">0.1322</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.3771</td>
<td class="ltx_td ltx_align_center">0.0608</td>
<td class="ltx_td ltx_align_center">0.0556</td>
<td class="ltx_td ltx_align_center">0.1220</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.4510</td>
<td class="ltx_td ltx_align_center">0.0690</td>
<td class="ltx_td ltx_align_center">0.0633</td>
<td class="ltx_td ltx_align_center">0.1116</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.2468</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">FAMA</td>
<td class="ltx_td ltx_align_center">0.0532</td>
<td class="ltx_td ltx_align_center">0.0511</td>
<td class="ltx_td ltx_align_center">0.1224</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.1036</td>
<td class="ltx_td ltx_align_center">0.0538</td>
<td class="ltx_td ltx_align_center">0.0519</td>
<td class="ltx_td ltx_align_center">0.1374</td>
<td class="ltx_td ltx_align_center ltx_border_r">1.2472</td>
<td class="ltx_td ltx_align_center">0.0571</td>
<td class="ltx_td ltx_align_center">0.0530</td>
<td class="ltx_td ltx_align_center">0.1327</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">1.2086</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0514</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.0491</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1799</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.8021</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0673</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0647</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1710</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">1.6268</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0738</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.0710</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">0.1696</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">1.5695</span></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>The predictive performance of MLP model trained on alphas mined by different methods on the CSI1000 stock pool.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A10">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A10.p1">
<p class="ltx_p">Despite the promising advancements presented by our framework for formulaic alpha mining, several limitations warrant discussion.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A10.p2">
<p class="ltx_p">First, while our method generates effective alpha formulas, there remains a gap in achieving the same level of novelty and complexity typically found in formulas developed by human experts. The framework may sometimes struggle to produce highly intricate or unconventional alphas.
Second, the diversity of the generated alphas is inherently constrained by the internal knowledge base of LLMs. This can, in turn, limit the breadth of the search space explored compared to certain non-LLM-based methodologies.
Consequently, scaling our approach to extremely large-scale alpha mining tasks, which necessitate the exploration of a vast and diverse alpha landscape, may present challenges.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A10.p3">
<p class="ltx_p">Addressing these limitations, such as by incorporating mechanisms for enhanced novelty or expanding the effective search space, constitutes important directions for future research.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_appendix" id="A11">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix K </span>LLM Agent Prompts</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A11.p1">
<p class="ltx_p">In our proposed framework, LLMs function as autonomous agents, instrumental in the multifaceted process of alpha formula mining. This includes the generation, iterative refinement, and overfitting risk evaluation of alpha formulas. This section details the core prompts designed to guide the LLM in these pivotal tasks. Each prompt is carefully designed to elicit specific behaviors and outputs from the LLM, ensuring a structured and effective approach to mining alpha formulas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="A11.SSx1">
<h3 class="ltx_title ltx_title_subsection">Alpha Portrait Generation Prompt</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A11.SSx1.p1">
<p class="ltx_p">As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.F15" title="Figure 15 ‣ Alpha Refinement Prompt ‣ Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">15</span></a>, the Alpha Portrait Generation Prompt is used to generate an alpha portrait based on information such as available data fields and operators. The alpha portrait is subsequently used to generate the corresponding alpha formula.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A11.SSx2">
<h3 class="ltx_title ltx_title_subsection">Alpha Formula Generation Prompt</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A11.SSx2.p1">
<p class="ltx_p">As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.F16" title="Figure 16 ‣ Alpha Refinement Prompt ‣ Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">16</span></a>, the Alpha Formula Generation Prompt is used to generate the corresponding alpha formula based on the provided alpha portrait and other relevant information. A formatted alpha formula facilitates correctness verification and the computation of alpha values.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A11.SSx3">
<h3 class="ltx_title ltx_title_subsection">Alpha Overfitting Risk Assessment Prompt</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A11.SSx3.p1">
<p class="ltx_p">As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.F17" title="Figure 17 ‣ Alpha Refinement Prompt ‣ Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">17</span></a>, the Alpha Overfitting Risk Assessment Prompt is used to assess the overfitting risk of an alpha based on its formula and refinement history information. We provide evaluation criteria within the prompt to assist the LLM in conducting a critical assessment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A11.SSx4">
<h3 class="ltx_title ltx_title_subsection">Alpha Refinement Prompt</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A11.SSx4.p1">
<p class="ltx_p">As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2505.11122v3#A11.F18" title="Figure 18 ‣ Alpha Refinement Prompt ‣ Appendix K LLM Agent Prompts ‣ Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining"><span class="ltx_text ltx_ref_tag">18</span></a>, the Alpha Refinement Prompt is used to refine the original alpha formula based on refinement suggestions, thereby generating an improved formula.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A11.F15">
<div class="ltx_logical-block ltx_minipage ltx_align_center ltx_align_middle" style="width:480.6pt;">
<div class="ltx_para" id="A11.F15.p11">
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Task Description:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p2">
<p class="ltx_p">You are a quantitative finance expert specializing in factor-based investing. Please design an alpha factor used in investment strategies according to the following requirements, and then provide the content of the alpha in the required format.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Data Fields:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p4">
<p class="ltx_p">The following data fields are available for use:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<pre class="ltx_verbatim ltx_font_typewriter">{available_fields}
</pre>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Operators:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p6">
<p class="ltx_p">The following operators are available for use:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<pre class="ltx_verbatim ltx_font_typewriter">{available_operators}
</pre>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Alpha Requirements:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I1">
<li class="ltx_item" id="A11.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I1.i1.p1">
<p class="ltx_p">The alpha value should be dimensionless (unitless).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I1.i2.p1">
<p class="ltx_p">The alpha should incorporate at least two distinct operations from the ”Available Operators” list to ensure it has sufficient complexity. Avoid creating overly simplistic alphas.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I1.i3.p1">
<p class="ltx_p">All look-back windows and other numerical parameters used in the alpha calculation MUST be represented as named parameters in the pseudo-code. These parameter names MUST follow Python naming conventions (e.g., <span class="ltx_text ltx_font_typewriter">lookback_period</span>, <span class="ltx_text ltx_font_typewriter">volatility_window</span>, <span class="ltx_text ltx_font_typewriter">smoothing_factor</span>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A11.I1.i4.p1">
<p class="ltx_p">The alpha should have NO MORE than 3 parameters in total.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A11.I1.i5.p1">
<p class="ltx_p">The pseudo-code should represent the alpha calculation step-by-step, using only the ”Available Operators” and clearly defined parameters. Each line in the pseudo-code should represent a single operation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="A11.I1.i6.p1">
<p class="ltx_p">Use descriptive variable names in the pseudo-code that clearly indicate the data they represent.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="A11.I1.i7.p1">
<p class="ltx_p">When designing alpha expressions, try to avoid including the following sub-expressions:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<pre class="ltx_verbatim ltx_font_typewriter">{freq_subtrees}
</pre>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p8">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Formatting Requirements:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p9">
<p class="ltx_p">The output must be in JSON format with three key-value pairs:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I2">
<li class="ltx_item" id="A11.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”name”:</span> A short, descriptive name for the alpha (following Python variable naming style, e.g., <span class="ltx_text ltx_font_typewriter">price_volatility_ratio</span>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”description”:</span> A concise explanation of the alpha’s purpose or what it measures. Avoid overly technical language. Focus on the intuition behind the alpha.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I2.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”pseudo_code”:</span> A list of strings, where each string is a line of simplified pseudo-code representing a single operation in the alpha calculation. Each line should follow the format: <span class="ltx_text ltx_font_typewriter">variable_name = op_name(input=[input1, input2, ...], param=[param1, param2, ...])</span>, where:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I2.i3.I1">
<li class="ltx_item" id="A11.I2.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I2.i3.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">variable_name</span> is the output variable of the operation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I2.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I2.i3.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">op_name</span> is the name of one of the ”Available Operators”.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I2.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I2.i3.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">input1</span>, <span class="ltx_text ltx_font_typewriter">input2</span>, …are input variables (either from ”Available Data Fields” or previously calculated variables, cannot be of a numeric type).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I2.i3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I2.i3.I1.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">param1</span>, <span class="ltx_text ltx_font_typewriter">param2</span>, …are parameter names defined in the alpha requirements.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A11.F15.p10">
<p class="ltx_p">The format example is as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A11.F15.p12">
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgIm5hbWUiOiAidm9sYXRpbGl0eV9hZGp1c3RlZF9tb21lbnR1bSIsCiAgICAiZGVzY3JpcHRpb24iOiAiLi4uLi4uIiwKICAgICJwc2V1ZG9fY29kZSI6IFsuLi4uLi5dCn0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"name"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"volatility_adjusted_momentum"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"description"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"......"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"pseudo_code"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">[</span><span class="ltx_text ltx_font_typewriter">......</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Alpha Portrait Generation Prompt</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A11.F16">
<div class="ltx_logical-block ltx_minipage ltx_align_center ltx_align_middle" style="width:480.6pt;">
<div class="ltx_para" id="A11.F16.p6">
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F16.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Task Description:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A11.F16.p7">
<p class="ltx_p">Please design a quantitative investment alpha expression according to the following requirements.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F16.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Data Fields:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I3">
<li class="ltx_item" id="A11.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I3.i1.p1">
<p class="ltx_p">The following data fields are available for use: <span class="ltx_text ltx_font_typewriter">{available_fields}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A11.F16.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Operators:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I4">
<li class="ltx_item" id="A11.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I4.i1.p1">
<p class="ltx_p">The following operators are available for use: <span class="ltx_text ltx_font_typewriter">{available_operators}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A11.F16.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Alpha Requirements:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I5">
<li class="ltx_item" id="A11.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I5.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">{alpha_portrait_prompt}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A11.F16.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Formatting Requirements:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I6">
<li class="ltx_item" id="A11.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I6.i1.p1">
<p class="ltx_p">Provide the output in JSON format.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I6.i2.p1">
<p class="ltx_p">The JSON object should contain two fields: <span class="ltx_text ltx_font_typewriter">"formula"</span>, and <span class="ltx_text ltx_font_typewriter">"arguments"</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I6.i2.I1">
<li class="ltx_item" id="A11.I6.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i2.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"formula"</span>: Represents the mathematical expression for calculating the alpha.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i2.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"arguments"</span>: Represents the configurable parameters of the alpha.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I6.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"formula"</span> is a list of dictionaries. Each dictionary represents a single operation and must contain four keys: <span class="ltx_text ltx_font_typewriter">"name"</span>, <span class="ltx_text ltx_font_typewriter">"param"</span>, <span class="ltx_text ltx_font_typewriter">"input"</span>, and <span class="ltx_text ltx_font_typewriter">"output"</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I6.i3.I1">
<li class="ltx_item" id="A11.I6.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i3.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"name"</span>: The operator’s name (a string), which MUST be one of the operators provided in the ”Available Operators” section.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i3.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"param"</span>: A list of strings, representing the parameter names for the operator. These parameter names MUST be used as keys in the <span class="ltx_text ltx_font_typewriter">"arguments"</span> section.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i3.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"input"</span>: A list of strings, representing the input variable names for the operator. These MUST be data fields from the ”Available Data Fields” or output variables from previous operations in the <span class="ltx_text ltx_font_typewriter">"formula"</span>, cannot be of a numeric type.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i3.I1.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"output"</span>: A string, representing the output variable name for the operator. This output can be used as an input for subsequent operations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I6.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A11.I6.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">"arguments"</span> is a list of dictionaries. Each dictionary represents a set of parameter values for the alpha.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I6.i4.I1">
<li class="ltx_item" id="A11.I6.i4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i4.I1.i1.p1">
<p class="ltx_p">The keys of each dictionary in <span class="ltx_text ltx_font_typewriter">"arguments"</span> MUST correspond exactly to the parameter names defined in the <span class="ltx_text ltx_font_typewriter">"param"</span> lists of the <span class="ltx_text ltx_font_typewriter">"formula"</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I6.i4.I1.i2.p1">
<p class="ltx_p">The values in each dictionary in <span class="ltx_text ltx_font_typewriter">"arguments"</span> are the specific numerical values for the parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I6.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A11.I6.i5.p1">
<p class="ltx_p">You may include a maximum of 3 sets of parameters within the <span class="ltx_text ltx_font_typewriter">"arguments"</span> field.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="A11.I6.i6.p1">
<p class="ltx_p">The parameter value that indicates the length of the lookback window (if applicable) must be within the <span class="ltx_text ltx_font_typewriter">{window_range}</span> range.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="A11.I6.i7.p1">
<p class="ltx_p">Ensure that the alpha expression is both reasonable and computationally feasible.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span>
<div class="ltx_para" id="A11.I6.i8.p1">
<p class="ltx_p">Parameter names should be descriptive and follow Python naming conventions (e.g., <span class="ltx_text ltx_font_typewriter">window_size</span>, <span class="ltx_text ltx_font_typewriter">lag_period</span>, <span class="ltx_text ltx_font_typewriter">smoothing_factor</span>). Avoid using single characters or numbers as parameter names.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I6.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">9.</span>
<div class="ltx_para" id="A11.I6.i9.p1">
<p class="ltx_p">Refer to the following example:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="A11.F16.p8">
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgImZvcm11bGEiOiBbLi4uLi4uXSwKICAgICJhcmd1bWVudHMiOiBbLi4uLi4uXQp9">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"formula"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">[</span><span class="ltx_text ltx_font_typewriter">......</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">]</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"arguments"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">[</span><span class="ltx_text ltx_font_typewriter">......</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Alpha Formula Generation Prompt</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A11.F17">
<div class="ltx_logical-block ltx_minipage ltx_align_center ltx_align_middle" style="width:480.6pt;">
<div class="ltx_para" id="A11.F17.p7">
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Task: Critical Alpha Overfitting Risk Assessment</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p2">
<p class="ltx_p">Critically evaluate the overfitting risk and generalization potential of the provided quantitative investment alpha, based on its expression and refinement history.
Your assessment must focus on whether complexity and optimization appear justified or are likely signs of overfitting.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Input:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I7">
<li class="ltx_item" id="A11.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I7.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Alpha Expression:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<pre class="ltx_verbatim ltx_font_typewriter">{alpha_formula}
</pre>
</div>
</li>
<li class="ltx_item" id="A11.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I7.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Refinement History:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<pre class="ltx_verbatim ltx_font_typewriter">{refinement_history}
</pre>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Evaluation Criteria:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I8">
<li class="ltx_item" id="A11.I8.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I8.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Justified Rationale vs. Complexity:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I8.i1.I1">
<li class="ltx_item" id="A11.I8.i1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="A11.I8.i1.I1.ix1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Critique:</span> Is the complexity of the alpha expression plausibly justified by an inferred economic rationale, or does it seem arbitrary/excessive, suggesting fitting to noise?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I8.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I8.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Principled Development vs. Data Dredging:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I8.i2.I1">
<li class="ltx_item" id="A11.I8.i2.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="A11.I8.i2.I1.ix1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Critique:</span> Does the refinement history indicate hypothesis-driven improvements, or does it suggest excessive optimization and curve-fitting (e.g., frequent, unjustified parameter tweaks)?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I8.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I8.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Transparency vs. Opacity:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I8.i3.I1">
<li class="ltx_item" id="A11.I8.i3.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="A11.I8.i3.I1.ix1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Critique:</span> Is the alpha’s logic reasonably interpretable despite its complexity, or is it opaque, potentially masking overfitting?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Scoring &amp; Output:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I9">
<li class="ltx_item" id="A11.I9.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I9.i1.p1">
<p class="ltx_p">Assign a single <span class="ltx_text ltx_font_bold">Overfitting Risk Score</span> from 0 to 10.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I9.i1.I2">
<li class="ltx_item" id="A11.I9.i1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold">–</span></span>
<div class="ltx_para" id="A11.I9.i1.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">10 = Very Low Risk</span> (High confidence in generalization)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I9.i1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold">–</span></span>
<div class="ltx_para" id="A11.I9.i1.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">0 = Very High Risk</span> (Low confidence in generalization)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A11.I9.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I9.i2.p1">
<p class="ltx_p">Use the full 0-10 range to differentiate risk levels effectively.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I9.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I9.i3.p1">
<p class="ltx_p">Provide a concise, one-sentence <span class="ltx_text ltx_font_bold">Justification</span> explaining the score, citing the key factors from the criteria.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I9.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I9.i4.p1">
<p class="ltx_p">Format the output as JSON, like the examples below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A11.F17.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Example JSON Outputs:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A11.F17.p8">
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgInJlYXNvbiI6ICJDb21wbGV4aXR5IGlzIGp1c3RpZmllZCBieSBhIHN0cm9uZyByYXRpb25hbGU7IHByaW5jaXBsZWQgcmVmaW5lbWVudCBoaXN0b3J5IHN1Z2dlc3RzIGxvdyByaXNrLiIsCiAgICAic2NvcmUiOiA5Cn0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"reason"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"Complexity<span class="ltx_text ltx_lst_space"> </span>is<span class="ltx_text ltx_lst_space"> </span>justified<span class="ltx_text ltx_lst_space"> </span>by<span class="ltx_text ltx_lst_space"> </span>a<span class="ltx_text ltx_lst_space"> </span>strong<span class="ltx_text ltx_lst_space"> </span>rationale;<span class="ltx_text ltx_lst_space"> </span>principled<span class="ltx_text ltx_lst_space"> </span>refinement<span class="ltx_text ltx_lst_space"> </span>history<span class="ltx_text ltx_lst_space"> </span>suggests<span class="ltx_text ltx_lst_space"> </span>low<span class="ltx_text ltx_lst_space"> </span>risk."</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"score"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#0000FF;">9</span>
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgInJlYXNvbiI6ICJQbGF1c2libGUgcmF0aW9uYWxlLCBidXQgc29tZSBleHByZXNzaW9uIG9wYWNpdHkgYW5kIHBhcmFtZXRlciB0dW5pbmcgaW4gaGlzdG9yeSBpbmRpY2F0ZSBtb2RlcmF0ZSByaXNrLiIsCiAgICAic2NvcmUiOiA1Cn0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"reason"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"Plausible<span class="ltx_text ltx_lst_space"> </span>rationale,<span class="ltx_text ltx_lst_space"> </span>but<span class="ltx_text ltx_lst_space"> </span>some<span class="ltx_text ltx_lst_space"> </span>expression<span class="ltx_text ltx_lst_space"> </span>opacity<span class="ltx_text ltx_lst_space"> </span>and<span class="ltx_text ltx_lst_space"> </span>parameter<span class="ltx_text ltx_lst_space"> </span>tuning<span class="ltx_text ltx_lst_space"> </span>in<span class="ltx_text ltx_lst_space"> </span>history<span class="ltx_text ltx_lst_space"> </span>indicate<span class="ltx_text ltx_lst_space"> </span>moderate<span class="ltx_text ltx_lst_space"> </span>risk."</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"score"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#0000FF;">5</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgInJlYXNvbiI6ICJIaWdoIHJpc2sgaW5mZXJyZWQgZnJvbSBvcGFxdWUgZXhwcmVzc2lvbiBsYWNraW5nIGNsZWFyIHJhdGlvbmFsZSwgc3VwcG9ydGVkIGJ5IGhpc3Rvcnkgc2hvd2luZyBleGNlc3NpdmUgdHVuaW5nLiIsCiAgICAic2NvcmUiOiAxCn0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"reason"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"High<span class="ltx_text ltx_lst_space"> </span>risk<span class="ltx_text ltx_lst_space"> </span>inferred<span class="ltx_text ltx_lst_space"> </span>from<span class="ltx_text ltx_lst_space"> </span>opaque<span class="ltx_text ltx_lst_space"> </span>expression<span class="ltx_text ltx_lst_space"> </span>lacking<span class="ltx_text ltx_lst_space"> </span>clear<span class="ltx_text ltx_lst_space"> </span>rationale,<span class="ltx_text ltx_lst_space"> </span>supported<span class="ltx_text ltx_lst_space"> </span>by<span class="ltx_text ltx_lst_space"> </span>history<span class="ltx_text ltx_lst_space"> </span>showing<span class="ltx_text ltx_lst_space"> </span>excessive<span class="ltx_text ltx_lst_space"> </span>tuning."</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"score"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#0000FF;">1</span>
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Alpha Overfitting Risk Assessment Prompt</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A11.F18">
<div class="ltx_logical-block ltx_minipage ltx_align_center ltx_align_middle" style="width:480.6pt;">
<div class="ltx_para" id="A11.F18.p14">
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Task Description:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p2">
<p class="ltx_p">There is an alpha factor used in quantitative investment to predict asset price trends.
Please improve it according to the following suggestions and provide the improved alpha expression.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Data Fields:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p4">
<p class="ltx_p">The following data fields are available for use: <span class="ltx_text ltx_font_typewriter">{available_fields}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Available Operators:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p6">
<p class="ltx_p">The following operators are available for use:<span class="ltx_text ltx_font_typewriter">{available_operators}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Alpha Suggestions:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I10">
<li class="ltx_item" id="A11.I10.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I10.i1.p1">
<p class="ltx_p">The alpha value should be dimensionless (unitless).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I10.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I10.i2.p1">
<p class="ltx_p">All look-back windows and other numerical parameters used in the alpha calculation MUST be represented as named parameters in the pseudo-code. These parameter names MUST follow Python naming conventions (e.g., <span class="ltx_text ltx_font_typewriter">lookback_period</span>, <span class="ltx_text ltx_font_typewriter">volatility_window</span>, <span class="ltx_text ltx_font_typewriter">smoothing_factor</span>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I10.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I10.i3.p1">
<p class="ltx_p">The alpha should have NO MORE than 3 parameters in total.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I10.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A11.I10.i4.p1">
<p class="ltx_p">The pseudo-code should represent the alpha calculation step-by-step, using only the ”Available Operators” and clearly defined parameters. Each line in the pseudo-code should represent a single operation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I10.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A11.I10.i5.p1">
<p class="ltx_p">Use descriptive variable names in the pseudo-code that clearly indicate the data they represent.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I10.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="A11.I10.i6.p1">
<p class="ltx_p">When designing alpha expressions, try to avoid including the following sub-expressions: <span class="ltx_text ltx_font_typewriter">{freq_subtrees}</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p8">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Original alpha expression:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,e29yaWdpbl9hbHBoYV9mb3JtdWxhfQ==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_font_typewriter">{</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter">origin_alpha_formula</span><span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p9">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Refinement suggestions:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p10">
<p class="ltx_p">NOTE: The following improvement suggestions do not need to be all adopted; they just need to be considered and reasonable ones selected for adoption.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,e3JlZmluZW1lbnRfc3VnZ2VzdGlvbnN9">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_font_typewriter">{</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter">refinement_suggestions</span><span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p11">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Formatting Requirements:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p12">
<p class="ltx_p">The output must be in JSON format with three key-value pairs:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A11.I11">
<li class="ltx_item" id="A11.I11.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A11.I11.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”name”</span>: A short, descriptive name for the alpha (following Python variable naming style, e.g., <span class="ltx_text ltx_font_typewriter">price_volatility_ratio</span>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I11.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A11.I11.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”description”</span>: A concise explanation of the alpha’s purpose or what it measures. Avoid overly technical language. Focus on the intuition behind the alpha.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I11.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A11.I11.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">”pseudo_code”</span>: A list of strings, where each string is a line of simplified pseudo-code representing a single operation in the alpha calculation. Each line should follow the format: <span class="ltx_text ltx_font_typewriter">variable_name = op_name(input=[input1, input2, ...], param=[param1, param2, ...])</span>, where:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A11.I11.i3.I1">
<li class="ltx_item" id="A11.I11.i3.I0.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I11.i3.I0.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">variable_name</span> is the output variable of the operation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I11.i3.I0.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I11.i3.I0.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">op_name</span> is the name of one of the ”Available Operators”.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I11.i3.I0.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I11.i3.I0.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">input1</span>, <span class="ltx_text ltx_font_typewriter">input2</span>, … are input variables (either from ”Available Data Fields” or previously calculated variables, cannot be of a numeric type).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A11.I11.i3.I0.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A11.I11.i3.I0.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_typewriter">param1</span>, <span class="ltx_text ltx_font_typewriter">param2</span>, … are parameter names defined in the alpha requirements.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A11.F18.p13">
<p class="ltx_p">The format example is as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgIm5hbWUiOiAidm9sYXRpbGl0eV9hZGp1c3RlZF9tb21lbnR1bSIsCiAgICAiZGVzY3JpcHRpb24iOiAiLi4uLi4uIiwKICAgICJwc2V1ZG9fY29kZSI6IFsuLi4uLi5dCn0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_text ltx_font_typewriter">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx25">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"name"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"volatility_adjusted_momentum"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"description"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"......"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" style="--ltx-fg-color:#BF0040;">"pseudo_code"</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#FF0000;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">[</span><span class="ltx_text ltx_font_typewriter">......</span><span class="ltx_text ltx_lst_literate ltx_font_typewriter" style="--ltx-fg-color:#000000;">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
</div>
<div class="ltx_para" id="A11.F18.p15">
<p class="ltx_p"><span class="ltx_rule ltx_filled_leader" style="width:480.6pt;height:1px;--ltx-bg-color:black;display:inline-block;">&nbsp;</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18: </span>Alpha Refinement Prompt</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><deepl-input-controller translate="no"><template shadowrootmode="open"><link rel="stylesheet" href="chrome-extension://fancfknaplihpclbhbpclnmmjcjanbaf/build/content.css"><div dir="ltr" style="visibility: initial !important;"><div class="dl-input-translation-container svelte-95aucy"><div></div></div></div></template></deepl-input-controller></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>/** 基础色阶定义 **/
:root,
#mount[data-theme="light"],
#mount:not([data-theme="dark"]) {
  /* 中性灰阶（light） */
  --c-00: #000000;
  --c-22: #222222;
  --c-33: #333333;
  --c-66: #666666;
  --c-83: #838383;
  --c-99: #999999;
  --c-c7: #c7c7c7;
  --c-cc: #cccccc;
  --c-e6: #e6e6e6;
  --c-f5: #f5f5f5;
  --c-ff: #ffffff;
  /* 品牌主色阶（light） */
  --p-main: #ea4c89;
  --p-hover: #ec5e95;
  --p-active: #e34a85;
  --p-special: #ee71a2;
  --p-disabled: #f4a5c4;
  --p-text-disabled: #f9c9dc;
  --p-weak: #fdedf3;
  /* Surface 层级（light，TC 填充-1） */
  --s-1: #f3f5f6;
  --s-1-hover: #f6f8f9;
  --s-1-active: #edf1f2;
  --s-1-weak: #fafbfb;
  /* 输入/边框（light，TC 填充-2） */
  --input-bg-base: #fafbfc;
  --input-border: #ecf0f7;
  --input-border-strong: #e0e0e6;
  --input-bg-strong: #fafdff;
}

:root[data-theme="dark"],
[data-theme="dark"] {
  /* 中性灰阶（dark） */
  --c-00: #ffffff;
  --c-22: #dbdbdb;
  --c-33: #dbdbdb;
  --c-66: #b3b3b3;
  --c-83: #838383;
  --c-99: #707070;
  --c-c7: #666666;
  --c-cc: #5c5c5c;
  --c-e6: #3b3b3b;
  --c-f5: #262626;
  --c-ff: #222222;
  /* 品牌主色阶（dark） */
  --p-main: #e23c7c;
  --p-hover: #ea4c89;
  --p-active: #d5467d;
  --p-special: #a93a65;
  --p-disabled: #7e2f4d;
  --p-text-disabled: #522335;
  --p-weak: #26171d;
  /* Surface 层级（dark，TC 填充-1） */
  --s-1: #2d2e2f;
  --s-1-hover: #323434;
  --s-1-active: #202121;
  --s-1-weak: #262627;
  /* 输入/边框（dark，TC 填充-2） */
  --input-bg-base: #2b2d30;
  --input-border: #3e434b;
  --input-border-strong: #43474b;
  --input-bg-strong: #1f2123;
}

:root,
#mount [data-theme] {
  /* 业务/通用变量引用色阶（全局可见，含 Shadow DOM） */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
}

#mount {
  --font-family: var(
    system-ui,
    -apple-system,
    "Segoe UI",
    "Roboto",
    "Ubuntu",
    "Cantarell",
    "Noto Sans",
    sans-serif,
    "Apple Color Emoji",
    "Segoe UI Emoji",
    "Segoe UI Symbol",
    "Noto Color Emoji"
  );
  /* PC/H5 兼容的字号、间距、圆角、阴影变量 */
  --f-12: 12px;
  --f-14: 14px;
  --f-15: 15px;
  --f-16: 16px;
  --f-18: 18px;
  --f-20: 20px;
  --space-4: 4px;
  --space-6: 6px;
  --space-8: 8px;
  --space-12: 12px;
  --space-16: 16px;
  --space-18: 18px;
  --space-24: 24px;
  --radius-8: 8px;
  --radius-12: 12px;
  --radius-16: 16px;
  --control-height-lg: 44px;
  --width-28: 28px;
  --width-24: 24px;
  --width-20: 20px;
  --width-18: 18px;
  --width-16: 16px;
  --width-label-md: 56px;
  --shadow-lg: 0 18px 48px rgba(0, 0, 0, 0.12);

  /* 常规变量 */
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 2px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  /* 兼容旧变量：主色直接引用品牌主色阶 */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  /* Modal 业务变量引用色阶 */
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
  line-height: var(--line-height);
  font-family: var(--font-family);
  font-size: var(--font-size);
}

@media (max-width: 480px) {
  :root,
  #mount {
    --f-12: 10px;
    --f-14: 12px;
    --f-15: 13px;
    --f-16: 14px;
    --f-18: 16px;
    --f-20: 18px;
    --space-4: 4px;
    --space-6: 4px;
    --space-8: 6px;
    --space-12: 8px;
    --space-16: 12px;
    --space-18: 14px;
    --space-24: 18px;
    --radius-8: 6px;
    --radius-12: 10px;
    --radius-16: 12px;
    --control-height-lg: 38px;
    --shadow-lg: 0 12px 32px rgba(0, 0, 0, 0.1);
    --width-28: 24px;
    --width-24: 20px;
    --width-20: 16px;
    --width-18: 14px;
    --width-16: 12px;
    --width-label-md: 52px;
  }
}

#mount * {
  box-sizing: border-box;
}

[hidden] {
  display: none !important;
}

:where(#mount) a,
:where(#mount) [role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
:where(#mount) a:is([aria-current], :hover, :active, :focus),
:where(#mount) [role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}

:where(#mount) label {
  font-size: 13px;
  line-height: 1.3;
  color: var(--text-gray-2, #222222);
}

:where(#mount) button {
  width: 100%;
  font-family: inherit;
  font-size: 15px;
  line-height: 1.3;
  min-height: 44px;
  border-radius: 12px;
  padding: 0 14px;
  border: none;
  background-color: var(--primary, #ea4c89);
  color: #ffffff;
  cursor: pointer;
  transition: background-color 0.2s ease, box-shadow 0.2s ease, color 0.2s ease;
}

:where(#mount) button:hover {
  background-color: var(--primary-hover, #f082ac);
}

:where(#mount) button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

:where(#mount) select,
:where(#mount) input,
:where(#mount) textarea {
  font-family: inherit;
  color: var(--text-gray-2, #222222);
}

:where(#mount) select {
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  font-family: inherit;
  color: var(--text-gray-2, inherit);
  font-size: 13px;
  line-height: 1.3;
  outline: none;
  padding: 8px 16px;
  border: none;
  border-radius: 12px;
  background-color: var(--popup-item-background-color, transparent);
  background-image: var(--icon-xia, none);
  background-repeat: no-repeat;
  background-position: center right 12px;
  background-size: 16px auto;
  cursor: pointer;
}

:where(#mount) input[type="checkbox"] {
  accent-color: var(--primary, #ea4c89);
}

[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

:where(#mount) [type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
:where(#mount) [type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  background-image: none;
}
:where(#mount) [type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

:where(#mount) [type="checkbox"][aria-invalid="false"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="false"],
:where(#mount) [type="radio"][aria-invalid="false"],
:where(#mount) [type="radio"]:checked[aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(#mount) [type="checkbox"][aria-invalid="true"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="true"],
:where(#mount) [type="radio"][aria-invalid="true"],
:where(#mount) [type="radio"]:checked[aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

.text-black {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.inline-flex {
  display: inline-flex;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

#mount {
  min-width: 268px;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}



.activity-tips {
  border-radius: 8px;
  padding: 0px 8px;
  min-height: 28px;
  background: linear-gradient(83deg, #FACCDE -0.87%, #FCE7EF 43.13%, #FBD6E4 72.08%, #FFB3D1 96.34%);  gap: 2px;
  color: #333;
  cursor: pointer;
  gap: 4px;
}

.activity-tips-icon {
  width: 18px;
  height: 18px;
  flex-shrink: 0;
}

.countdown-container {
  min-width: 50px;
  text-align: left;
  font-weight: 600;
  font-size: 12px;
  letter-spacing: 0.01em;
}

.activity-tips-text {
  font-weight: 600;
  max-width: 100px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 100%;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #b3b3b3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 869px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg></div></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; bottom: 30px; right: 65px;"></div></div></div></div></template></div></html>